<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>è®ºæ–‡é˜…è¯» | Deep Semantic Role Labeling:What Works and Whatâ€™s Next</title>
      <link href="/passages/srl-paper-reading-md/"/>
      <url>/passages/srl-paper-reading-md/</url>
      
        <content type="html"><![CDATA[<h2 id="ä»€ä¹ˆæ˜¯SRL"><a href="#ä»€ä¹ˆæ˜¯SRL" class="headerlink" title="ä»€ä¹ˆæ˜¯SRL"></a>ä»€ä¹ˆæ˜¯SRL</h2><p>Semantic Role Labeling ä»»åŠ¡æŒ‡çš„æ˜¯å›´ç»•ç€è°“è¯æ ‡è®°ä¸€å¥è¯çš„è®ºå…ƒä¿¡æ¯ï¼Œè¯†åˆ«å‡ºwhatï¼Œwhoï¼Œwhomï¼Œwhenï¼Œwhereç­‰ä¿¡æ¯ã€‚è¿™æ˜¯ä¸€é¡¹æ ‡è®°å¥å­äº‹ä»¶çš„æµ…å±‚è¯­ä¹‰å¤„ç†ï¼Œä¸æ¶‰åŠå¥å­çš„å¥æ³•åˆ†æã€‚æ¯”å¦‚å¯¹äºâ€œä»–æ˜¨å¤©æŠŠä¹¦äº¤ç»™äº†å¼ ä¸‰â€å’Œâ€œæ˜¨å¤©ä¹¦è¢«ä»–äº¤ç»™äº†å¼ ä¸‰â€è¿™ä¸¤å¥è¯ï¼Œå®ƒä»¬åœ¨å¥æ³•ä¸Šä¸ä¸€æ ·ï¼Œä½†æ˜¯åœ¨è¯­ä¹‰è§’è‰²æ ‡æ³¨ä¸Šæ˜¯ä¸€æ ·çš„ã€‚</p><p>è¯­ä¹‰è§’è‰²æ ‡æ³¨æ˜¯è‡ªç„¶è¯­è¨€å¤„ç†çš„åº•å±‚ä»»åŠ¡ï¼Œé€šè¿‡è¿™é¡¹ä»»åŠ¡ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥è·å–åˆ°ä¸€å¥è¯äº‹ä»¶æ€§çš„ä¿¡æ¯ï¼Œå¦‚æœèƒ½å¤Ÿå¤„ç†å¥½ï¼Œå°†å¯¹è‡ªåŠ¨é—®ç­”ã€è‡ªåŠ¨æ–‡æ‘˜ç­‰ä»»åŠ¡äº§ç”Ÿç›´æ¥è€Œæœ‰åŠ›çš„å¸®åŠ©ã€‚</p><h2 id="æœ¬æ–‡çš„æ¨¡å‹"><a href="#æœ¬æ–‡çš„æ¨¡å‹" class="headerlink" title="æœ¬æ–‡çš„æ¨¡å‹"></a>æœ¬æ–‡çš„æ¨¡å‹</h2><p>Luçš„æ¨¡å‹ä¹‹æ‰€ä»¥èƒ½å¤Ÿæ¯”åŸæœ‰çš„ç³»ç»Ÿæœ‰é‚£ä¹ˆå¤§çš„æå‡ï¼Œå¥¹è®¤ä¸ºä¸»è¦åŸå› æ˜¯ä¸¤æ–¹é¢ï¼Œä¸€æ–¹é¢æ˜¯ä½¿ç”¨äº†ä¼˜åŒ–è¿‡çš„BiLSTMæ¨¡å‹ï¼Œå¦ä¸€æ–¹é¢æ˜¯å¯¹è¾“å‡ºè¿›è¡Œäº†ä¼˜åŒ–ç¼–ç ã€‚</p><p><img width="400" src="http://ww1.sinaimg.cn/large/62751203ly1g1xhlrv9d4j20sa0mutca.jpg"></p><h3 id="ä¼˜åŒ–è¿‡çš„BiLSTMæ¨¡å‹"><a href="#ä¼˜åŒ–è¿‡çš„BiLSTMæ¨¡å‹" class="headerlink" title="ä¼˜åŒ–è¿‡çš„BiLSTMæ¨¡å‹"></a>ä¼˜åŒ–è¿‡çš„BiLSTMæ¨¡å‹</h3><h4 id="Inputã€Output-amp-Function"><a href="#Inputã€Output-amp-Function" class="headerlink" title="Inputã€Output &amp; Function"></a>Inputã€Output &amp; Function</h4><p><img width="400" src="http://ww1.sinaimg.cn/large/62751203ly1g1xihhtogej213k0he10j.jpg"></p><ul><li><p>è®­ç»ƒè¾“å…¥$(w,v)$ã€‚</p><ul><li>$w$ä»£è¡¨è¯å‘é‡ï¼Œæœ¬æ–‡ä½¿ç”¨çš„æ˜¯GLoVe embeddingï¼Œç„¶å$v$ä»£è¡¨æ˜¯å¦æ˜¯predicateï¼ˆè°“è¯ï¼‰ï¼Œè‹¥æ˜¯ï¼Œåˆ™ä¸º1ï¼Œå¦ä¸º0ï¼Œä¸¤ä¸ªéƒ½æ˜¯100 dimã€‚</li></ul></li><li><p>è¾“å‡ºæ˜¯y(BIO-tagger)</p></li><li>Scoring Functionï¼š<ul><li>$f(\boldsymbol{w}, \boldsymbol{y})=\sum_{t=1}^{n} \log p\left(y_{t} | \boldsymbol{w}\right)-\sum_{c \in \mathcal{C}} c\left(\boldsymbol{w}, y_{1 : t}\right)$</li><li>å¯èƒ½æ€§å‡å»æƒ©ç½šå€¼ã€‚å› ä¸ºè¾“å‡ºçš„ç»“æœæœ‰ä¸€äº›é™åˆ¶ï¼Œè¿™äº›åé¢ä¼šè®²ã€‚</li></ul></li><li>ä¸ºä½¿ç›®æ ‡å‡½æ•°æœ€å¤§è¿›è¡Œå‰å‘åé¦ˆå’Œåå‘åé¦ˆè¿›è¡Œè®­ç»ƒã€‚</li></ul><h4 id="BiLSTM"><a href="#BiLSTM" class="headerlink" title="BiLSTM"></a>BiLSTM</h4><p>BiLSTM çš„å†…éƒ¨æ„é€ å°±æ˜¯ç®€å•çš„LSTMåªä¸è¿‡å åŠ äº†ä¸¤å±‚ï¼Œå³ä¸€ä¸ªå•å…ƒä¼šæ”¶åˆ°å‰è¯ä¿¡æ¯ä¹Ÿä¼šæ”¶åˆ°åè¯ä¿¡æ¯ã€‚</p><script type="math/tex; mode=display">\begin{aligned} \boldsymbol{i}_{l, t} &=\sigma\left(\mathbf{W}_{\mathrm{i}}^{l}\left[\boldsymbol{h}_{l, t+\delta_{l}}, \boldsymbol{x}_{l, t}\right]+\boldsymbol{b}_{\mathrm{i}}^{l}\right) \\ \boldsymbol{o}_{l, t} &=\sigma\left(\mathbf{W}_{\mathrm{o}}^{l}\left[\boldsymbol{h}_{l, t+\delta_{l}}, \boldsymbol{x}_{l, t}\right]+\boldsymbol{b}_{\mathrm{o}}^{l}\right) \\ \boldsymbol{f}_{l, t} &=\sigma\left(\mathbf{W}_{\mathrm{f}}^{l}\left[\boldsymbol{h}_{l, t+\delta_{l}}, \boldsymbol{x}_{l, t}\right]+\boldsymbol{b}_{\mathrm{f}}^{l}+1\right) \\ \tilde{\boldsymbol{c}}_{l, t} &=\tanh \left(\mathbf{W}_{\mathrm{c}}^{l}\left[\boldsymbol{h}_{l, t+\delta_{l}}, \boldsymbol{x}_{l, t}\right]+\boldsymbol{b}_{\mathrm{c}}^{l}\right) \end{aligned}</script><script type="math/tex; mode=display">\begin{aligned} \boldsymbol{c}_{l, t} &=\boldsymbol{i}_{l, t} \circ \tilde{\boldsymbol{c}}_{l, t}+\boldsymbol{f}_{l, t} \circ \boldsymbol{c}_{t+\delta_{l}} \\ \boldsymbol{h}_{l, t} &=\boldsymbol{o}_{l, t} \circ \tanh \left(\boldsymbol{c}_{l, t}\right) \end{aligned}</script><script type="math/tex; mode=display">\boldsymbol{x}_{l, t}=\left\{\begin{array}{ll}{\left[\mathbf{W}_{\mathrm{emb}}\left(w_{t}\right), \mathbf{W}_{\mathrm{mask}}(t=v)\right]} & {l=1} \\ {\boldsymbol{h}_{l-1, t}} & {l>1}\end{array}\right.</script><script type="math/tex; mode=display">\delta_{l}=\left\{\begin{array}{ll}{1} & {\text { if } l \text { is even }} \\ {-1} & {\text { otherwise }}\end{array}\right.</script><p><img width="400" src="http://ww1.sinaimg.cn/large/62751203ly1g1xjba5x79j20ok0n0jw0.jpg"></p><h4 id="Recurrent-dropout"><a href="#Recurrent-dropout" class="headerlink" title="Recurrent dropout"></a>Recurrent dropout</h4><p>ä¸ºäº†é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œæˆ‘ä»¬ä¼šä½¿ç”¨dropoutçš„æ–¹æ³•ã€‚è¿‡å»çš„dropoutæˆ‘ä»¬å¤§å¤šä½¿ç”¨éšæœºç”Ÿæˆï¼Œä½†æ˜¯åœ¨è¿™æ ·å¤æ‚çš„ç½‘ç»œä¸­ï¼Œå¦‚æœé‡‡å–ä¹‹å‰çš„åšæ³•ä¼šè®©æ¨¡å‹è®­ç»ƒçš„å™ªå£°è¶Šæ¥è¶Šå¤§ï¼Œä¸ºæ­¤ï¼Œæˆ‘ä»¬ä½¿ç”¨Recurrent dropoutï¼Œè¿™ç§dropoutæ¯å±‚éƒ½æ˜¯ä¸€æ ·çš„ï¼ˆsharedï¼‰ï¼Œå› æ­¤å¯ä»¥å‡å°‘å™ªå£°ï¼Œè¾¾åˆ°é˜²æ­¢è¿‡æ‹Ÿåˆçš„æ•ˆæœã€‚</p><script type="math/tex; mode=display">\begin{aligned} \widetilde{\boldsymbol{h}}_{l, t} &=\boldsymbol{r}_{l, t} \circ \boldsymbol{h}_{l, t}^{\prime}+\left(1-\boldsymbol{r}_{l, t}\right) \circ \mathbf{W}_{\mathrm{h}}^{l} \boldsymbol{x}_{l, t} \\ \boldsymbol{h}_{l, t} &=\boldsymbol{z}_{l} \circ \widetilde{\boldsymbol{h}}_{l, t} \end{aligned}</script><p><img width="400" src="http://ww1.sinaimg.cn/large/62751203ly1g1xjeuagzzj20lm0nw43c.jpg"></p><h3 id="Constrained-A-decoding"><a href="#Constrained-A-decoding" class="headerlink" title="Constrained A* decoding"></a>Constrained A* decoding</h3><p>ç»è¿‡softmaxå±‚ä¹‹åï¼Œæˆ‘ä»¬ä¼šå¾—åˆ°ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼Œä½†æ˜¯å¹¶éé€‰æ‹©æ¦‚ç‡æœ€é«˜çš„é‚£ä¸ªtagå°±æ˜¯æˆ‘ä»¬æ‰€è¦çš„tagï¼Œå› ä¸ºå‰è¯åè¯çš„tagé€‰æ‹©å¹¶éç‹¬ç«‹ï¼Œè€Œæ˜¯ä¼šç›¸äº’å½±å“çš„ï¼Œæ¢å¥è¯è¯´ï¼Œæˆ‘ä»¬æœ€åé€‰æ‹©tagæ—¶ä¼šæ”¶åˆ°ä¸€äº›é™åˆ¶ã€‚</p><p>ä½œè€…ä¸»è¦è®²äº†æœ‰ä¸‰ç§é™åˆ¶ï¼š</p><ul><li>ç¬¬ä¸€æ˜¯BIOæ ‡ç­¾ä½“ç³»çš„é™åˆ¶ï¼Œæ¯”å¦‚I-tagä¸èƒ½åœ¨B-å‰é¢ï¼›</li><li>ç¬¬äºŒæ˜¯è¯­ä¹‰è§’è‰²ä¸Šçš„é™åˆ¶ï¼Œæ¯”å¦‚æ ¸å¿ƒçš„è¯­ä¹‰è§’è‰²AG0-AG5ï¼Œåœ¨åªæœ‰ä¸€ä¸ªè°“è¯çš„æƒ…å†µä¸‹ï¼Œæ¯ä¸ªæœ€å¤šå‡ºç°1æ¬¡ï¼›</li><li>ç¬¬ä¸‰æ˜¯å¥æ³•ä¸Šçš„é™åˆ¶ï¼Œæ¯”å¦‚å¥æ³•ä¸Šä¸åŒåœ¨ä¸€ä¸ªçˆ¶èŠ‚ç‚¹ä¸­çš„ä¸¤ä¸ªè®ºå…ƒä¸èƒ½è¢«æ ‡è®°ä¸ºB-Xï¼ŒI-Xï¼ˆXæŒ‡æœ‰åŒæ ·çš„è¯­ä¹‰è§’è‰²ï¼‰ã€‚</li></ul><p>é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œä½œè€…ç»™å‡ºäº†ä¸€ä¸ªæƒ©ç½šå‡½æ•°æ¥æ§åˆ¶æœ€åçš„åˆ†æ•°ï¼Œå¥¹å¸Œæœ›é€‰å‡ºåœ¨è€ƒè™‘äº†è¿™äº›é™åˆ¶ä¹‹åæ¦‚ç‡æœ€å¤§çš„ç»“æœã€‚</p><h2 id="ç»“æœ"><a href="#ç»“æœ" class="headerlink" title="ç»“æœ"></a>ç»“æœ</h2><p>æ¯”ä»¥å‰çš„æ¨¡å‹çš„F1æé«˜äº†10%ã€‚å¹¶é€šè¿‡å®éªŒè¯æ˜äº†ï¼š</p><ul><li>Deep-BiLSTM å¯ä»¥å¾ˆå¥½åœ°è§£å†³è¯­ä¹‰è§’è‰²æ ‡æ³¨ä¸­é•¿è·ç¦»ä¾å­˜çš„é—®é¢˜ï¼›</li><li>è®­ç»ƒæ—¶å¯¹æƒé‡è¿›è¡Œéšæœºæ­£äº¤åˆ†è§£èƒ½å¤Ÿä½¿è®­ç»ƒæ›´å¿«å¼€å§‹ï¼›</li><li>å¥æ³•ä¿¡æ¯å¯¹è¯­ä¹‰è§’è‰²æ ‡æ³¨æ˜¯æœ‰ç”¨çš„ï¼Œæœªæ¥å¯ä»¥è€ƒè™‘åœ¨æƒ©ç½šå‡½æ•°ä¸­ä¼˜åŒ–ï¼Œæˆ‘è§‰å¾—å°±æ˜¯èƒ½å°†ä¹‹å‰ç‰¹å¾å·¥ç¨‹ä¸­æ‰€æ€»ç»“çš„ä¸€äº›æ¡ä»¶è§„åˆ’åˆ°è¿™ä¸ªæ¨¡å‹é‡Œæ¥ã€‚</li></ul><h2 id="åç»­å­¦ä¹ "><a href="#åç»­å­¦ä¹ " class="headerlink" title="åç»­å­¦ä¹ "></a>åç»­å­¦ä¹ </h2><ul><li>è¿™ä¸ªç®—æ³•æ¨¡å‹å·²ç»è¢«æ•´åˆåˆ°AllenNLPä¸­ï¼Œå¯ä»¥å­¦ä¹ ä¸‹å¦‚ä½•åœ¨æœ¬åœ°ä½¿ç”¨ï¼›</li><li>å¦‚ä½•è¿ç§»åˆ°ä¸­æ–‡ä»»åŠ¡ä¸­ï¼Ÿ</li></ul><h2 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h2><ul><li><a href="https://www.aclweb.org/anthology/papers/P/P17/P17-1044/" target="_blank" rel="noopener">è®ºæ–‡</a></li><li><a href="https://www.youtube.com/watch?v=aptipHMTmmk" target="_blank" rel="noopener">Luå…³äºè¿™ä¸ªæ¨¡å‹çš„talk</a>(æ²¹ç®¡)</li></ul>]]></content>
      
      
      <categories>
          
          <category> SRL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> SRL </tag>
            
            <tag> paper-reading </tag>
            
            <tag> NLP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ç»ˆç«¯å‘½ä»¤ç¬”è®°</title>
      <link href="/passages/about-terminal/"/>
      <url>/passages/about-terminal/</url>
      
        <content type="html"><![CDATA[<h1 id="vi-å¸¸ç”¨å‘½ä»¤"><a href="#vi-å¸¸ç”¨å‘½ä»¤" class="headerlink" title="vi å¸¸ç”¨å‘½ä»¤"></a>vi å¸¸ç”¨å‘½ä»¤</h1><h2 id="1-è¿›å…¥-vi-ç¼–è¾‘å™¨"><a href="#1-è¿›å…¥-vi-ç¼–è¾‘å™¨" class="headerlink" title="1. è¿›å…¥ vi ç¼–è¾‘å™¨"></a>1. è¿›å…¥ vi ç¼–è¾‘å™¨</h2><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo <span class="keyword">vi</span> <span class="symbol">&lt;path&gt;</span></span><br></pre></td></tr></table></figure><h2 id="2-ä¿®æ”¹å†…å®¹"><a href="#2-ä¿®æ”¹å†…å®¹" class="headerlink" title="2. ä¿®æ”¹å†…å®¹"></a>2. ä¿®æ”¹å†…å®¹</h2><p>è¾“å…¥<code>i</code>ï¼Œè¿›å…¥<code>insert</code>æ¨¡å¼ã€‚<br>æŒ‰<code>esc</code>ï¼Œé€€å‡ºæ¨¡å¼ã€‚</p><h2 id="3-ä¿å­˜ï¼Œé€€å‡º"><a href="#3-ä¿å­˜ï¼Œé€€å‡º" class="headerlink" title="3. ä¿å­˜ï¼Œé€€å‡º"></a>3. ä¿å­˜ï¼Œé€€å‡º</h2><ul><li><code>:w</code> ä¿å­˜æ–‡ä»¶ä½†ä¸é€€å‡ºvi;</li><li><code>:wq</code> ä¿å­˜æ–‡ä»¶å¹¶é€€å‡ºvi;</li><li><code>q:</code> ä¸ä¿å­˜æ–‡ä»¶ï¼Œé€€å‡ºvi</li><li><code>:e!</code> æ”¾å¼ƒæ‰€æœ‰ä¿®æ”¹ï¼Œä»ä¸Šæ¬¡ä¿å­˜æ–‡ä»¶å¼€å§‹å†ç¼–è¾‘</li></ul><p><a href="https://www.cnblogs.com/mondol/p/vi-examples.html" target="_blank" rel="noopener">viå‘½ä»¤å¤§å…¨</a> </p><h1 id="Jupyter-or-conda-not-found"><a href="#Jupyter-or-conda-not-found" class="headerlink" title="Jupyter or conda not found"></a>Jupyter or conda not found</h1><p>æˆ‘å®‰è£…å¥½anacondaåï¼Œæ‰“ç®—ç”¨å‘½ä»¤è¡Œç›´æ¥æ‰“å¼€jupyter notebookï¼Œç»“æœå´æ²¡æœ‰æˆåŠŸï¼Œç½‘ä¸Šä¸€èˆ¬çš„è§£é‡Šæ˜¯è¦æŠŠanacondaé…ç½®åˆ°ç¯å¢ƒå˜é‡é‡Œï¼š<br>åœ¨ç»ˆç«¯ä¸­è¾“å…¥ï¼š</p><figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo vi ~<span class="string">/.bash_profile</span></span><br></pre></td></tr></table></figure><p>æ‰“å¼€ååœ¨æœ«å°¾åŠ ä¸Šï¼š</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="string">'~/anaconda/bin:$PATH'</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># è¿™é‡Œçš„pathè¦æ ¹æ®anacondaæ‰€åœ¨çš„ä½ç½®å®šä¹‰</span></span><br><span class="line"></span><br><span class="line">source ~/.bash_profile</span><br><span class="line"></span><br><span class="line"><span class="comment"># è¡¨ç¤ºä¿®æ”¹ç«‹å³ç”Ÿæ•ˆ</span></span><br></pre></td></tr></table></figure><p>ä½†æ˜¯å‘¢ï¼Œæˆ‘è¯•äº†å¥½å‡ æ¬¡éƒ½æ²¡æœ‰æˆåŠŸï¼Œäº‹å®ä¸Šï¼Œæ˜¯æˆ‘é…ç½®äº†<code>oh-my-zsh</code>çš„åŸå› ã€‚</p><p>å› æ­¤ï¼Œæ­£ç¡®çš„è§£å†³æ–¹æ³•æ˜¯ï¼Œæ‰“å¼€<code>~/.zshrc</code>ï¼Œç„¶ååœ¨æ–‡ä»¶æœ€åä¸€è¡Œæ·»åŠ ï¼š</p><figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="builtin-name">export</span> <span class="attribute">PATH</span>=<span class="variable">$PATH</span>:$HOME/anaconda/bin</span><br></pre></td></tr></table></figure><p>ä¿å­˜æ–‡ä»¶åï¼Œå…³é—­çª—å£ï¼Œé‡æ–°å¼€å¯çª—å£æ—¶ï¼Œè¾“å…¥å‘½ä»¤<code>conda --v</code>æ¥æ£€æµ‹æ˜¯å¦æˆåŠŸã€‚</p><p><a href="https://stackoverflow.com/questions/18675907/how-to-run-conda" target="_blank" rel="noopener">å‚è€ƒé“¾æ¥ğŸ”—</a> </p><h1 id="zsh-not-found"><a href="#zsh-not-found" class="headerlink" title="zsh not found"></a>zsh not found</h1><figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">exec <span class="regexp">/bin/</span>zsh</span><br></pre></td></tr></table></figure><p><a href="https://www.jiloc.com/43492.html" target="_blank" rel="noopener">å‚è€ƒèµ„æ–™ğŸ”—</a> </p>]]></content>
      
      
      
        <tags>
            
            <tag> å‘½ä»¤è¡Œ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Slot Filling with SimpleRNN</title>
      <link href="/passages/slot-filling/"/>
      <url>/passages/slot-filling/</url>
      
        <content type="html"><![CDATA[<h1 id="ä»€ä¹ˆæ˜¯Slot-Fillingï¼Ÿ"><a href="#ä»€ä¹ˆæ˜¯Slot-Fillingï¼Ÿ" class="headerlink" title="ä»€ä¹ˆæ˜¯Slot Fillingï¼Ÿ"></a>ä»€ä¹ˆæ˜¯Slot Fillingï¼Ÿ</h1><p>Slot Fillingæ˜¯è‡ªç„¶è¯­è¨€ç†è§£ä¸­çš„ä¸€ä¸ªåŸºæœ¬é—®é¢˜ï¼Œæ˜¯å¯¹è¯­è¨€å«ä¹‰çš„ç®€å•åŒ–å¤„ç†ï¼Œå®ƒçš„æ€æƒ³ç±»ä¼¼äºè¯­è¨€å­¦ä¸­æ¡†æ¶ä¸»ä¹‰çš„ä¸€æ´¾ï¼Œå…ˆè®¾å®šå¥½ç‰¹å®šçš„è¯­è¨€ç±»å‹æ§½ï¼Œå†å°†è¾“å…¥çš„å•è¯ä¸€ä¸€å¡«å…¥æ§½å†…ï¼Œè€Œè·å–è¨€è¯­å«ä¹‰çš„æ—¶å€™å³æ˜¯æ ¹æ®è¯­ä¹‰æ§½çš„å«ä¹‰è¿›è¡Œæå–å’Œæ£€ç´¢ã€‚æˆ‘ä»¬è¿™é‡Œçš„ä»»åŠ¡å°±æ˜¯å°†è¡¨ç¤ºå®šè´­èˆªç­ï¼ˆATISæ•°æ®é›†ï¼‰è¿™ä¸€è¨€è¯­è¡Œä¸ºçš„ä¸€ç³»åˆ—è¯­å¥å¡«å…¥å„ç§ç±»å‹çš„è¯­ä¹‰æ§½ä¸­ã€‚</p><h1 id="ä¸ºä»€ä¹ˆä½¿ç”¨SimpleRNN"><a href="#ä¸ºä»€ä¹ˆä½¿ç”¨SimpleRNN" class="headerlink" title="ä¸ºä»€ä¹ˆä½¿ç”¨SimpleRNN?"></a>ä¸ºä»€ä¹ˆä½¿ç”¨SimpleRNN?</h1><p>Slot Fillingå±äºRNNåº”ç”¨ä¸­ä¸€å¯¹ä¸€çš„åº”ç”¨ï¼Œé€šè¿‡è®­ç»ƒæ¨¡å‹ï¼Œæ¯ä¸ªè¯éƒ½èƒ½è¢«å¡«åˆ°åˆé€‚çš„æ§½ä¸­ã€‚<br>RNNå’Œä¸€èˆ¬çš„ç¥ç»ç½‘ç»œçš„ä¸åŒåœ¨äºï¼Œåœ¨RNNä¸­ï¼Œæˆ‘ä»¬åœ¨æ—¶é—´tçš„è¾“å‡ºä¸ä»…å–å†³äºå½“å‰çš„è¾“å…¥å’Œæƒé‡ï¼Œè¿˜å–å†³äºä¹‹å‰çš„è¾“å…¥ï¼Œè€Œå¯¹äºå…¶ä»–ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œæ¯ä¸ªæ—¶åˆ»çš„è¾“å…¥å’Œè¾“å‡ºéƒ½æ˜¯ç‹¬ç«‹è€Œéšæœºçš„ï¼Œæ²¡æœ‰ç›¸å…³æ€§ã€‚æ”¾åˆ°æˆ‘ä»¬è¦å¤„ç†è¯­ä¹‰ç†è§£çš„é—®é¢˜ä¸Šçœ‹ï¼Œè¯­è¨€ä½œä¸ºä¸€ç§åŸºäºæ—¶é—´çš„çº¿æ€§è¾“å‡ºï¼Œæ˜¾ç„¶ä¼šå—åˆ°å‰è¯çš„å½±å“ï¼Œå› æ­¤æˆ‘ä»¬é€‰å–RNNæ¨¡å‹æ¥è¿›è¡Œè§£å†³è¿™ä¸ªé—®é¢˜ã€‚<br>è¿™é‡Œé€‰å–SimpleRNN,æ˜¯å› ä¸ºè¿™ä¸ªRNNæ¯”è¾ƒç®€å•ï¼Œèƒ½è¾¾åˆ°ç†Ÿæ‚‰æ¡†æ¶çš„ç»ƒä¹ æ•ˆæœï¼Œä¹‹åå¯ä»¥é€‰å–å…¶ä»–æœ‰æ•ˆçš„RNNæ¨¡å‹ï¼Œå¦‚LSTMSè¿›è¡Œä¼˜åŒ–ã€‚</p><h1 id="æ„å»ºæ€è·¯ä¸€è§ˆï¼š"><a href="#æ„å»ºæ€è·¯ä¸€è§ˆï¼š" class="headerlink" title="æ„å»ºæ€è·¯ä¸€è§ˆï¼š"></a>æ„å»ºæ€è·¯ä¸€è§ˆï¼š</h1><ul><li>è½½å…¥æ•°æ®ï¼Œä½¿ç”¨çš„æ˜¯<a href="https://github.com/chsasank/ATIS.keras" target="_blank" rel="noopener">chsasank</a>ä¿®æ”¹çš„<a href="https://github.com/mesnilgr/is13" target="_blank" rel="noopener">mesnilgr</a>çš„load.pyã€‚</li><li>å®šä¹‰æ¨¡å‹ã€‚é‡‡å–Kerasä¸­çš„åºåˆ—æ¨¡å‹æ­å»ºï¼Œé¦–å…ˆä½¿ç”¨ä¸€ä¸ª100ç»´çš„word embeddingå±‚å°†è¾“å…¥çš„å•è¯è½¬åŒ–ä¸ºé«˜ç»´ç©ºé—´ä¸­çš„ä¸€ä¸ªå‘é‡ï¼ˆåœ¨è¿™ä¸ªç©ºé—´ä¸­ï¼Œè¯­ä¹‰å’Œè¯­æ³•ä½ç½®è¶Šè¿‘çš„å•è¯çš„è·ç¦»è¶Šå°ï¼‰ï¼Œç„¶åæˆ‘ä»¬æ„å»ºä¸€ä¸ªdropoutå±‚é˜²æ­¢è¿‡æ‹Ÿåˆï¼Œè®¾ç½®SimpleRNNå±‚ï¼Œè®¾ç½®TimeDistributedå±‚ä»¥å®ŒæˆåŸºäºæ—¶é—´çš„åå‘ä¼ æ’­ã€‚æœ€åæˆ‘ä»¬å°†è¿™äº›å±‚ç»„ç»‡åœ¨ä¸€èµ·ï¼Œå¹¶ç¡®å®šoptimizerå’Œloss functionã€‚æˆ‘ä»¬é€‰å–çš„optimizeræ˜¯rmsprop,è¿™æ ·åœ¨è®­ç»ƒåæœŸä¾ç„¶èƒ½æ‰¾åˆ°è¾ƒæœ‰é¡¹ï¼Œè€Œé€‰å–categorical_crossentropyä½œä¸ºæŸå¤±å‡½æ•°ï¼Œåˆ™æ˜¯å› ä¸ºå¤„ç†çš„é—®é¢˜æ€§è´¨é€‚åˆäºæ­¤ã€‚</li><li>è®­ç»ƒæ¨¡å‹ã€‚å‡ºäºå¯¹è®¡ç®—èµ„æºçš„è€ƒè™‘ï¼Œæˆ‘ä»¬ä¸€èˆ¬ä½¿ç”¨minibtachçš„æ–¹æ³•æ‰¹é‡å¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚ä½†æ˜¯æˆ‘ä»¬è¿™é‡Œçš„æ•°æ®æ˜¯ä¸€å¥å¥è¯ï¼Œå¦‚æœæŒ‰ç…§ä¸€ä¸ªå›ºå®šçš„batch_sizeå°†å…¶åˆ†è£‚ï¼Œå¯èƒ½å¢åŠ äº†ä¸å¿…è¦çš„è”ç³»ï¼ˆå› ä¸ºä¸Šä¸‹ä¸¤å¥è¯æ˜¯ç‹¬ç«‹çš„ï¼‰ï¼Œå› æ­¤æˆ‘ä»¬å°†ä¸€å¥è¯ä½œä¸ºä¸€ä¸ªbatchå»è¿›è¡Œè®­ç»ƒã€éªŒè¯ä»¥åŠé¢„æµ‹ï¼Œå¹¶æ‰‹åŠ¨ç®—å‡ºä¸€ä¸ªepochçš„å¹³å‡è¯¯å·®ã€‚</li><li>è¯„ä¼°å’Œé¢„æµ‹æ¨¡å‹ã€‚æˆ‘ä»¬é€šè¿‡è§‚å¯ŸéªŒè¯è¯¯å·®å’Œé¢„æµ‹F1ç²¾åº¦æ¥å¯¹æ¨¡å‹è¿›è¡Œè¯„ä¼°ã€‚é¢„æµ‹F1ç²¾åº¦ä½¿ç”¨çš„æ˜¯<a href="https://github.com/sighsmile/conlleval" target="_blank" rel="noopener">signsmile</a>ç¼–å†™çš„conlleval.pyã€‚</li><li>ä¿å­˜æ¨¡å‹ã€‚</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers.embeddings <span class="keyword">import</span> Embedding</span><br><span class="line"><span class="keyword">from</span> keras.layers.recurrent <span class="keyword">import</span> SimpleRNN</span><br><span class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> Dense,Dropout</span><br><span class="line"><span class="keyword">from</span> keras.utils <span class="keyword">import</span> to_categorical</span><br><span class="line"><span class="keyword">from</span> keras.layers.wrappers <span class="keyword">import</span> TimeDistributed</span><br><span class="line"><span class="keyword">from</span> matplotlib <span class="keyword">import</span> pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> data.load</span><br><span class="line"><span class="keyword">from</span> metrics.accuracy <span class="keyword">import</span> evaluate</span><br></pre></td></tr></table></figure><pre><code>Using TensorFlow backend.</code></pre><h1 id="Load-Data"><a href="#Load-Data" class="headerlink" title="Load Data"></a>Load Data</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">train_set,valid_set,dicts = data.load.atisfull()</span><br><span class="line"><span class="comment"># print(train_set[:1])</span></span><br><span class="line"><span class="comment"># dicts = &#123;'label2idx':&#123;&#125;,'words2idx':&#123;&#125;,'table2idx':&#123;&#125;&#125;</span></span><br><span class="line">w2idx,labels2idx = dicts[<span class="string">'words2idx'</span>],dicts[<span class="string">'labels2idx'</span>]</span><br><span class="line">train_x,_,train_label = train_set</span><br><span class="line">val_x,_,val_label = valid_set</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">idx2w = &#123;w2idx[i]:i <span class="keyword">for</span> i <span class="keyword">in</span> w2idx&#125;</span><br><span class="line">idx2lab = &#123;labels2idx[i]:i <span class="keyword">for</span> i <span class="keyword">in</span> labels2idx&#125;</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">n_classes = len(idx2lab)</span><br><span class="line">n_vocab = len(idx2w)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">words_train = [[idx2w[i] <span class="keyword">for</span> i <span class="keyword">in</span> w[:]] <span class="keyword">for</span> w <span class="keyword">in</span> train_x]</span><br><span class="line">labels_train = [[idx2lab[i] <span class="keyword">for</span> i <span class="keyword">in</span> w[:]] <span class="keyword">for</span> w <span class="keyword">in</span> train_label]</span><br><span class="line"></span><br><span class="line">words_val = [[idx2w[i] <span class="keyword">for</span> i <span class="keyword">in</span> w[:]] <span class="keyword">for</span> w <span class="keyword">in</span> val_x]</span><br><span class="line"><span class="comment"># labels_val = [[idx2lab[i] for i in w[:]] for w in val_label]</span></span><br><span class="line">labels_val =[]</span><br><span class="line"><span class="keyword">for</span> w <span class="keyword">in</span> val_label:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> w[:]:</span><br><span class="line">        labels_val.append(idx2lab[i])</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Real Sentence : &#123;&#125;'</span>.format(words_train[<span class="number">0</span>]))</span><br><span class="line">print(<span class="string">'Encoded Form : &#123;&#125;'</span>.format(train_x[<span class="number">0</span>]))</span><br><span class="line">print(<span class="string">'='</span>*<span class="number">40</span>)</span><br><span class="line">print(<span class="string">'Real Label : &#123;&#125;'</span>.format(labels_train[<span class="number">0</span>]))</span><br><span class="line">print(<span class="string">'Encoded Form : &#123;&#125;'</span>.format(train_label[<span class="number">0</span>]))</span><br></pre></td></tr></table></figure><pre><code>Real Sentence : [&#39;i&#39;, &#39;want&#39;, &#39;to&#39;, &#39;fly&#39;, &#39;from&#39;, &#39;boston&#39;, &#39;at&#39;, &#39;DIGITDIGITDIGIT&#39;, &#39;am&#39;, &#39;and&#39;, &#39;arrive&#39;, &#39;in&#39;, &#39;denver&#39;, &#39;at&#39;, &#39;DIGITDIGITDIGITDIGIT&#39;, &#39;in&#39;, &#39;the&#39;, &#39;morning&#39;]Encoded Form : [232 542 502 196 208  77  62  10  35  40  58 234 137  62  11 234 481 321]========================================Real Label : [&#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;B-fromloc.city_name&#39;, &#39;O&#39;, &#39;B-depart_time.time&#39;, &#39;I-depart_time.time&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;B-toloc.city_name&#39;, &#39;O&#39;, &#39;B-arrive_time.time&#39;, &#39;O&#39;, &#39;O&#39;, &#39;B-arrive_time.period_of_day&#39;]Encoded Form : [126 126 126 126 126  48 126  35  99 126 126 126  78 126  14 126 126  12]</code></pre><h1 id="Define-and-Compile-the-model"><a href="#Define-and-Compile-the-model" class="headerlink" title="Define and Compile the model"></a>Define and Compile the model</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">model = Sequential()</span><br><span class="line">model.add(Embedding(n_vocab,<span class="number">100</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.25</span>))</span><br><span class="line">model.add(SimpleRNN(<span class="number">100</span>,return_sequences=<span class="keyword">True</span>))</span><br><span class="line">model.add(TimeDistributed(Dense(n_classes,activation=<span class="string">'softmax'</span>)))</span><br><span class="line">model.compile(optimizer = <span class="string">'rmsprop'</span>,loss = <span class="string">'categorical_crossentropy'</span>)</span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure><pre><code>_________________________________________________________________Layer (type)                 Output Shape              Param #   =================================================================embedding_1 (Embedding)      (None, None, 100)         57200     _________________________________________________________________dropout_1 (Dropout)          (None, None, 100)         0         _________________________________________________________________simple_rnn_1 (SimpleRNN)     (None, None, 100)         20100     _________________________________________________________________time_distributed_1 (TimeDist (None, None, 127)         12827     =================================================================Total params: 90,127Trainable params: 90,127Non-trainable params: 0_________________________________________________________________</code></pre><h1 id="Train-the-model"><a href="#Train-the-model" class="headerlink" title="Train the model"></a>Train the model</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_the_model</span><span class="params">(n_epochs,train_x,train_label,val_x,val_label)</span>:</span></span><br><span class="line">    epoch,train_avgloss,val_avgloss,f1s = [],[],[],[]</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,n_epochs+<span class="number">1</span>):</span><br><span class="line">        epoch.append(i)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">## training</span></span><br><span class="line">        train_avg_loss =<span class="number">0</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> n_batch,sent <span class="keyword">in</span> enumerate(train_x):</span><br><span class="line">            label = train_label[n_batch]</span><br><span class="line">            <span class="comment"># label to one-hot</span></span><br><span class="line">            label = to_categorical(label,num_classes=n_classes)[np.newaxis,:]</span><br><span class="line">            sent = sent[np.newaxis,:]</span><br><span class="line">            loss = model.train_on_batch(sent,label)</span><br><span class="line">            train_avg_loss += loss</span><br><span class="line">            </span><br><span class="line">        train_avg_loss = train_avg_loss/n_batch</span><br><span class="line">        train_avgloss.append(train_avg_loss)</span><br><span class="line">        </span><br><span class="line">        <span class="comment">## evaluate&amp;predict</span></span><br><span class="line">        val_pred_label,pred_label_val,val_avg_loss  = [],[],<span class="number">0</span></span><br><span class="line">        </span><br><span class="line">        <span class="keyword">for</span> n_batch,sent <span class="keyword">in</span> enumerate(val_x):</span><br><span class="line">            label = val_label[n_batch]</span><br><span class="line">            label = to_categorical(label,num_classes=n_classes)[np.newaxis,:]</span><br><span class="line">            sent = sent[np.newaxis,:]</span><br><span class="line">            loss = model.test_on_batch(sent,label)</span><br><span class="line">            val_avg_loss += loss</span><br><span class="line">            </span><br><span class="line">            pred = model.predict_on_batch(sent)</span><br><span class="line">            pred = np.argmax(pred,<span class="number">-1</span>)[<span class="number">0</span>]</span><br><span class="line">            val_pred_label.append(pred)</span><br><span class="line">            </span><br><span class="line">        val_avg_loss = val_avg_loss/n_batch</span><br><span class="line">        val_avgloss.append(val_avg_loss)</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> w <span class="keyword">in</span> val_pred_label:</span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> w[:]:</span><br><span class="line">                pred_label_val.append(idx2lab[k])</span><br><span class="line">            </span><br><span class="line">        prec, rec, f1 = evaluate(labels_val,pred_label_val, verbose=<span class="keyword">False</span>)</span><br><span class="line">        print(<span class="string">'Training epoch &#123;&#125;\t train_avg_loss = &#123;&#125; \t val_avg_loss = &#123;&#125;'</span>.format(i,train_avg_loss,val_avg_loss))</span><br><span class="line">        print(<span class="string">'precision: &#123;:.2f&#125;% \t recall: &#123;:.2f&#125;% \t f1 :&#123;:.2f&#125;%'</span>.format(prec,rec,f1))</span><br><span class="line">        print(<span class="string">'-'</span>*<span class="number">60</span>)</span><br><span class="line">        f1s.append(f1)</span><br><span class="line"></span><br><span class="line">        </span><br><span class="line"><span class="comment">#     return epoch,pred_label_train,train_avgloss,pred_label_val,val_avgloss</span></span><br><span class="line">    <span class="keyword">return</span> epoch,f1s,val_avgloss,train_avgloss</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">epoch,f1s,val_avgloss,train_avgloss = train_the_model(<span class="number">40</span>,train_x,train_label,val_x,val_label)</span><br></pre></td></tr></table></figure><p><strong>è¾“å‡ºï¼š</strong><br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">  Training epoch <span class="number">1</span> train_avg_loss = <span class="number">0.5546463992293973</span>  val_avg_loss = <span class="number">0.4345020865901363</span></span><br><span class="line"><span class="symbol">  precision:</span> <span class="number">84.79</span>%  <span class="string">recall:</span> <span class="number">80.79</span>%  <span class="string">f1 :</span><span class="number">82.74</span>%</span><br><span class="line">  ------------------------------------------------------------</span><br><span class="line">  Training epoch <span class="number">2</span> train_avg_loss = <span class="number">0.2575569036037627</span>  val_avg_loss = <span class="number">0.36228470020366654</span></span><br><span class="line"><span class="symbol">  precision:</span> <span class="number">86.64</span>%  <span class="string">recall:</span> <span class="number">83.86</span>%  <span class="string">f1 :</span><span class="number">85.22</span>%</span><br><span class="line">  ------------------------------------------------------------</span><br><span class="line">  Training epoch <span class="number">3</span> train_avg_loss = <span class="number">0.2238766908014994</span>  val_avg_loss = <span class="number">0.33974187403771694</span></span><br><span class="line"><span class="symbol">  precision:</span> <span class="number">88.03</span>%  <span class="string">recall:</span> <span class="number">85.55</span>%  <span class="string">f1 :</span><span class="number">86.77</span>%</span><br><span class="line">  ------------------------------------------------------------</span><br><span class="line">â€¦â€¦</span><br><span class="line">     ------------------------------------------------------------</span><br><span class="line">  Training epoch <span class="number">40</span> train_avg_loss = <span class="number">0.09190682124901069</span>  val_avg_loss = <span class="number">0.2697056618613356</span></span><br><span class="line"><span class="symbol">  precision:</span> <span class="number">92.51</span>%  <span class="string">recall:</span> <span class="number">91.47</span>%  <span class="string">f1 :</span><span class="number">91.99</span>%</span><br><span class="line">  ------------------------------------------------------------</span><br></pre></td></tr></table></figure></p><h1 id="å¯è§†åŒ–"><a href="#å¯è§†åŒ–" class="headerlink" title="å¯è§†åŒ–"></a>å¯è§†åŒ–</h1><p>è§‚å¯ŸéªŒè¯è¯¯å·®ï¼Œé€‰å–åˆé€‚çš„epochã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line">plt.xlabel=(<span class="string">'epoch'</span>)</span><br><span class="line">plt.ylabel=(<span class="string">'loss'</span>)</span><br><span class="line">plt.plot(epoch,train_avgloss,<span class="string">'b'</span>)</span><br><span class="line">plt.plot(epoch,val_avgloss,<span class="string">'r'</span>,label=(<span class="string">'validation error'</span>))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure><p><img src="http://ohj9e0ect.bkt.clouddn.com/blog/180911/5A7mAF88bL.png?imageslim" alt="mark"></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">print(<span class="string">'æœ€å¤§f1å€¼ä¸º &#123;:.2f&#125;%'</span>.format(max(f1s)))</span><br></pre></td></tr></table></figure><pre><code>æœ€å¤§f1å€¼ä¸º 92.56%</code></pre><h1 id="ä¿å­˜æ¨¡å‹"><a href="#ä¿å­˜æ¨¡å‹" class="headerlink" title="ä¿å­˜æ¨¡å‹"></a>ä¿å­˜æ¨¡å‹</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.save(<span class="string">'slot_filling_with_simpleRNN.h5'</span>)</span><br></pre></td></tr></table></figure><h1 id="ç»“æœåˆ†æ"><a href="#ç»“æœåˆ†æ" class="headerlink" title="ç»“æœåˆ†æ"></a>ç»“æœåˆ†æ</h1><p>ä½¿ç”¨SimpleRNNæœ€ç»ˆå¾—åˆ°çš„F1å€¼ä¸º92.56%ï¼Œå’Œå¸ˆå…„çš„95.47%ç›¸æ¯”ç¡®å®è¿˜ç›¸å·®å¾ˆå¤šã€‚è¿™ä¸»è¦æ˜¯å’Œæˆ‘ä»¬æ¨¡å‹çš„é€‰å–æœ‰å…³ï¼ŒSimpleRNNåªèƒ½å°†å‰è¯çš„å½±å“å¸¦å…¥åˆ°æ¨¡å‹ä¸­ï¼Œä½†æ˜¯è¯­è¨€ä¸­åè¯å¯¹å‰è¯ä¹Ÿä¼šæœ‰ä¸€å®šçš„å½±å“ï¼Œå› æ­¤å¯ä»¥é€šè¿‡é€‰æ‹©æ›´åŠ å¤æ‚çš„æ¨¡å‹æˆ–è€…å¢åŠ èƒ½å¤Ÿæ•æ‰åˆ°åè¯ä¿¡æ¯çš„å±‚æ¥è¿›è¡Œä¼˜åŒ–ã€‚</p><h1 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h1><ul><li><a href="https://chsasank.github.io/spoken-language-understanding.html" target="_blank" rel="noopener">Keras Tutorial - Spoken Language Understanding</a></li><li><a href="https://github.com/czs0x55aa/pytorch-slot-filling/blob/master/evaluate.py" target="_blank" rel="noopener">pytorch-slot-filling</a></li><li><a href="https://github.com/liu946/AtisSlotLabeling" target="_blank" rel="noopener">liu946 AtisSlotLabeling</a></li><li><a href="https://blog.csdn.net/winteeena/article/details/78997053" target="_blank" rel="noopener">ã€Kerasæƒ…æ„Ÿåˆ†ç±»ã€‘è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°çš„é—®é¢˜æ±‡æ€»</a></li><li><a href="https://keras.io/zh/layers/recurrent/" target="_blank" rel="noopener">keras-SimpleRNN</a></li><li><a href="https://www.cnblogs.com/dapeng-bupt/p/7606111.html" target="_blank" rel="noopener">æœºå™¨å­¦ä¹ ä¸­è¿‡æ‹Ÿåˆçš„è§£å†³åŠæ³•</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> keras </tag>
            
            <tag> RNN </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TensorFlowå°è¯•ç‰›åˆ€</title>
      <link href="/passages/tf%E5%B0%8F%E8%AF%95%E7%89%9B%E5%88%80/"/>
      <url>/passages/tf%E5%B0%8F%E8%AF%95%E7%89%9B%E5%88%80/</url>
      
        <content type="html"><![CDATA[<blockquote><p>æ­¤æ—¥å¿—ä¸ºå‚ç…§Udacityè¯¾ç¨‹ä¸­ã€ŠIntro to tensorflowã€‹çš„jupyter notebookæ‰€åšçš„åˆ†è§£æºç ï¼Œç›®çš„åœ¨äºç†è§£ä»£ç é€»è¾‘ï¼Œç†Ÿæ‚‰åˆ›å»ºæµç¨‹å’Œå¥—è·¯ã€‚å…¶ä¸­å‚è€ƒäº†ä¸å°‘åšæ–‡é“¾æ¥ï¼Œéå¸¸æ„Ÿè°¢ï¼Œå…¨éƒ¨æ”¾åœ¨æ–‡æœ«ï¼Œåœ¨åŸæ–‡ä¸­ä¸å†æŒ‡å‡ºã€‚</p></blockquote><p>æ•°æ®é“¾æ¥ï¼šç™¾åº¦äº‘ï¼š<a href="https://pan.baidu.com/s/1xEB_B8QPzSjuLpPXgnAhJg" target="_blank" rel="noopener">NoMNIST</a>  å¯†ç ï¼šfsks</p><h1 id="P1-é¢„å¤„ç†æ•°æ®"><a href="#P1-é¢„å¤„ç†æ•°æ®" class="headerlink" title="P1:é¢„å¤„ç†æ•°æ®"></a>P1:é¢„å¤„ç†æ•°æ®</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> hashlib</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">from</span> urllib.request <span class="keyword">import</span> urlretrieve</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> PIL <span class="keyword">import</span> Image</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">from</span> sklearn.preprocessing <span class="keyword">import</span> LabelBinarizer</span><br><span class="line"><span class="keyword">from</span> sklearn.utils <span class="keyword">import</span> resample</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">from</span> zipfile <span class="keyword">import</span> ZipFile</span><br></pre></td></tr></table></figure><h2 id="è§£å‹å›¾ç‰‡æ–‡ä»¶"><a href="#è§£å‹å›¾ç‰‡æ–‡ä»¶" class="headerlink" title="è§£å‹å›¾ç‰‡æ–‡ä»¶"></a>è§£å‹å›¾ç‰‡æ–‡ä»¶</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">uncompress_features_labels</span><span class="params">(file)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Uncompress features and labels from a zip file</span></span><br><span class="line"><span class="string">    :param file: The zip file to extract the data from</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    features = []</span><br><span class="line">    labels = []</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> ZipFile(file) <span class="keyword">as</span> zipf:</span><br><span class="line">        <span class="comment"># Progress Bar</span></span><br><span class="line">        filenames_pbar = tqdm(zipf.namelist(), unit=<span class="string">'files'</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Get features and labels from all files</span></span><br><span class="line">        <span class="keyword">for</span> filename <span class="keyword">in</span> filenames_pbar:</span><br><span class="line">            <span class="comment"># Check if the file is a directory</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> filename.endswith(<span class="string">'/'</span>):</span><br><span class="line">                <span class="keyword">with</span> zipf.open(filename) <span class="keyword">as</span> image_file:</span><br><span class="line">                    image = Image.open(image_file)</span><br><span class="line">                    image.load()</span><br><span class="line">                    <span class="comment"># Load image data as 1 dimensional array</span></span><br><span class="line">                    <span class="comment"># We're using float32 to save on memory space</span></span><br><span class="line">                    feature = np.array(image, dtype=np.float32).flatten()</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Get the the letter from the filename.  This is the letter of the image.</span></span><br><span class="line">                label = os.path.split(filename)[<span class="number">1</span>][<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">                features.append(feature)</span><br><span class="line">                labels.append(label)</span><br><span class="line">    <span class="keyword">return</span> np.array(features), np.array(labels)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get the features and labels from the zip files</span></span><br><span class="line">train_features, train_labels = uncompress_features_labels(<span class="string">'notMNIST_train.zip'</span>)</span><br><span class="line">test_features, test_labels = uncompress_features_labels(<span class="string">'notMNIST_test.zip'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Limit the amount of data to work with a docker container</span></span><br><span class="line">docker_size_limit = <span class="number">150000</span></span><br><span class="line">train_features, train_labels = resample(train_features, train_labels, n_samples=docker_size_limit)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set flags for feature engineering.  This will prevent you from skipping an important step.</span></span><br><span class="line">is_features_normal = <span class="keyword">False</span></span><br><span class="line">is_labels_encod = <span class="keyword">False</span></span><br></pre></td></tr></table></figure><figure class="highlight dns"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">100</span>%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| <span class="number">210001/210001</span> [<span class="number">00:54&lt;00:00</span>, <span class="number">3832</span>.<span class="number">78</span>files/s]</span><br><span class="line"><span class="number">100</span>%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| <span class="number">10001/10001</span> [<span class="number">00:03&lt;00:00</span>, <span class="number">3207</span>.<span class="number">15</span>files/s]</span><br></pre></td></tr></table></figure><h2 id="Min-Max-Scaling"><a href="#Min-Max-Scaling" class="headerlink" title="Min-Max Scaling"></a>Min-Max Scaling</h2><p>Implement Min-Max scaling in the <code>normalize_grayscale()</code> function to a range of <code>a=0.1</code> and <code>b=0.9</code>. After scaling, the values of the pixels in the input data should range from 0.1 to 0.9.</p><p>Since the raw notMNIST image data is in <a href="https://en.wikipedia.org/wiki/Grayscale" target="_blank" rel="noopener">grayscale</a>, the current values range from a min of 0 to a max of 255.</p><p>Min-Max Scaling:$Xâ€™=a+{\frac {\left(X-X_{\min }\right)\left(b-a\right)}{X_{\max }-X_{\min }}}$</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">normalize_grayscale</span><span class="params">(image_data)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Normalize the image data with Min-Max scaling to a range of [0.1, 0.9]</span></span><br><span class="line"><span class="string">    :param image_data: The image data to be normalized</span></span><br><span class="line"><span class="string">    :return: Normalized image data</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"> </span><br><span class="line">    a = <span class="number">0.1</span></span><br><span class="line">    b = <span class="number">0.9</span></span><br><span class="line">    max_grayscale = <span class="number">255</span></span><br><span class="line">    min_grayscale = <span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> a+((image_data-min_grayscale))*(b-a)/(max_grayscale-min_grayscale)</span><br></pre></td></tr></table></figure><figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">train_features</span> = normalize_grayscale(train_features)</span><br><span class="line"><span class="attr">test_features</span> = normalize_grayscale(test_features)</span><br></pre></td></tr></table></figure><h2 id="æ ‡ç­¾äºŒå€¼åŒ–"><a href="#æ ‡ç­¾äºŒå€¼åŒ–" class="headerlink" title="æ ‡ç­¾äºŒå€¼åŒ–"></a>æ ‡ç­¾äºŒå€¼åŒ–</h2><p><code>LabelBinarizer()</code>æ˜¯sklearn.preprocessionä¸­ç”¨æ¥å°†éæ•°å€¼ç±»æ ‡ç­¾è½¬æ¢ä¸ºç‹¬çƒ­ç¼–ç å‘é‡çš„å‡½æ•°ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Create the encoder åˆ›å»ºç¼–ç å™¨</span></span><br><span class="line">encoder = LabelBinarizer()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ç¼–ç å™¨æ‰¾åˆ°ç±»åˆ«å¹¶åˆ†é… one-hot å‘é‡</span></span><br><span class="line">encoder.fit(train_labels)</span><br><span class="line"></span><br><span class="line"><span class="comment">#æœ€åæŠŠç›®æ ‡ï¼ˆlablesï¼‰è½¬æ¢æˆç‹¬çƒ­ç¼–ç çš„ï¼ˆone-hot encodedï¼‰å‘é‡</span></span><br><span class="line">train_labels = encoder.transform(train_labels)</span><br><span class="line">test_labels = encoder.transform(test_labels)</span><br></pre></td></tr></table></figure><p>è½¬æ¢æ•°æ®ç±»å‹ï¼Œè¿™æ ·åé¢å…¬å¼ä¸­æ‰å¯ä»¥è¿›è¡Œè¿ç®—ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">train_labels = train_labels.astype(np.float32)</span><br><span class="line">test_labels = test_labels.astype(np.float32)</span><br></pre></td></tr></table></figure><h2 id="éšæœºåˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†"><a href="#éšæœºåˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†" class="headerlink" title="éšæœºåˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†"></a>éšæœºåˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†</h2><p>å¸¸è§å½¢å¼ä¸ºï¼š<br><code>X_train,X_test, y_train, y_test =cross_validation.train_test_split(train_data,train_target,test_size=0.4, random_state=0)</code></p><p><strong>å‚æ•°è§£é‡Šï¼š</strong></p><ul><li>train_dataï¼šæ‰€è¦åˆ’åˆ†çš„æ ·æœ¬ç‰¹å¾é›†</li><li>train_targetï¼šæ‰€è¦åˆ’åˆ†çš„æ ·æœ¬ç»“æœ</li><li>test_sizeï¼šæ ·æœ¬å æ¯”ï¼Œå¦‚æœæ˜¯æ•´æ•°çš„è¯å°±æ˜¯æ ·æœ¬çš„æ•°é‡</li><li>random_stateï¼šæ˜¯éšæœºæ•°çš„ç§å­ã€‚</li></ul><p>éšæœºæ•°ç§å­ï¼šå…¶å®å°±æ˜¯è¯¥ç»„éšæœºæ•°çš„ç¼–å·ï¼Œåœ¨éœ€è¦é‡å¤è¯•éªŒçš„æ—¶å€™ï¼Œä¿è¯å¾—åˆ°ä¸€ç»„ä¸€æ ·çš„éšæœºæ•°ã€‚æ¯”å¦‚ä½ æ¯æ¬¡éƒ½å¡«1ï¼Œå…¶ä»–å‚æ•°ä¸€æ ·çš„æƒ…å†µä¸‹ä½ å¾—åˆ°çš„éšæœºæ•°ç»„æ˜¯ä¸€æ ·çš„ã€‚ä½†å¡«0æˆ–ä¸å¡«ï¼Œæ¯æ¬¡éƒ½ä¼šä¸ä¸€æ ·ã€‚</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Get randomized datasets for training and validation</span></span><br><span class="line">train_features, valid_features, train_labels, valid_labels = train_test_split(</span><br><span class="line">    train_features,</span><br><span class="line">    train_labels,</span><br><span class="line">    test_size=<span class="number">0.05</span>,</span><br><span class="line">    random_state=<span class="number">832289</span>)</span><br></pre></td></tr></table></figure><h2 id="æ‰“åŒ…æ•°æ®æ–¹ä¾¿ä¸‹æ¬¡å–ç”¨"><a href="#æ‰“åŒ…æ•°æ®æ–¹ä¾¿ä¸‹æ¬¡å–ç”¨" class="headerlink" title="æ‰“åŒ…æ•°æ®æ–¹ä¾¿ä¸‹æ¬¡å–ç”¨"></a>æ‰“åŒ…æ•°æ®æ–¹ä¾¿ä¸‹æ¬¡å–ç”¨</h2><p>åºåˆ—åŒ–çš„æ–¹æ³•ä¸º pickle.dump()ï¼Œè¯¥æ–¹æ³•çš„ç›¸å…³å‚æ•°å¦‚ä¸‹ï¼š<br><code>pickle.dump(obj, file, protocol=None,*,fix_imports=True)</code></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># æ–°å»ºpickle_file</span></span><br><span class="line"><span class="comment"># å‚æ•°fileå¿…é¡»æ˜¯ä»¥äºŒè¿›åˆ¶çš„å½¢å¼è¿›è¡Œæ“ä½œ,å³ã€Œwbã€</span></span><br><span class="line">pickle_file = <span class="string">'notMNIST.pickle'</span></span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> os.path.isfile(pickle_file):</span><br><span class="line">    print(<span class="string">'Saving data to pickle file...'</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">with</span> open(<span class="string">'notMNIST.pickle'</span>, <span class="string">'wb'</span>) <span class="keyword">as</span> pfile:</span><br><span class="line">            pickle.dump(</span><br><span class="line">                &#123;</span><br><span class="line">                    <span class="string">'train_dataset'</span>: train_features,</span><br><span class="line">                    <span class="string">'train_labels'</span>: train_labels,</span><br><span class="line">                    <span class="string">'valid_dataset'</span>: valid_features,</span><br><span class="line">                    <span class="string">'valid_labels'</span>: valid_labels,</span><br><span class="line">                    <span class="string">'test_dataset'</span>: test_features,</span><br><span class="line">                    <span class="string">'test_labels'</span>: test_labels,</span><br><span class="line">                &#125;,</span><br><span class="line">                pfile, pickle.HIGHEST_PROTOCOL)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        print(<span class="string">'Unable to save data to'</span>, pickle_file, <span class="string">':'</span>, e)</span><br><span class="line">        <span class="keyword">raise</span></span><br></pre></td></tr></table></figure><h1 id="P2-ä»é¢„å¤„ç†å¥½çš„pickleä¸­è¯»å–æ•°æ®"><a href="#P2-ä»é¢„å¤„ç†å¥½çš„pickleä¸­è¯»å–æ•°æ®" class="headerlink" title="P2:ä»é¢„å¤„ç†å¥½çš„pickleä¸­è¯»å–æ•°æ®"></a>P2:ä»é¢„å¤„ç†å¥½çš„pickleä¸­è¯»å–æ•°æ®</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">%matplotlib inline</span><br><span class="line"></span><br><span class="line"><span class="comment"># Load the modules</span></span><br><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tqdm <span class="keyword">import</span> tqdm</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="comment"># Reload the data</span></span><br><span class="line">pickle_file = <span class="string">'notMNIST.pickle'</span></span><br><span class="line"><span class="keyword">with</span> open(pickle_file, <span class="string">'rb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">  pickle_data = pickle.load(f)</span><br><span class="line">  train_features = pickle_data[<span class="string">'train_dataset'</span>]</span><br><span class="line">  train_labels = pickle_data[<span class="string">'train_labels'</span>]</span><br><span class="line">  valid_features = pickle_data[<span class="string">'valid_dataset'</span>]</span><br><span class="line">  valid_labels = pickle_data[<span class="string">'valid_labels'</span>]</span><br><span class="line">  test_features = pickle_data[<span class="string">'test_dataset'</span>]</span><br><span class="line">  test_labels = pickle_data[<span class="string">'test_labels'</span>]</span><br><span class="line">  <span class="keyword">del</span> pickle_data  <span class="comment"># Free up memory</span></span><br></pre></td></tr></table></figure><pre><code>C:\Users\10677\Anaconda3\envs\keras\lib\site-packages\h5py\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.  from ._conv import register_converters as _register_converters</code></pre><h1 id="ä½¿ç”¨TFåˆ›å»ºå•å±‚ç¥ç»ç½‘ç»œ"><a href="#ä½¿ç”¨TFåˆ›å»ºå•å±‚ç¥ç»ç½‘ç»œ" class="headerlink" title="ä½¿ç”¨TFåˆ›å»ºå•å±‚ç¥ç»ç½‘ç»œ"></a>ä½¿ç”¨TFåˆ›å»ºå•å±‚ç¥ç»ç½‘ç»œ</h1><p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬ä½¿ç”¨<code>TensorFlow</code>åˆ›å»ºä¸€ä¸ªåªæœ‰ä¸€ä¸ªè¾“å…¥å±‚å’Œè¾“å‡ºå±‚çš„ç¥ç»ç½‘ç»œï¼Œæ¿€æ´»å‡½æ•°ä¸º<code>softmax</code>ã€‚<br>åœ¨<code>TensorFlow</code>ä¸­ï¼Œæ•°æ®ä¸æ˜¯ä»¥æ•´æ•°ã€æµ®ç‚¹æ•°æˆ–å­—ç¬¦ä¸²çš„å½¢å¼å­˜å‚¨çš„ï¼Œè€Œæ˜¯ä»¥<code>tensor</code>å¯¹è±¡çš„å½¢å¼è¢«å­˜å‚¨çš„ã€‚</p><p>åœ¨<code>tensor</code>ä¸­ä¼ é€’å€¼æœ‰ä¸¤ç§æ–¹æ³•ï¼š</p><ul><li>ä½¿ç”¨<code>tf.constant()</code>ï¼Œä¼ å…¥å˜é‡ï¼Œä½†æ˜¯ä¼ å…¥ä¹‹åå°±ä¸å¯å˜äº†</li><li>å¦‚æœè¦ä½¿æ•°æ®å¯å˜ï¼Œç»“åˆ<code>tf.placeholder()</code>å’Œ<code>tf.feed_dict</code>æ¥è¾“å…¥</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># All the pixels in the image (28 * 28 = 784)</span></span><br><span class="line">features_count = <span class="number">784</span></span><br><span class="line"><span class="comment"># All the labels ("A,B...J")</span></span><br><span class="line">labels_count = <span class="number">10</span></span><br><span class="line"></span><br><span class="line">features = tf.placeholder(tf.float32)</span><br><span class="line">labels = tf.placeholder(tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Set the weights and biases tensors</span></span><br><span class="line"><span class="comment"># tf.truncated_normal:ç”Ÿæˆæ­£æ€åˆ†å¸ƒçš„éšæœºå€¼</span></span><br><span class="line"><span class="comment"># weightså·²ç»éšæœºåŒ–ï¼Œbiaseså°±ä¸å¿…éšæœºï¼Œç®€åŒ–ä¸º0å³å¯</span></span><br><span class="line"></span><br><span class="line">weights = tf.Variable(tf.truncated_normal((features_count,labels_count)))</span><br><span class="line">biases = tf.Variable(tf.zeros(labels_count))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Feed dicts for training, validation, and test session</span></span><br><span class="line">train_feed_dict = &#123;features: train_features, labels: train_labels&#125;</span><br><span class="line">valid_feed_dict = &#123;features: valid_features, labels: valid_labels&#125;</span><br><span class="line">test_feed_dict = &#123;features: test_features, labels: test_labels&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># Linear Function WX + b</span></span><br><span class="line">logits = tf.matmul(features, weights) + biases</span><br><span class="line"></span><br><span class="line">prediction = tf.nn.softmax(logits)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Cross entropy</span></span><br><span class="line">cross_entropy = -tf.reduce_sum(labels * tf.log(prediction), reduction_indices=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Training loss</span></span><br><span class="line">loss = tf.reduce_mean(cross_entropy)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create an operation that initializes all variables</span></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Test Cases</span></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> session:</span><br><span class="line">    session.run(init)</span><br><span class="line">    session.run(loss, feed_dict=train_feed_dict)</span><br><span class="line">    session.run(loss, feed_dict=valid_feed_dict)</span><br><span class="line">    session.run(loss, feed_dict=test_feed_dict)</span><br><span class="line">    biases_data = session.run(biases)</span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">is_correct_prediction = tf.equal(tf.argmax(prediction, <span class="number">1</span>), tf.argmax(labels, <span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(is_correct_prediction, tf.float32))</span><br></pre></td></tr></table></figure><h1 id="P3-è®­ç»ƒç¥ç»ç½‘ç»œ"><a href="#P3-è®­ç»ƒç¥ç»ç½‘ç»œ" class="headerlink" title="P3:è®­ç»ƒç¥ç»ç½‘ç»œ"></a>P3:è®­ç»ƒç¥ç»ç½‘ç»œ</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Change if you have memory restrictions</span></span><br><span class="line">batch_size = <span class="number">128</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Find the best parameters for each configuration</span></span><br><span class="line">epochs =  <span class="number">4</span></span><br><span class="line">learning_rate = <span class="number">0.2</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># Gradient Descent</span></span><br><span class="line"><span class="comment"># ä½¿ç”¨æ¢¯åº¦ä¸‹é™è¿›è¡Œè®­ç»ƒ</span></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)    </span><br><span class="line"></span><br><span class="line"><span class="comment"># The accuracy measured against the validation set</span></span><br><span class="line">validation_accuracy = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Measurements use for graphing loss and accuracy</span></span><br><span class="line">log_batch_step = <span class="number">50</span></span><br><span class="line">batches = []</span><br><span class="line">loss_batch = []</span><br><span class="line">train_acc_batch = []</span><br><span class="line">valid_acc_batch = []</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> session:</span><br><span class="line">    session.run(init)</span><br><span class="line">    batch_count = int(math.ceil(len(train_features)/batch_size))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch_i <span class="keyword">in</span> range(epochs):</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Progress bar</span></span><br><span class="line">        batches_pbar = tqdm(range(batch_count), desc=<span class="string">'Epoch &#123;:&gt;2&#125;/&#123;&#125;'</span>.format(epoch_i+<span class="number">1</span>, epochs), unit=<span class="string">'batches'</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># The training cycle</span></span><br><span class="line">        <span class="keyword">for</span> batch_i <span class="keyword">in</span> batches_pbar:</span><br><span class="line">            <span class="comment"># Get a batch of training features and labels</span></span><br><span class="line">            batch_start = batch_i*batch_size</span><br><span class="line">            batch_features = train_features[batch_start:batch_start + batch_size]</span><br><span class="line">            batch_labels = train_labels[batch_start:batch_start + batch_size]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Run optimizer and get loss</span></span><br><span class="line">            _, l = session.run(</span><br><span class="line">                [optimizer, loss],</span><br><span class="line">                feed_dict=&#123;features: batch_features, labels: batch_labels&#125;)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Log every 50 batches</span></span><br><span class="line">            <span class="keyword">if</span> <span class="keyword">not</span> batch_i % log_batch_step:</span><br><span class="line">                <span class="comment"># Calculate Training and Validation accuracy</span></span><br><span class="line">                training_accuracy = session.run(accuracy, feed_dict=train_feed_dict)</span><br><span class="line">                validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)</span><br><span class="line"></span><br><span class="line">                <span class="comment"># Log batches</span></span><br><span class="line">                previous_batch = batches[<span class="number">-1</span>] <span class="keyword">if</span> batches <span class="keyword">else</span> <span class="number">0</span></span><br><span class="line">                batches.append(log_batch_step + previous_batch)</span><br><span class="line">                loss_batch.append(l)</span><br><span class="line">                train_acc_batch.append(training_accuracy)</span><br><span class="line">                valid_acc_batch.append(validation_accuracy)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Check accuracy against Validation data</span></span><br><span class="line">        validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)</span><br><span class="line"></span><br><span class="line">loss_plot = plt.subplot(<span class="number">211</span>)</span><br><span class="line">loss_plot.set_title(<span class="string">'Loss'</span>)</span><br><span class="line">loss_plot.plot(batches, loss_batch, <span class="string">'g'</span>)</span><br><span class="line">loss_plot.set_xlim([batches[<span class="number">0</span>], batches[<span class="number">-1</span>]])</span><br><span class="line">acc_plot = plt.subplot(<span class="number">212</span>)</span><br><span class="line">acc_plot.set_title(<span class="string">'Accuracy'</span>)</span><br><span class="line">acc_plot.plot(batches, train_acc_batch, <span class="string">'r'</span>, label=<span class="string">'Training Accuracy'</span>)</span><br><span class="line">acc_plot.plot(batches, valid_acc_batch, <span class="string">'x'</span>, label=<span class="string">'Validation Accuracy'</span>)</span><br><span class="line">acc_plot.set_ylim([<span class="number">0</span>, <span class="number">1.0</span>])</span><br><span class="line">acc_plot.set_xlim([batches[<span class="number">0</span>], batches[<span class="number">-1</span>]])</span><br><span class="line">acc_plot.legend(loc=<span class="number">4</span>)</span><br><span class="line">plt.tight_layout()</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line">print(<span class="string">'Validation accuracy at &#123;&#125;'</span>.format(validation_accuracy))</span><br></pre></td></tr></table></figure><pre><code>Epoch  1/4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1114/1114 [00:11&lt;00:00, 101.27batches/s]Epoch  2/4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1114/1114 [00:10&lt;00:00, 101.99batches/s]Epoch  3/4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1114/1114 [00:10&lt;00:00, 101.38batches/s]Epoch  4/4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1114/1114 [00:12&lt;00:00, 92.55batches/s]</code></pre><p><img src="http://ohj9e0ect.bkt.clouddn.com/blog/180903/dAh5BG2iKD.png?imageslim" alt="mark"></p><pre><code>Validation accuracy at 0.7662666440010071</code></pre><h1 id="P4-æ£€æµ‹"><a href="#P4-æ£€æµ‹" class="headerlink" title="P4:æ£€æµ‹"></a>P4:æ£€æµ‹</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">test_accuracy = <span class="number">0.0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> session:</span><br><span class="line">    </span><br><span class="line">    session.run(init)</span><br><span class="line">    batch_count = int(math.ceil(len(train_features)/batch_size))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> epoch_i <span class="keyword">in</span> range(epochs):</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># Progress bar</span></span><br><span class="line">        batches_pbar = tqdm(range(batch_count), desc=<span class="string">'Epoch &#123;:&gt;2&#125;/&#123;&#125;'</span>.format(epoch_i+<span class="number">1</span>, epochs), unit=<span class="string">'batches'</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># The training cycle</span></span><br><span class="line">        <span class="keyword">for</span> batch_i <span class="keyword">in</span> batches_pbar:</span><br><span class="line">            <span class="comment"># Get a batch of training features and labels</span></span><br><span class="line">            batch_start = batch_i*batch_size</span><br><span class="line">            batch_features = train_features[batch_start:batch_start + batch_size]</span><br><span class="line">            batch_labels = train_labels[batch_start:batch_start + batch_size]</span><br><span class="line"></span><br><span class="line">            <span class="comment"># Run optimizer</span></span><br><span class="line">            _ = session.run(optimizer, feed_dict=&#123;features: batch_features, labels: batch_labels&#125;)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Check accuracy against Test data</span></span><br><span class="line">        test_accuracy = session.run(accuracy, feed_dict=test_feed_dict)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">assert</span> test_accuracy &gt;= <span class="number">0.80</span>, <span class="string">'Test accuracy at &#123;&#125;, should be equal to or greater than 0.80'</span>.format(test_accuracy)</span><br><span class="line">print(<span class="string">'Nice Job! Test Accuracy is &#123;&#125;'</span>.format(test_accuracy))</span><br></pre></td></tr></table></figure><pre><code>Epoch  1/4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1114/1114 [00:01&lt;00:00, 588.57batches/s]Epoch  2/4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1114/1114 [00:01&lt;00:00, 634.64batches/s]Epoch  3/4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1114/1114 [00:01&lt;00:00, 633.74batches/s]Epoch  4/4: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1114/1114 [00:01&lt;00:00, 638.60batches/s]Nice Job! Test Accuracy is 0.8468999862670898</code></pre><h2 id="å‚è€ƒé“¾æ¥ï¼š"><a href="#å‚è€ƒé“¾æ¥ï¼š" class="headerlink" title="å‚è€ƒé“¾æ¥ï¼š"></a>å‚è€ƒé“¾æ¥ï¼š</h2><ul><li><a href="https://lorexxar.cn/2016/07/21/python-tqdm/" target="_blank" rel="noopener">python tqdmæ¨¡å—åˆ†æ</a></li><li><a href="https://blog.csdn.net/CherDW/article/details/54881167" target="_blank" rel="noopener">Sklearn-train_test_splitéšæœºåˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†</a></li><li><a href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.flatten.html" target="_blank" rel="noopener">numpy_ndarray.flatten</a></li><li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html" target="_blank" rel="noopener">sklearn.LabelBinarizer</a></li></ul>]]></content>
      
      
      
        <tags>
            
            <tag> tensorflow </tag>
            
            <tag> æ·±åº¦å­¦ä¹  </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>åŒ—å¤§åˆ†è¯æ–¹æ¡ˆè§£è¯»åŠé¢—ç²’åº¦åˆ†è¯æ–¹æ¡ˆ</title>
      <link href="/passages/%E9%A2%97%E7%B2%92%E5%BA%A6%E5%88%86%E8%AF%8D%E8%B0%83%E7%A0%94/"/>
      <url>/passages/%E9%A2%97%E7%B2%92%E5%BA%A6%E5%88%86%E8%AF%8D%E8%B0%83%E7%A0%94/</url>
      
        <content type="html"><![CDATA[<h1 id="ä¸€ã€è°ƒç ”èµ„æ–™"><a href="#ä¸€ã€è°ƒç ”èµ„æ–™" class="headerlink" title="ä¸€ã€è°ƒç ”èµ„æ–™"></a>ä¸€ã€è°ƒç ”èµ„æ–™</h1><ol><li><a href="https://www.jianguoyun.com/p/DXc5BJwQhaz8Bhio1m4" target="_blank" rel="noopener">åŒ—å¤§ç°ä»£æ±‰è¯­è¯­æ–™åº“åŸºæœ¬åŠ å·¥è§„èŒƒ</a></li><li><a href="https://www.jianguoyun.com/p/DQfbcd4Qhaz8BhjF1m4" target="_blank" rel="noopener">è®¡ç®—æ‰€æ±‰è¯­è¯æ€§æ ‡æ³¨é›†</a></li><li><a href="http://www.hankcs.com/nlp/corpus/several-revenue-segmentation-system-used-set-of-source-tagging.html" target="_blank" rel="noopener">å‡ ä¸ªå¼€æºåˆ†è¯ç³»ç»Ÿæ‰€ä½¿ç”¨æ ‡æ³¨é›†çš„æ¥æº</a></li><li><a href="https://www.jianguoyun.com/p/DT74b1kQhaz8Bhje1m4" target="_blank" rel="noopener">æµ·é‡ä¸­æ–‡æ™ºèƒ½åˆ†è¯æ¥å£æ‰‹å†Œ</a></li><li><a href="https://patents.google.com/patent/CN102479191B" target="_blank" rel="noopener">é˜¿é‡Œå¤šç²’åº¦åˆ†è¯ä¸“åˆ©</a></li><li><a href="https://patents.google.com/patent/CN101246472A/zh" target="_blank" rel="noopener">è…¾è®¯å¤šç²’åº¦åˆ†è¯ä¸“åˆ©</a></li><li><a href="https://patents.google.com/patent/CN103324626A/zh" target="_blank" rel="noopener">ç™¾åº¦å¤šç²’åº¦åˆ†è¯ä¸“åˆ©</a></li><li><a href="http://www.cnblogs.com/eaglet/archive/2008/05/27/1208423.html" target="_blank" rel="noopener">KTDictSeg åˆ†è¯ç»„ä»¶1.3ç‰ˆæœ¬ éƒ¨åˆ†ç®—æ³•è®¨è®º â€” åˆ†è¯ç²’åº¦</a></li></ol><h1 id="äºŒã€è°ƒç ”ç›®çš„"><a href="#äºŒã€è°ƒç ”ç›®çš„" class="headerlink" title="äºŒã€è°ƒç ”ç›®çš„"></a>äºŒã€è°ƒç ”ç›®çš„</h1><p>åˆ†è¯å•ä½ä¸åŒäºè¯­è¨€å­¦ä¸­çš„â€œè¯â€ï¼Œä¸åŒçš„ç®—æ³•ä¸‹çš„åˆ†è¯ç»“æœåƒå·®ä¸‡åˆ«ï¼Œæœ‰çš„åˆ†å‡ºçš„æ˜¯è¯­è¨€å­¦æ„ä¹‰ä¸Šçš„è¯ï¼Œè€Œæœ‰çš„åˆ†å‡ºçš„æ˜¯è¯­è¨€å­¦æ„ä¹‰ä¸Šçš„â€œçŸ­è¯­â€ï¼ˆæˆ–è€…è¯´â€œè¯ç»„â€ï¼‰å› æ­¤ï¼Œæˆ‘ä»¬å¸Œæœ›å¯»æ‰¾ä¸€ä¸ªå¯ç†è§£çš„ç»Ÿä¸€çš„ç²’åº¦æ ‡å‡†ï¼Œè€Œè¿™ä¸ªç²’åº¦æ ‡å‡†èƒ½å¤Ÿå®ç°å¯¹ä¸åŒåˆ†è¯ä»»åŠ¡çš„ä¸åŒå±‚æ¬¡çš„åˆ†è¯ã€‚ä¸ºè¯å®å¤šé¢—ç²’åº¦çš„åˆ†è¯æ ‡æ³¨ç¡®å®èƒ½æé«˜ç‰¹å®šçš„åˆ†è¯ä»»åŠ¡çš„å‡†ç¡®ç‡ï¼Œæˆ‘ä»¬è¿›è¡Œäº†è¿™æ ·çš„å‰æœŸè°ƒç ”ã€‚<br>é€šè¿‡æœé›†èµ„æ–™ï¼Œæˆ‘ä»¬ä»¥åŒ—å¤§æ–¹æ¡ˆä¸ºè“æœ¬ï¼Œä»¥ä¸€å®šçš„è¯­è¨€å­¦çŸ¥è¯†ä¸ºåŸºç¡€ï¼Œå¯¹åˆ†è¯é¢—ç²’è¿›è¡Œä¸åŒç²’åº¦çš„åˆ’åˆ†ã€‚<br>é¦–å…ˆå¯¹åŒ—å¤§åˆ†è¯æ–¹æ¡ˆè¿›è¡Œè§£è¯»ï¼Œç„¶åå†é˜é‡Šæˆ‘å¯¹åˆ†è¯ç²’åº¦åˆæ­¥çš„æ„å»ºæƒ³æ³•ã€‚</p><p>æ³¨ï¼šé¢—ç²’åº¦æ–¹æ¡ˆåªè€ƒè™‘åˆ†è¯é—®é¢˜ï¼Œä¸è€ƒè™‘è¯æ€§æ ‡æ³¨ã€‚</p><h1 id="ä¸‰ã€åŒ—å¤§åˆ†è¯æ–¹æ¡ˆè®²è§£"><a href="#ä¸‰ã€åŒ—å¤§åˆ†è¯æ–¹æ¡ˆè®²è§£" class="headerlink" title="ä¸‰ã€åŒ—å¤§åˆ†è¯æ–¹æ¡ˆè®²è§£"></a>ä¸‰ã€åŒ—å¤§åˆ†è¯æ–¹æ¡ˆè®²è§£</h1><h2 id="1-åˆ†è¯å•ä½çš„æ¦‚å¿µç•Œå®š"><a href="#1-åˆ†è¯å•ä½çš„æ¦‚å¿µç•Œå®š" class="headerlink" title="1. åˆ†è¯å•ä½çš„æ¦‚å¿µç•Œå®š"></a>1. åˆ†è¯å•ä½çš„æ¦‚å¿µç•Œå®š</h2><p><code>åˆ†è¯å•ä½</code>ï¼Œâ€œæŒ‡ä¿¡æ¯å¤„ç†ä¸­ä½¿ç”¨çš„ã€å…·æœ‰ç¡®å®šçš„è¯­ä¹‰å’Œè¯­æ³•åŠŸèƒ½çš„åŸºæœ¬å•ä½â€ï¼Œè¯¥æ¦‚å¿µæ˜ç¡®äº†å…¶ä½¿ç”¨çš„ç‰¹å®šç¯å¢ƒâ€”â€”â€œä¿¡æ¯å¤„ç†ä»»åŠ¡â€ï¼Œä»¥åŠå…¶è¯­ä¹‰å’Œè¯­æ³•åŠŸèƒ½æ˜ç¡®çš„ç‰¹ç‚¹ã€‚</p><p>åŸºäºè¿™æ ·çš„æ¦‚å¿µåˆ’åˆ†ï¼ŒåŒ—å¤§æ–¹æ¡ˆè®¤å®šçš„åˆ†è¯å•ä½é‡Œä¸ä»…åŒ…æ‹¬äº†è¯ï¼Œè¿˜â€œåŒ…æ‹¬äº†ä¸€éƒ¨åˆ†ç»“åˆç´§å¯†ã€ä½¿ç”¨ç¨³å®šçš„è¯ç»„â€ï¼Œå¹¶ä¸”â€œåœ¨æŸäº›ç‰¹æ®Šæƒ…å†µå­¤ç«‹çš„è¯­ç´ æˆ–éè¯­ç´ å­—â€ã€‚</p><p>äº‹å®ä¸Šï¼Œæˆ‘ä»¬æ’‡å¼€åŒ—å¤§æ–¹æ¡ˆæ¥çœ‹è¯è¿™ä¸ªæ•´ä½“ï¼Œæ ¹æ®æœ±å¾·ç†™å…ˆç”Ÿçš„åˆ’åˆ†ï¼Œå¯ä»¥åˆ†ä¸ºå¯ç©·å°½çš„è™šè¯ç±»å’Œä¸å¯ç©·å°½çš„å®è¯ç±»ã€‚è™šè¯ç±»ï¼Œä¸¾ä¾‹æ¥è¯´ï¼ŒåŒ…æ‹¬è¿è¯ã€è¯­æ°”è¯ã€ä»‹è¯ç­‰ï¼Œè¿™ç±»è¯å¯ä»¥åœ¨è¯­æ³•è¯å…¸ä¸­è¢«æšä¸¾å‡ºæ¥ï¼Œå› æ­¤åœ¨è¿›è¡Œåˆ†è¯æ—¶éš¾åº¦è¾ƒå°ã€‚å› æ­¤ï¼Œåˆ†è¯çš„å›°éš¾å¸¸å¸¸å‡ºç°åœ¨å®è¯çš„åˆ‡åˆ†ä¸Šã€‚</p><p>ç»“åˆåŒ—å¤§æ–¹æ¡ˆçš„åˆ’åˆ†ï¼Œæˆ‘è®¤ä¸ºå¯¹å®è¯åºåˆ—è¿›è¡Œåˆ’åˆ†æ—¶ï¼Œä¸€èˆ¬å¯ä»¥éµç…§ä»¥ä¸‹åŸåˆ™ï¼š</p><p>ï¼ˆ1ï¼‰ä¾æ®è¯­æ³•è¯å…¸æ¥åˆ’åˆ†ï¼Œå¦‚æœè¯­æ³•è¯å…¸ä¸­è¿›è¡Œè§„å®šï¼Œé‚£ä¹ˆå°±ä¸åšåˆ’åˆ†ã€‚è¯­è¨€æ˜¯çº¦å®šä¿—æˆçš„äº§ç‰©ï¼Œå½“æŸä¸ªè¯è¯­ç»„åˆè¢«å¹¿æ³›è€Œç¨³å®šåœ°ä½¿ç”¨æ—¶ï¼Œé‚£ä¹ˆç¤¾ä¼šå›¢ä½“ä¾¿ä¼šæ¥å—è¿™æ ·çš„ä¸€ä¸ªâ€œæ–°è¯â€ï¼Œå› æ­¤è¿™æ ·çš„ä¸€ä¸ªè¯è¯­ç»„åˆä¹Ÿå¯ä»¥è¢«è§†ä½œæ˜¯ä¸€ä¸ªåˆ†è¯å•ä½ã€‚è€Œåˆ¤æ–­ç¤¾ä¼šå›¢ä½“æ˜¯å¦å·²ç»æ¥å—è¿™ä¸€è¯­è¨€ç°è±¡å¾ˆæ˜¾æ€§çš„ä¸€å¤§æ ‡å¿—ä¾¿æ˜¯è¯å…¸æ”¶å½•äº†è¯¥è¯æ¡ã€‚é‚£ä¹ˆé—®é¢˜å°±è½¬å˜ä¸ºï¼Œä»€ä¹ˆæ ·çš„è¯å…¸å¯ä»¥æˆä¸ºå¯ä¾›åˆ’åˆ†çš„è¯­æ³•è¯å…¸ã€‚</p><p>ï¼ˆ2ï¼‰è€ƒè™‘åˆ‡åˆ†åºåˆ—çš„éŸ³èŠ‚ç»„åˆã€‚æ±‰è¯­åœ¨å‘å±•è¿‡ç¨‹ä¸­ç»å†äº†ä¸€ä¸ªä»å•éŸ³èŠ‚å‘åŒéŸ³èŠ‚çš„å‘å±•è¿‡ç¨‹ã€‚è™½ç„¶ç°ä»£æ±‰è¯­ä»¥åŒéŸ³èŠ‚ä¸ºä¸»è¦çš„æˆè¯å•ä½ï¼Œä½†æ˜¯å¤ä»£æ±‰è¯­ä¸­çš„ä¸€äº›å•éŸ³èŠ‚è¯ä¾ç„¶æ®‹å­˜åœ¨ç°ä»£æ±‰è¯­ä¸­ï¼Œå¹¶ä¸”åœ¨ä¸€äº›ç‰¹æ®Šè¯­ä½“ä¸­è¿˜å¹¿æ³›åœ°å­˜åœ¨ç€ã€‚å› æ­¤ï¼Œå¯¹äºé‚£äº›å•éŸ³èŠ‚æˆè¯çš„å•ä½åœ¨æ ‡æ³¨æ—¶è¦æ ¼å¤–æ³¨æ„æ ‡è®°å‡ºæ¥ï¼Œè€Œå¤„ç†å¤šéŸ³èŠ‚åºåˆ—æ—¶ï¼Œåˆ™è¦å°½é‡ä¿è¯åˆ†è¯ç»“æœä»¥åŒéŸ³èŠ‚ä¸ºä¸€ä¸ªå•ä½ã€‚</p><p>ï¼ˆ3ï¼‰è€ƒè™‘åˆ°è¯ä¹‰ä¸è¯­ç´ ç»“åˆä¹‰ã€‚æˆ‘ä»¬æ‰€è®¤å®šçš„åˆ†è¯å•ä½ï¼Œå®ƒçš„è¯ä¹‰æ˜¯å‡åˆè€Œæˆçš„ï¼Œè€Œä¸æ˜¯ä¸¤ä¸ªè¯­ç´ çš„æ„ä¹‰ç®€å•çš„ç›¸åŠ ã€‚å› æ­¤ï¼Œå¦‚æœä¸€ä¸ªåˆ‡åˆ†å•ä½çš„è¯­ä¹‰æ˜¯å…¶åˆ‡åˆ†å•ä½æ„ä¹‰çš„ç®€å•ç›¸åŠ ï¼Œé‚£ä¹ˆå°±è¦å¯¹å…¶è¿›è¡Œåˆ‡åˆ†ã€‚è€Œåˆ¤å®šæ˜¯å¦æ˜¯è¯ä¹‰ç®€å•çš„ç›¸åŠ çš„æ–¹æ³•ä¸»è¦æœ‰â€œçš„â€æ’å…¥æ³•å’Œæ›¿æ¢æ³•ä¸¤ç§ï¼Œè¿™åœ¨åé¢å…·ä½“çš„è®²è§£ä¸­ä¼šè¿›è¡Œé˜é‡Šã€‚</p><p>ï¼ˆ4ï¼‰è¦è€ƒè™‘åˆ°åˆ‡åˆ†çš„ç»æµæ€§ã€‚åŒ—å¤§æ–¹æ¡ˆæ˜¯åˆ‡åˆ†å’Œæ ‡æ³¨åŒæ—¶è¿›è¡Œï¼Œä¸ºäº†ä¿è¯æ ‡æ³¨ç¬¦å·ä½¿ç”¨çš„ç»æµæ€§ï¼Œæ–¹æ¡ˆè¦æ±‚ï¼Œè¦ä¿è¯åˆ‡åˆ†å‡ºæ¥çš„å•ä½å°½é‡å°‘çš„æ˜¯æ— æ³•ç‹¬ç«‹æˆè¯çš„è¯­ç´ ã€‚å› æ­¤ï¼Œå¯¹äºä¸€ä¸ªåˆ‡åˆ†åºåˆ—ï¼Œå¦‚æœæˆ‘ä»¬åˆ‡åˆ†åå¤šå‡ºäº†æ— æ³•ç‹¬ç«‹æˆè¯çš„è¯­ç´ ï¼Œæ¯”å¦‚è¯´å‰æ¥æˆåˆ†ã€åæ¥æˆåˆ†ç­‰ï¼Œæˆ‘ä»¬å°½å¯èƒ½åœ°ä¸å»åˆ‡åˆ†å®ƒã€‚</p><h2 id="2-åˆ†è¯å®é™…æƒ…å†µä¸­çš„åº”ç”¨"><a href="#2-åˆ†è¯å®é™…æƒ…å†µä¸­çš„åº”ç”¨" class="headerlink" title="2.åˆ†è¯å®é™…æƒ…å†µä¸­çš„åº”ç”¨"></a>2.åˆ†è¯å®é™…æƒ…å†µä¸­çš„åº”ç”¨</h2><p>æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†å¯¹åˆ†è¯æ–¹æ¡ˆçš„ç¬¬å››ç« ã€ç¬¬äº”ç« ç»“åˆæˆ‘ä»¬æ€»ç»“å‡ºæ¥çš„è§„åˆ™è¿›è¡Œç²¾ç®€å¼çš„è¯´æ˜ã€‚</p><p>ï¼ˆ1ï¼‰äººå</p><p>å¯¹äºäººåçš„åˆ‡åˆ†ï¼Œæ–¹æ¡ˆç»™å‡ºçš„åˆ‡åˆ†æ ‡å‡†æ˜¯å§“å’Œååˆ‡åˆ†å¼€ã€‚è€Œå¯¹äºå…¶ä»–ç§°å‘¼æ˜¯å¦åˆ‡åˆ†ï¼Œå¯ä»¥ç”¨è¯­ä¹‰è§„åˆ™æ¥è§£é‡Šã€‚ç¬¬äºŒæ¡è§„åˆ™ï¼šå§“ååçš„èŒåŠ¡ã€èŒç§°æˆ–ç§°å‘¼è¦åˆ†å¼€ã€‚ç¬¬å››æ¡è§„åˆ™ï¼šå¸¦æ˜æ˜¾æ’è¡Œçš„äº²å±ç§°è°“è¦åˆ‡åˆ†å¼€ã€‚è¿™ä¸¤æ¡è§„åˆ™æ˜¯å› ä¸ºç»„æˆçš„åˆ‡åˆ†åºåˆ—çš„æ„æ€å³æ˜¯å„ç»„æˆæˆåˆ†çš„ç»„åˆä¹‰ï¼Œå› æ­¤è¦åˆ‡åˆ†ã€‚è€Œç¬¬ä¸‰æ¡è§„åˆ™ï¼šå¯¹äººçš„ç®€ç§°ã€å°Šç§°è‹¥ä¸ºä¸¤ä¸ªå­—ï¼Œåˆ™åˆä¸ºä¸€ä¸ªåˆ‡åˆ†å•ä½ã€‚ä¸ä»…æ˜¯å› ä¸ºè¿™äº›åˆ‡åˆ†åºåˆ—çš„å«ä¹‰ä¸æ˜¯å…¶ç»„æˆæˆåˆ†çš„ç»„åˆä¹‰ï¼Œè‡³å°‘æœ‰è¡¨ç¤ºå°Šæ•¬çš„ç¤¾ä¼šå«ä¹‰ï¼Œè¿˜æ˜¯å› ä¸ºå¦‚æœåˆ‡åˆ†ï¼Œä¼šå¤šå‡ºæ— æ³•ç‹¬ç«‹æˆè¯çš„è¯­ç´ ï¼Œå› æ­¤æŠŠè¿™äº›åŒéŸ³èŠ‚ä½œä¸ºä¸€ä¸ªåˆ‡åˆ†å•ä½ã€‚è€Œå¯¹äºå¤–å›½äººåå’Œç¬”åã€è‘—åäººåï¼Œæˆ‘ä»¬ä¸åšåˆ‡åˆ†ï¼Œä¸€æ˜¯å› ä¸ºè¿™ç§å‘½åæ˜¯éšæ„çš„ï¼Œåˆ‡åˆ†ä¸‹æ¥çš„æ„ä¹‰ä¸å¤§ï¼›äºŒæ˜¯å› ä¸ºè‘—åäººåæ˜¯åœ¨è¯­æ³•è¯å…¸ä¸­å°±è§„å®šäº†çš„å†…å®¹ã€‚</p><p>ï¼ˆ2ï¼‰åœ°å</p><p>å¤§éƒ¨åˆ†åœ°åéƒ½æ˜¯åœ¨è¯­æ³•è¯å…¸ä¸­äº‹å…ˆè§„å®šäº†çš„ï¼Œé™¤æ­¤ä»¥å¤–çš„åˆ‡åˆ†åŸåˆ™ä¸»è¦æ˜¯å’ŒéŸ³èŠ‚æœ‰å…³ï¼Œå¦‚æœåœ°ååæ¥çš„æ˜¯å•éŸ³èŠ‚è¯­ç´ ï¼Œåˆ™ä¸åˆ‡åˆ†ï¼›å¦‚æœæ¥çš„æ˜¯åŒéŸ³èŠ‚æˆ–å¤šéŸ³èŠ‚è¯­ç´ ï¼Œåˆ™è¦è¿›è¡Œåˆ‡åˆ†ã€‚</p><p>ï¼ˆ3ï¼‰å›¢ä½“ã€æœºæ„ã€ç»„ç»‡çš„ä¸“æœ‰åç§°</p><p>å¯¹äºå›¢ä½“ã€æœºæ„ã€ç»„ç»‡çš„ä¸“æœ‰åç§°ï¼Œå¦‚æœå®ƒä»¬è¢«è¯­æ³•è¯å…¸æ”¶å½•ï¼Œé‚£ä¹ˆè‚¯å®šä¸åˆ‡åˆ†ï¼Œå¦‚æœæ²¡æœ‰ï¼Œåˆ™è¦è¿›è¡Œåˆ‡åˆ†ã€‚ï¼ˆå¦‚æœæ‰¾ä¸åˆ°è¿™æ ·åˆé€‚çš„è¯å…¸ï¼Œä¸€ä¸ªPLAN Bçš„å»ºè®®ï¼šæŒ‰ç…§æ™®é€šè¯ç»„åˆ‡åˆ†ï¼Œå†ä¸Šæ¸¸ä»»åŠ¡ä¸­å†è¯†åˆ«å‡ºæ¥ï¼‰</p><p>ï¼ˆ4ï¼‰é™¤äººåã€å›½åã€åœ°åã€å›¢ä½“ã€æœºæ„ã€ç»„ç»‡ä»¥å¤–çš„å…¶ä»–ä¸“å</p><p>é¦–å…ˆï¼Œæˆ‘ä»¬è¿˜æ˜¯è¦è€ƒè™‘å…¶æ˜¯å¦è¢«è¯­æ³•è¯å…¸æ”¶å½•ã€‚ç„¶åè¦è€ƒè™‘å…¶åæ¥è¯­ç´ çš„éŸ³èŠ‚ï¼Œå¦‚æœæ˜¯å•éŸ³èŠ‚çš„ï¼Œå¦‚â€œäººâ€â€œæ—â€è¿™æ ·çš„ï¼Œä¸åˆ‡åˆ†ï¼Œå¦‚æœæ˜¯å¤šéŸ³èŠ‚çš„ï¼Œåˆ™è¦è¿›è¡Œåˆ‡åˆ†ã€‚</p><p>ï¼ˆ5ï¼‰æ•°è¯ä¸æ•°é‡è¯ç»„</p><p>æ•°è¯ä¸æ•°é‡è¯ç»„çš„è§„å®šæ˜¯å¦å¤–çš„ã€‚è¯¦è§æ–¹æ¡ˆã€‚</p><p>ï¼ˆ6ï¼‰æ—¶é—´è¯</p><p>æ—¶é—´è¯ä¸­ç™»å½•åœ¨è¯­æ³•è¯å…¸ä¸­çš„ï¼Œæ¯”å¦‚å†å²æœä»£çš„åç§°ï¼Œç‰¹æ®Šçš„å¹´ä»½â€œç”²åˆå¹´â€ç­‰ï¼Œä¸åšåˆ‡åˆ†ï¼Œå…¶ä»–çš„è¦æŒ‰ç…§â€œå¹´ã€æœˆã€æ—¥ã€æ—¶ã€åˆ†ã€ç§’â€çš„å±‚æ¬¡è¿›è¡Œåˆ‡åˆ†ã€‚</p><p>ï¼ˆ7ï¼‰å•éŸ³èŠ‚ä»£è¯â€œæœ¬â€ã€â€œæ¯â€ã€â€œå„â€ã€â€œè¯¸</p><p>è‹¥åæ¥æˆåˆ†æ˜¯å•éŸ³èŠ‚åè¯ï¼Œåˆ™ä¸åšåˆ‡åˆ†ï¼Œè‹¥æ˜¯åŒéŸ³èŠ‚æˆ–å¤šéŸ³èŠ‚ï¼Œåˆ™è¦åˆ‡åˆ†å¼€ã€‚</p><p>ï¼ˆ8ï¼‰åŒºåˆ«è¯</p><p>é¦–å…ˆï¼Œæˆ‘ä»¬è¦æ˜ç¡®ä½•ä¸ºåŒºåˆ«è¯ï¼ŒåŒºåˆ«è¯æŒ‡çš„æ˜¯æˆå¯¹çš„ï¼Œæœ‰åˆ†ç±»æ€§è´¨çš„ä¸€ç±»è¯ï¼Œå®ƒä»¬åªèƒ½å¤Ÿåšå®šè¯­ï¼Œä¸èƒ½åšè°“è¯­ï¼Œæ‰€ä»¥åˆç§°ä¸ºéè°“å½¢å®¹è¯ã€‚</p><p>ä¸¾ä¾‹æ¥è¯´ï¼ŒåŒºåˆ«è¯åŒ…æ‹¬ï¼šç”·ã€å¥³ã€é›Œã€é›„ã€å•ã€åŒã€å¤ã€é‡‘ã€é“¶ã€è¥¿å¼ã€ä¸­å¼ã€å¤ä»£ã€è¿‘ä»£ã€ç°ä»£ã€å½“ä»£ã€é˜´æ€§ã€é˜³æ€§ã€å†›ç”¨ã€æ°‘ç”¨ã€å›½æœ‰ã€ç§æœ‰ã€å°å‹ã€ä¸­å‹ã€å¤§å‹ã€å¾®å‹ã€æœ‰æœŸã€æ— æœŸã€å½©è‰²ã€é»‘ç™½ã€æ€¥æ€§ã€æ…¢æ€§ã€å°å·ã€ä¸­å·ã€å¤§å·ã€é‡ç”Ÿã€å®¶å…»ã€æ­£å¼ã€éæ­£å¼ã€äººé€ ï¼ˆä»åŠ¨è¯è¿‡æ¥çš„ï¼‰ã€å¤©ç„¶ã€å†’ç‰Œã€æ­£ç‰Œã€æ­£ç‰ˆã€ç›—ç‰ˆã€ä¸‹ç­‰ã€ä¸­ç­‰ã€ä¸Šç­‰ã€åˆçº§ã€ä¸­çº§ã€é«˜çº§ã€ä¸­å¼ã€æ¬§å¼ç­‰ç­‰ã€‚</p><p>å¯¹äºå«æœ‰åŒºåˆ«è¯çš„åºåˆ—ï¼Œæˆ‘ä»¬çš„åˆ‡åˆ†åŸåˆ™ä¹Ÿæ˜¯åŒæ ·æŒ‰ç…§éŸ³èŠ‚æ¥è¿›è¡Œï¼Œå¦‚æœåŒºåˆ«è¯åæ¥ä¸€ä¸ªå•éŸ³èŠ‚åè¯ï¼Œåˆ™ä¸åˆ‡åˆ†ï¼Œè‹¥æ¥çš„æ˜¯å¤šéŸ³èŠ‚åè¯ï¼Œåˆ™è¦åˆ‡åˆ†ã€‚</p><p>ï¼ˆ9ï¼‰è¿°è¡¥ç»“æ„</p><p>ç®€å•æ¥è¯´ï¼Œè¿°è¡¥ç»“æ„æŒ‡çš„æ˜¯æè¿°ä¸€ä¸ªåŠ¨è¯å‘ç”Ÿçš„æƒ…è²Œæˆ–ç»“æœï¼Œå³å¯¹åŠ¨è¯æ‰€ä»£è¡¨çš„äº‹ä»¶è¿›è¡Œçš„è¡¥å……ã€‚å¯¹äºåŒéŸ³èŠ‚çš„è¿°è¡¥ç»“æ„æˆ‘ä»¬çš„åˆ‡åˆ†åŸåˆ™æ˜¯ï¼Œå¦‚æœè¿›è¡Œåˆ‡åˆ†åï¼Œä¼šæœ‰æ— æ³•ç‹¬ç«‹æˆè¯çš„è¯­ç´ å­˜åœ¨ï¼Œåˆ™ä¸åˆ‡åˆ†ï¼Œåä¹‹ï¼Œåˆ™åˆ‡åˆ†ã€‚</p><p>è¿°è¡¥ç»“æ„ä¸­è¿˜æœ‰ä¸€ç±»å¸¸è§çš„å¤šéŸ³èŠ‚çš„â€œå¾—â€å­—è¡¥è¯­ï¼Œå¯¹äºè¿™ç±»è¿°è¡¥ç»“æ„ï¼Œæˆ‘ä»¬å¯ä»¥å°†â€œå¾—â€å­—å»æ‰ï¼Œè‹¥å»æ‰åä¾ç„¶èƒ½æˆè¯ï¼Œåˆ™è¦å°†å…¶åˆ‡åˆ†ï¼›è‹¥ä¸èƒ½æˆè¯ï¼Œåˆ™â€œå¾—â€å­—è¡¥è¯­æ•´ä½“ä½œä¸ºä¸€ä¸ªåˆ†è¯å•ä½ï¼Œå†…éƒ¨ä¸åšåˆ‡åˆ†ã€‚</p><p>ï¼ˆ10ï¼‰ã€ï¼ˆ11ï¼‰ã€ï¼ˆ12ï¼‰ã€ï¼ˆ13ï¼‰ç•¥</p><p>ï¼ˆ14ï¼‰è¯­ç´ å’Œéè¯­ç´ å­—çš„å¤„ç†</p><p>å¯¹äºç¦»åˆè¯çš„ç¦»æå½¢å¼ï¼Œè¦è¿›è¡Œåˆ‡åˆ†ã€‚æ‰€è°“ç¦»åˆè¯ï¼ŒæŒ‡çš„æ˜¯å¯ä»¥åœ¨ç»„åˆçš„ä¸¤ä¸ªè¯­ç´ ä¸­æ’å…¥å…¶ä»–æˆåˆ†çš„è¯ï¼Œæ¯”å¦‚â€œåƒé¥­â€ï¼Œå®ƒçš„ç¦»æå½¢å¼æœ‰ï¼Œâ€œåƒäº†é¥­â€â€œåƒäº†ä¸€ä¸ªé¥­â€ç­‰ã€‚</p><p>å¯¹äºè¡¨ç¤ºæ–¹ä½çš„åŒéŸ³èŠ‚è¯ï¼Œè‹¥åˆ‡åˆ†å‡ºæ— æ³•ç‹¬ç«‹æˆè¯çš„è¯­ç´ ï¼Œåˆ™ä¸åˆ‡åˆ†ï¼Œå¦åˆ™åˆ™è¦è¿›è¡Œåˆ‡åˆ†ã€‚</p><p>ï¼ˆ15ï¼‰æ–‡æœ¬ä¸­éæ±‰å­—çš„å­—ç¬¦ä¸²  ç•¥</p><p>ï¼ˆ16ï¼‰é‡å </p><p> é‡å æ˜¯æ±‰è¯­ç‹¬ç‰¹çš„è¯­è¨€ç°è±¡ä¹‹ä¸€ã€‚åŒ—å¤§æ–¹æ¡ˆä¸­å¯¹è¿™ç±»è¯çš„åˆ‡åˆ†çœ‹ä¼¼å¤æ‚ï¼Œå®è´¨ä¸Šæ˜¯åˆ‡åˆ†åˆ°èƒ½å¤Ÿç‹¬ç«‹ä½¿ç”¨çš„å•ä½ï¼Œå¹¶ä¸”è¦é¿å…åˆ‡åˆ†å‡ºä¸èƒ½å•ç‹¬æˆè¯çš„è¯­ç´ ã€‚</p><p>æ¯”å¦‚ï¼Œâ€œç”œç”œçš„èœ‚èœœâ€ï¼Œç”±äºâ€œç”œç”œâ€ä¸èƒ½å•ç‹¬æˆè¯ï¼Œå› æ­¤è¦åˆ‡åˆ†åˆ°â€œç”œç”œçš„â€ã€‚</p><p>è€Œâ€œè¯•è¯•çœ‹â€ç”±äºâ€œçœ‹â€è¿™é‡Œè¡¨ç¤ºåŠ¨ä½œçš„å°è¯•ï¼Œä½œä¸ºè¿™ä¸ªæ„ä¹‰å¹¶ä¸èƒ½å•ç‹¬è¿ç”¨ï¼Œå› æ­¤ä¸åˆ‡åˆ†ã€‚</p><p>ï¼ˆ17ï¼‰é™„åŠ æˆåˆ†</p><p>é™„åŠ æˆåˆ†å®è´¨ä¸ŠæŒ‡çš„æ˜¯æ„è¯ä¸­çš„å‰ç¼€å’Œåç¼€ã€‚æ±‰è¯­æ„è¯æ³•ä¸­æœ‰ä¸€ç±»æ˜¯ä¾æ®è¯ç¼€åŠ è¯æ ¹è¿›è¡Œçš„æ´¾ç”Ÿæ„è¯ã€‚å¯¹äºè¿™ä¸€ç±»åˆ‡åˆ†åºåˆ—ï¼Œé™¤éå…¶æ¥å…¥æˆåˆ†å¤ªå¤šï¼Œä¼šå¯¹å…¶è¿›è¡Œåˆ‡åˆ†ï¼Œå¦åˆ™ä¸åˆ‡åˆ†ã€‚æ¯”å¦‚â€œè€å¸ˆä»¬â€å°±ä¸åšåˆ‡åˆ†ï¼Œâ€œè‹¦è‹¦è¿½æ±‚è€Œä¸å¾—è€…â€ä¸­çš„â€œè€…â€ç”±äºç»Ÿæ‘„çš„æˆåˆ†å¤ªå¤šï¼Œæ‰€ä»¥è¦å•ç‹¬åˆ‡åˆ†å¼€ã€‚</p><p>ï¼ˆ18ï¼‰å¤åˆè¯æ„è¯</p><p>åœ¨åˆ‡åˆ†å¤åˆè¯çš„é—®é¢˜ä¸Šï¼ŒåŒ—å¤§æ–¹æ¡ˆæ˜¯å­˜åœ¨è®¨è®ºçš„ä½™åœ°çš„ã€‚ç”±äºå¤åˆè¯æœ¬èº«å’ŒçŸ­è¯­ä¹‹é—´çš„ç•Œé™è¾ƒä¸ºæ¨¡ç³Šï¼Œå³ä½¿åœ¨è¯­è¨€å­¦æ„ä¹‰çš„ç•Œå®šä¸Šä¹Ÿä¼šå­˜åœ¨åˆ†æ­§ï¼Œå› æ­¤å¯¹äºå¤åˆè¯ç±»å‹çš„åˆ‡åˆ†åºåˆ—æ˜¯å¦åˆ‡åˆ†ï¼Œå®è´¨ä¸Šå¾ˆéš¾å›ç­”ã€‚åŒ—å¤§æ–¹æ¡ˆç»™å‡ºçš„è§£å†³åŠæ³•æ˜¯ï¼Œé¦–å…ˆå¦‚æœåˆ‡åˆ†åä¼šæœ‰æ— æ³•ç‹¬ç«‹æˆè¯çš„æˆåˆ†ï¼Œé‚£ä¹ˆå°±ä¸åˆ‡åˆ†ï¼›å¦å¤–è¦åˆ¤æ–­è¿™ä¸ªå¤åˆè¯çš„æ„ä¹‰æ˜¯å¦åªæ˜¯ç»„æˆæˆåˆ†çš„ç®€å•ç›¸åŠ ï¼Œå¦‚æœæ˜¯ï¼Œé‚£ä¹ˆå°±åˆ‡åˆ†ï¼Œå¦‚æœä¸æ˜¯ï¼Œé‚£å°±è¯´æ˜ç»„æˆè¯¥è¯çš„ä¸¤ä¸ªæˆåˆ†ä¹‹é—´æ„ä¹‰æ˜¯æœ‰ç›¸äº’æ¸—é€çš„è”ç»“çš„ï¼Œå°±ä¸èƒ½åˆ‡åˆ†ã€‚ä½†æ˜¯å¦‚ä½•åˆ¤æ–­å¤åˆè¯æ„ä¹‰æ˜¯å¦æ˜¯ç»„åˆæˆåˆ†çš„ç›¸åŠ å‘¢ï¼Ÿ</p><p>è¿™é‡Œçš„æ–¹æ³•ä¸»è¦æœ‰ä¸¤ä¸ªï¼Œä¸€ä¸ªæ˜¯åŠ â€œçš„â€æ³•ã€‚è¿™ä¸ªæ–¹æ³•ä¸»è¦é’ˆå¯¹çš„æ˜¯å®šä¸­ç»“æ„çš„å¤åˆè¯ï¼Œå³ä¸€ä¸ªè¯­ç´ ä¿®é¥°å¦ä¸€ä¸ªè¯­ç´ ã€‚æ¯”å¦‚â€œç™½èŠ±â€ï¼Œå’Œâ€œç™½çš„èŠ±â€æ„ä¹‰ä¸€è‡´ï¼Œé‚£ä¹ˆå°±è¦åˆ‡åˆ†ã€‚</p><p>ç¬¬äºŒä¸ªæ–¹æ³•æ˜¯æ›¿æ¢æ³•ï¼Œå°†å¤åˆè¯â€œABâ€çš„Aè¯­ç´ æ‹¿å‡ºæ¥è¿›è¡Œç»„è¯ï¼Œå†å°†Bè¯­ç´ æ‹¿å‡ºæ¥è¿›è¡Œç»„è¯ï¼Œè‹¥å•ç‹¬ç»„è¯åå…¶è¯ä¹‰éƒ½æ˜¯ä¸€æ ·çš„ï¼Œé‚£ä¹ˆå°±è¯´æ˜å¤åˆè¯ABçš„è¯ä¹‰æ˜¯Aè¯­ç´ ä¹‰å’ŒBè¯­ç´ ä¹‰çš„ç›¸åŠ ï¼Œå› æ­¤è¦åˆ‡åˆ†ï¼›è‹¥æœ‰Aè¯­ç´ æˆ–Bè¯­ç´ æœ‰å’Œå…¶ä»–ç»„è¯æƒ…å†µä¸­è¯­ä¹‰ä¸åŒçš„ï¼Œé‚£ä¹ˆå°±ä¸åˆ‡åˆ†å¤åˆè¯ABã€‚</p><p>ä½†æ˜¯è¿™ä¸¤ä¸ªæ–¹æ³•å¹¶ä¸èƒ½è§£å†³æ‰€æœ‰çš„å¤åˆè¯åˆ¤æ–­é—®é¢˜ï¼Œå› æ­¤åˆ°åº•æ˜¯å°†é—®é¢˜ç®€åŒ–è¿˜æ˜¯å¯¹è§„åˆ™è¿›ä¸€æ­¥ç»†è‡´ï¼Œæ˜¯å€¼å¾—æ€è€ƒçš„ã€‚</p><h2 id="é¢—ç²’åº¦æ–¹æ¡ˆï¼ˆè°ƒæ•´ç‰ˆï¼‰"><a href="#é¢—ç²’åº¦æ–¹æ¡ˆï¼ˆè°ƒæ•´ç‰ˆï¼‰" class="headerlink" title="é¢—ç²’åº¦æ–¹æ¡ˆï¼ˆè°ƒæ•´ç‰ˆï¼‰"></a>é¢—ç²’åº¦æ–¹æ¡ˆï¼ˆè°ƒæ•´ç‰ˆï¼‰</h2><p>è°ƒæ•´å†…å®¹ï¼š</p><ul><li>å°†åŸæ¥çš„ç¬¬ä¸€ç²’åº¦ä½œä¸ºç»†ç²’åº¦ï¼ˆéå¸¸ç»†ï¼Œå­˜åœ¨è¯­ä¹‰ä¸é€æ˜çš„è¯ç¼€ï¼‰ï¼Œå°†ç¬¬äºŒç²’åº¦å’Œç¬¬ä¸‰ç²’åº¦åˆå¹¶æˆä¸ºç²—ç²’åº¦ï¼‰ï¼Œé’ˆå¯¹ä¸“æœ‰åè¯çš„é—®é¢˜ï¼Œåˆ’å‡ºç²—ç²’åº¦2çº§ï¼ˆè¿™ä¸ªå¯ä»¥è®¨è®ºï¼Œæ˜¯åœ¨åˆ†è¯ä¸­ä¸€ä¸‹å­åˆ’åˆ†å‡ºæ¥ï¼Œè¿˜æ˜¯åœ¨ä¸Šæ¸¸ä»»åŠ¡ä¸­å†å¤„ç†ã€‚åœ¨å‚è€ƒèµ„æ–™çš„ä¸“åˆ©ä¸­ï¼Œä»–ä»¬å¾€å¾€åœ¨åˆ†è¯ä¸­å°±è§£å†³äº†ï¼‰ã€‚</li><li>ç†æ¸…å®ä½“å’Œä¸“æœ‰åè¯çš„åŒºåˆ«<h3 id="ç»†ç²’åº¦"><a href="#ç»†ç²’åº¦" class="headerlink" title="ç»†ç²’åº¦"></a>ç»†ç²’åº¦</h3></li><li>å•éŸ³è¯<ul><li>å•ç‹¬ä¸€ä¸ªè¯­ç´ å³å¯æˆè¯çš„ï¼Œå¦‚â€œç«ã€ä¹¦ã€æ°´â€</li></ul></li><li>è¿ç»µè¯<ul><li>å¿…é¡»å’Œå…¶ä»–è¯­ç´ ç»“åˆæˆè¯çš„ï¼Œä¸”ç»“åˆçš„è¯­ç´ æ˜¯å›ºå®šçš„ï¼Œå¦‚â€œè‘¡è„â€â€œä¹’ä¹“â€</li></ul></li><li>éŸ³è¯‘è¯<ul><li>åŒ…æ‹¬äº†å¤–å›½çš„ä¸“åï¼ˆäººåç­‰ï¼‰</li></ul></li><li>æ•°è¯</li><li>é‡è¯<ul><li>æ¯”å¦‚ï¼šæ¡ã€ä¸²ã€å¼ </li><li>è¿™é‡Œè¦æ³¨æ„ä¸€äº›ä»åè¯å‘å±•è¿‡æ¥çš„é‡è¯ï¼Œæ¯”å¦‚â€œç¢—â€</li><li>è¿™é‡ŒåŒ…æ‹¬åº¦é‡ï¼š3/cmï¼Œ7/å¤©</li><li>å¦å¤–ç»†ç²’åº¦ä¸­ï¼Œæ—¶é—´æ•°å’Œæ—¶é—´å•ä½ä¹Ÿåˆ‡åˆ†å¼€ï¼Œå¦‚ï¼š2018/å¹´</li></ul></li><li>ä¸å«è¡Œæ”¿åŒºåˆ’çš„åœ°å<ul><li>æ¯”å¦‚ï¼šä¸Šæµ·ã€åŒ—äº¬ã€æ­¦æ±‰</li></ul></li><li>ä¸“æœ‰åè¯ï¼šæœºæ„ã€å›¢ä½“ã€ç»„ç»‡<ul><li>æ˜¯ä¸€ä¸ªå°é—­ç±»ï¼Œæ˜¯ä¸å¯ç±»æ¨çš„</li><li>åŒ…å«ä¸Šä¸‹éš¶å±å…³ç³»çš„å›¢ä½“æœºæ„ä¸“æœ‰åè¯ï¼Œåˆ‡åˆ†åˆ°æœ€å°çš„å›¢ä½“æœºæ„ã€‚æ¯”å¦‚â€œä¸­å›½/é“¶è¡Œ/åŒ—äº¬/åˆ†è¡Œâ€ã€‚</li></ul></li><li>ç®€ç§°ç•¥è¯­</li><li>æ–¹ä½è¯</li><li>è¯­æ°”è¯</li><li>å¹è¯</li><li>å®è¯­ç´ <ul><li>åŒ…æ‹¬åŒ—å¤§æ–¹æ¡ˆé‡Œçš„å½¢è¯­ç´ ã€åè¯­ç´ ã€åŠ¨è¯­ç´ ã€äººåä¸­çš„å§“æ°ï¼Œæ¯”å¦‚ï¼šé”¦ï¼ˆå½¢è¯­ç´ ï¼‰</li></ul></li><li>è™šè¯­ç´ <ul><li>å‰æ¥æˆåˆ†<ul><li>æ¯”å¦‚â€œé˜¿â€â€œè€â€â€œéâ€</li><li>è¿™ç±»é™¤äº†ä¼ ç»Ÿæ„ä¹‰ä¸Šçš„å‰ç¼€ï¼Œä¹Ÿè¦è€ƒè™‘ä¸€äº›ç½‘ç»œæµè¡Œè¯­çš„ä¸´æ—¶æ„è¯äº§å‡ºçš„å‰ç¼€</li></ul></li><li>å‰¯è¯­ç´ <ul><li>ä¸»è¦æ˜¯å¦å®šå‰¯è¯ï¼Œæ¯”å¦‚â€œä¸â€â€œå¾ˆâ€</li></ul></li><li>åæ¥æˆåˆ†<ul><li>æ¯”å¦‚ï¼šä»¬ï¼Œå„¿ï¼ˆè¡¨äº²æ˜µçš„ï¼‰ï¼Œå­ï¼Œå¤´ï¼ŒåŒ–ï¼Œè€…</li><li>æˆ‘è®¤ä¸ºï¼Œè¿˜åº”åŒ…æ‹¬è¡Œæ”¿åŒºåˆ’çš„å•ä½ï¼Œæ¯”å¦‚ï¼šçœã€å¸‚ã€åŒºç­‰ï¼›å’Œè¡¨ç¤ºå°Šç§°çš„â€œè€â€â€œæ€»â€</li></ul></li><li>åŠ©è¯<ul><li>åŠ©åŠ¨è¯ã€åŠ©æ•°è¯</li></ul></li></ul></li><li>ä¹ è¯­<ul><li>åŒ…æ‹¬æˆè¯­ã€å››å­—æ ¼çŸ­è¯­ã€æ­‡åè¯­</li><li>ä½†æ˜¯å¦‚æœæ­‡åè¯­æœ‰æ ‡ç‚¹ç¬¦å·ï¼Œè¦æŒ‰ç…§æ ‡ç‚¹ç¬¦å·åˆ’åˆ†</li><li>æ¯”å¦‚ï¼šâ€œä¸ç®¡ä¸‰ä¸ƒäºŒåä¸€â€â€œç™¾å°ºç«¿å¤´/ï¼Œ/æ›´è¿›ä¸€æ­¥â€</li></ul></li></ul><h3 id="ç²—ç²’åº¦"><a href="#ç²—ç²’åº¦" class="headerlink" title="ç²—ç²’åº¦"></a>ç²—ç²’åº¦</h3><p>ç®€è¨€ä¹‹ï¼šåˆ‡åˆ°è¯ç»„å±‚ï¼Œä¸”æ³¨æ„éŸ³èŠ‚æ•°ï¼Œå¯¹åŒéŸ³èŠ‚æ”¾å®½ã€‚å°†ç»†ç²’åº¦ä¸­å¯æˆè¯çš„ç»„åˆæˆè¯ï¼ˆæ´¾ç”Ÿè¯ï¼‰ï¼Œå¦å°†å¯ç‹¬ç«‹æˆè¯çš„è¯æ ¹ç»“åˆæˆå¤åˆè¯ã€‚<br>ç²—ç²’åº¦çš„åˆ‡åˆ†ç›®æ ‡æ˜¯ï¼Œä½¿å¾—æ¯ä¸€ä¸ªå®è¯æ€§çš„åˆ‡åˆ†å•ä½éƒ½æ˜¯è¡¨ä¹‰æ˜ç¡®çš„åˆ†è¯å•ä½ï¼Œä¸å­˜åœ¨è¯­ä¹‰ä¸é€æ˜çš„åˆ†è¯å•ä½ã€‚å› æ­¤ï¼Œæˆ‘ä»¬ä¹Ÿä¸èƒ½å¥¢æ±‚å®ä½“è¯†åˆ«ç­‰ä¸Šæ¸¸ä»»åŠ¡åœ¨åˆ†è¯ä»»åŠ¡ä¸­å°±å¾—ä»¥è§£å†³ã€‚</p><ul><li>å‰æ¥æˆåˆ†+åè¯<ul><li>æ¯”å¦‚ï¼šé˜¿ç‰›</li></ul></li><li>å‰æ¥æˆåˆ†+æ•°<ul><li>æ¯”å¦‚ï¼šé˜¿å¤§</li></ul></li><li>åè¯+åæ¥æˆåˆ†<ul><li>æ¯”å¦‚ï¼šå­¦ç”Ÿä»¬ã€è€å¸ˆä»¬ã€æ‹³å¤´ã€é«˜æ¸…ç‰ˆ</li></ul></li><li>åŠ¨è¯+åæ¥æˆåˆ†<ul><li>æ¯”å¦‚ï¼šåˆ›æ–°åŒ–ï¼ˆå•ç‹¬â€œåˆ›æ–°â€è¿˜æ˜¯åˆ†åˆ°â€åˆ›æ–°â€œï¼‰</li></ul></li><li>å§“æ°+å<ul><li>æ¯”å¦‚ï¼šå¼ ä¼Ÿ</li></ul></li><li>æ•°+é‡+ï¼ˆåŠ©æ•°è¯ï¼‰<ul><li>æ¯”å¦‚ï¼šå››/äººï¼Œäº”ä¸ª/äºº</li></ul></li><li>æ—¶é—´<ul><li>æŒ‰åŒ—å¤§æ–¹æ¡ˆï¼Œä¸è¦åˆå¹¶</li><li>æ¯”å¦‚ï¼š1997å¹´/9æœˆ/3æ—¥ï¼Œæ—©/å…«ç‚¹</li></ul></li><li>å¤åˆè¯<ul><li>åŒéŸ³èŠ‚ã€ä¸‰éŸ³èŠ‚ï¼ˆåˆ‡åˆ†åŸåˆ™è¯¦è§å¯¹åŒ—å¤§æ–¹æ¡ˆçš„è®²è§£ï¼‰</li><li>æ³¨æ„ï¼Œä¸è¦å°†è”åˆæ„è¯çš„è¯ç»„ç®—ä½œå¤åˆè¯ã€‚</li></ul></li><li>åœ°å+è¡Œæ”¿åŒºåˆ’<ul><li>æ¯”å¦‚ï¼šåŒ—äº¬å¸‚ã€ä¸Šæµ·å¸‚</li></ul></li><li>åœ°å+è‡ªç„¶åœ°å½¢<ul><li>æ¯”å¦‚ï¼šååŒ—å¹³åŸã€å—æ²™ç¾¤å²›</li></ul></li></ul><h2 id="ç²—ç²’åº¦ä¸‹çš„åˆ‡åˆ†éš¾ç‚¹"><a href="#ç²—ç²’åº¦ä¸‹çš„åˆ‡åˆ†éš¾ç‚¹" class="headerlink" title="ç²—ç²’åº¦ä¸‹çš„åˆ‡åˆ†éš¾ç‚¹"></a>ç²—ç²’åº¦ä¸‹çš„åˆ‡åˆ†éš¾ç‚¹</h2><h3 id="1-ä¸“åå’Œå®ä½“çš„åˆ‡åˆ†"><a href="#1-ä¸“åå’Œå®ä½“çš„åˆ‡åˆ†" class="headerlink" title="1.ä¸“åå’Œå®ä½“çš„åˆ‡åˆ†"></a>1.ä¸“åå’Œå®ä½“çš„åˆ‡åˆ†</h3><p>ä¸“æœ‰åè¯æŒ‡çš„æ˜¯ä¸“æŒ‡æ€§çš„äººåã€åœ°åã€å›¢ä½“ã€æœºæ„ã€ç»„ç»‡ã€æ°‘æ—ã€å•†æ ‡ã€‚</p><p>äººåã€åœ°åã€æ°‘æ—ã€å•†æ ‡åŸºæœ¬ä¸Šæ²¡æœ‰å¼‚è®®ï¼Œä½†æ˜¯å“ªäº›å›¢ä½“ã€æœºæ„ã€ç»„ç»‡èƒ½ç®—ä¸“æœ‰åè¯ï¼Œå“ªäº›ä¸èƒ½ç®—æ˜¯ä¸å¤ªæ˜ç¡®çš„ã€‚</p><p>å¦å¤–ï¼Œé™¤ä¸Šé¢æŒ‡å‡ºçš„åˆ†ç±»å¤–ï¼Œå…¶ä»–çš„å…·æœ‰ä¸“æŒ‡æ€§çš„å®ä½“ï¼Œä¸èƒ½è¢«å½“åšä¸“æœ‰åè¯æ¥å¤„ç†ã€‚å…·ä½“æ¥è¯´ï¼Œä¸“æœ‰åè¯çš„åˆ‡åˆ†éš¾ç‚¹æœ‰ä»¥ä¸‹å‡ ç‚¹ï¼š</p><p>ï¼ˆ1ï¼‰ ä¸“æœ‰åè¯çš„ä¸“æŒ‡æ€§æ˜¯å¿½ç•¥æ–‡æœ¬è¯­å¢ƒã€‚æ¯”å¦‚â€æ ¡é•¿åŠå…¬å®¤å‘å¸ƒé‡è¦é€šçŸ¥â€œï¼Œå³ä½¿é€šè¿‡å‰æ–‡æˆ‘ä»¬çŸ¥é“è¿™é‡ŒæŒ‡çš„æ˜¯åŒ—å¤§çš„æ ¡é•¿åŠå…¬å®¤ï¼Œæˆ‘ä»¬åªå°†å®ƒä½œä¸ºæ™®é€šåè¯çš„å¤„ç†ï¼Œè€Œä¸æ˜¯ä½œä¸ºä¸€ä¸ªä¸“æŒ‡æ€§çš„æœºæ„åæ¥å¤„ç†ã€‚ <strong>ä½†æ˜¯åœ¨å›½é™…æˆ–ä¸­å›½èŒƒå›´å†…çš„çŸ¥åçš„å”¯ä¸€çš„å›¢ä½“ã€æœºæ„ã€ç»„ç»‡ çš„åç§°æˆ‘ä»¬ä¾ç„¶å°†ä¹‹å¤„ç†ä¸ºä¸“å</strong>ï¼Œæ¯”å¦‚â€œå›½åŠ¡é™¢â€ï¼Œå®ƒå’Œâ€œæ ¡é•¿åŠå…¬å®¤â€çš„åŒºåˆ«åœ¨äºâ€œå›½åŠ¡é™¢â€å…¨å›½åªæœ‰ä¸€ä¸ªï¼Œè€Œâ€œæ ¡é•¿åŠå…¬å®¤â€æœ‰å¾ˆå¤šä¸ªï¼Œå› æ­¤â€œå›½åŠ¡é™¢â€ä½œä¸ºä¸“åä¸åˆ‡åˆ†ï¼Œè€Œâ€œæ ¡é•¿åŠå…¬å®¤â€è¦åˆ‡åˆ†æˆâ€œæ ¡é•¿/åŠå…¬å®¤â€ã€‚</p><p> ï¼ˆ2ï¼‰ä¸“æœ‰åè¯çš„ç»„åˆæ€§ã€‚ä¸“æœ‰åè¯æœ‰æ—¶ä¼šå’Œå…¶ä»–åè¯ä¸€èµ·ç»„åˆæˆè¯ã€‚å¯¹äºåˆ†è¯ä»»åŠ¡è€Œè¨€ï¼Œæˆ‘ä»¬åªéœ€è€ƒè™‘å°†ä¸“æœ‰åè¯å’Œè¿™ä¸ªè¯åˆ‡å¼€åè¿™ä¸ªè¯èƒ½å¦å•ç‹¬æˆè¯ï¼Œå¦‚æœä¸èƒ½ï¼Œé‚£ä¹ˆå°±ä¸åˆ‡åˆ†ï¼Œå¦‚æœèƒ½ï¼Œé‚£ä¹ˆå°±åˆ‡åˆ†ã€‚ï¼ˆè¿™é‡Œå’ŒåŒ—å¤§æ–¹æ¡ˆä¸åŒï¼ŒåŒ—å¤§æ–¹æ¡ˆè®¤ä¸ºæ¥å•éŸ³èŠ‚å¯ä»¥åˆ‡åˆ†ï¼Œä¹Ÿå¯ä»¥ä¸åˆ‡åˆ†ã€‚ï¼‰æ¯”å¦‚â€æ»¡äººâ€œï¼Œâ€å“ˆè¨å…‹äººâ€œï¼Œâ€æ˜Œå¹³/åˆ†è¡Œâ€œï¼Œè€Œå¯¹äºä¸€äº›å¤šä¸ªåè¯ç»„åˆæˆä¸“åçš„æƒ…å†µï¼Œæ¯”å¦‚â€œå…¨å›½/æ€»/å·¥ä¼šâ€â€œå…¨å›½/äººæ°‘/ä»£è¡¨/å¤§ä¼šâ€œï¼Œåœ¨ç»†ç²’åº¦å’Œç²—ç²’åº¦ä¸­ï¼Œç”±äºå®ƒä»¬éŸ³èŠ‚æ•°è¾ƒå¤šï¼Œè§†ä¸ºæ™®é€šåè¯è¿›è¡Œåˆ‡åˆ†ã€‚æ˜¯å¦å¯ä»¥è®¾ç½®ä¸€ä¸ª<strong>ç²—ç²’åº¦2çº§ï¼Œåœ¨ç²—ç²’åº¦2çº§ä¸­ï¼Œä½œä¸ºç»„ç»‡ç±»ä¸“æœ‰åè¯ï¼Œä¸åˆ‡åˆ†</strong>ã€‚</p><p>ï¼ˆ3ï¼‰ä¸“æœ‰åè¯å±‚æ¬¡æ€§ã€‚è¡¨ç¤ºæœºæ„çš„ä¸“æœ‰åè¯ä¸­æœ‰äº›æ˜¯å‰åç›¸è¿ï¼ŒåŒ…å«ä¸Šä¸‹éš¶å±å…³ç³»çš„ã€‚<strong>ä¸‹çº§æœºæ„çš„ä¸“æŒ‡æ€§</strong>æœ‰çš„æ˜¯ä»ç”±ä¸Šçº§å›¢ä½“ç»§æ‰¿æ¥çš„ï¼Œæ¯”å¦‚â€œåŒ—äº¬å¤§å­¦è®¡ç®—è¯­è¨€å­¦ç ”ç©¶æ‰€â€æ˜¯ä¸€ä¸ªä¸“æŒ‡æ€§çš„çŸ­è¯­ï¼Œå®ƒä¹‹æ‰€ä»¥æœ‰ä¸“æŒ‡æ€§ï¼Œæ˜¯å› ä¸ºâ€œåŒ—äº¬å¤§å­¦â€è¿™ä¸ªä¸“æœ‰åè¯çš„ä¸“æŒ‡æ€§ï¼Œå¦‚æœæ²¡æœ‰â€œåŒ—äº¬å¤§å­¦â€ï¼Œåˆ™â€œè®¡ç®—è¯­è¨€å­¦ç ”ç©¶æ‰€â€æŒ‰ç…§æ™®é€šåè¯è¯ç»„æ¥åˆ‡åˆ†ï¼ˆå‚ç…§ç¬¬ä¸€ç‚¹ï¼‰ï¼›æœ‰çš„æ˜¯é€šè¿‡å…¶ä»–ä¸“æœ‰åè¯ï¼Œå¦‚åœ°åã€äººåè·å¾—çš„ï¼Œæ¯”å¦‚â€œé²è¿…ç ”ç©¶é™¢â€ï¼Œâ€œåŒ—äº¬åˆ†è¡Œâ€ã€‚åœ¨ç²—ç²’åº¦ä¸­ï¼Œå¯¹äºè·å¾—ä¸“æŒ‡æ€§çš„ä¸“æœ‰åè¯ä¸åˆ‡åˆ†ï¼Œå¦‚â€œé²è¿…ç ”ç©¶é™¢â€ï¼Œâ€œåŒ—äº¬åˆ†è¡Œâ€<strong>æ˜¯å¦å¯ä»¥è®¾ç½®ç²—ç²’åº¦2çº§ï¼Œè¡¨ç¤ºä¸Šä¸‹çº§çš„ä¸“æœ‰åè¯å…¨éƒ¨çº³å…¥ï¼Ÿ</strong>æ¯”å¦‚â€œåŒ—äº¬å¤§å­¦è®¡ç®—è¯­è¨€å­¦ç ”ç©¶æ‰€â€ï¼Œåœ¨ç²—ç²’åº¦2çº§ä¸­å°±ä¸åšåˆ‡åˆ†ã€‚</p><p>ï¼ˆ4ï¼‰ç”µè§†èŠ‚ç›®ã€æ–‡è‰ºä½œå“ï¼ˆä¹¦ã€æ–‡æ¡£ã€åè®®ï¼‰æ ‡é¢˜ã€ç”µè§†å‰§ã€æˆ˜äº‰åç­‰ï¼Œä¸ä½œä¸ºä¸“æœ‰åè¯ï¼ŒæŒ‰ç…§æ™®é€šåè¯åˆ’åˆ†ã€‚ä¸¾ä¾‹ï¼š</p><ul><li>ä¼Šæ‹‰å…‹/æˆ˜äº‰</li><li>è¾›äº¥/é©å‘½</li><li>å¹³æ´¥/æˆ˜å½¹</li><li>å¼€å¿ƒ/è¯å…¸</li><li>æ–°é—»/30åˆ†</li><li>æ–°é—»/æ—©/8ç‚¹</li><li>ä¸­å¤®ç”µè§†å°/-/1<br>ï¼ˆå®ƒä»¬åæœŸå¯ä»¥é€šè¿‡ä¹¦åå·å’Œå¼•å·è¯†åˆ«å‡ºæ¥ã€‚ï¼‰</li></ul><h3 id="2-æ”¿æ²»è¯è¯­æ˜¯å¦ç®—ä½œä¹ è¯­ï¼Ÿï¼ˆå¯ä»¥è®¨è®ºï¼‰"><a href="#2-æ”¿æ²»è¯è¯­æ˜¯å¦ç®—ä½œä¹ è¯­ï¼Ÿï¼ˆå¯ä»¥è®¨è®ºï¼‰" class="headerlink" title="2.æ”¿æ²»è¯è¯­æ˜¯å¦ç®—ä½œä¹ è¯­ï¼Ÿï¼ˆå¯ä»¥è®¨è®ºï¼‰"></a>2.æ”¿æ²»è¯è¯­æ˜¯å¦ç®—ä½œä¹ è¯­ï¼Ÿï¼ˆå¯ä»¥è®¨è®ºï¼‰</h3><p>æ”¿æ²»å£å·å’Œæ”¿æ²»æ€æƒ³ç”±äºåœ¨ä¸€å®šçš„å†å²æ—¶æœŸä¸­é¢‘ç¹ä½¿ç”¨ï¼Œå› æ­¤ï¼Œå¦‚æœåˆ‡åˆ†è¡¨æ„å°±ä¸ä¸€æ ·ã€‚æ¯”å¦‚â€œä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰æ€æƒ³â€å’Œâ€œä¹ è¿‘å¹³æ–°æ—¶ä»£ä¸­å›½ç‰¹è‰²ç¤¾ä¼šä¸»ä¹‰æ€æƒ³â€å°±æ˜¯ä¸¤ä¸ªæ¦‚å¿µã€‚</p><p>æœ‰ä¸¤ä¸ªè§£å†³æ–¹æ¡ˆï¼Œä¸€ä¸ªæ˜¯å°†éŸ³èŠ‚è¾ƒçŸ­çš„æ”¿æ²»è¯è¯­ç®—ä½œè¯­æ³•è¯å…¸ä¸­çš„è¯ï¼Œå¦‚â€œç§‘æŠ€å¼ºå›½â€â€œç§‘æ•™å…´å›½â€â€œç»¿è‰²ç»æµâ€ï¼Œâ€œç§‘æŠ€åˆ›æ–°â€ç­‰ç­‰ï¼Œç„¶åé‡åˆ°è¿™æ ·çš„è¯ï¼Œç»†ç²’åº¦ã€ç²—ç²’åº¦é‡Œéƒ½ä¸åˆ‡åˆ†ï¼Œè€ŒéŸ³èŠ‚è¾ƒé•¿çš„ï¼Œæ¯”å¦‚â€œä¸­åæ°‘æ—ä¼Ÿå¤§å¤å…´â€å°±ä½œä¸ºæ™®é€šåè¯è¿›è¡Œåˆ‡åˆ†ï¼›ç¬¬äºŒä¸ªè§£å†³æ–¹æ¡ˆæ˜¯å…¨éƒ¨æŒ‰ç…§æ™®é€šåè¯åˆ‡åˆ†ï¼Œåˆ°å…·ä½“çš„ä»»åŠ¡éœ€æ±‚æ—¶å†å¤„ç†ã€‚ä¸è¿‡ï¼Œæˆ‘è§‰å¾—è¿™ä¸¤ä¸ªè§£å†³æ–¹æ¡ˆéƒ½ä¼šå½±å“åˆ†è¯ç²’åº¦æ•´ä½“çš„å¹³è¡¡åº¦ï¼Œå› ä¸ºæ”¿æ²»å£å·æ„è¯æœ‰æ—¶éå¸¸éå¸¸é•¿ã€‚</p><h3 id="3-æŸæŸç†è®ºçš„åç§°ç®—ä½œä¸“åå—ï¼ŸæŸæŸé¢†åŸŸç†è®ºä¸­çš„ä¸“ä¸šæœ¯è¯­ç®—ä½œä¸“åå—ï¼Ÿ"><a href="#3-æŸæŸç†è®ºçš„åç§°ç®—ä½œä¸“åå—ï¼ŸæŸæŸé¢†åŸŸç†è®ºä¸­çš„ä¸“ä¸šæœ¯è¯­ç®—ä½œä¸“åå—ï¼Ÿ" class="headerlink" title="3.æŸæŸç†è®ºçš„åç§°ç®—ä½œä¸“åå—ï¼ŸæŸæŸé¢†åŸŸç†è®ºä¸­çš„ä¸“ä¸šæœ¯è¯­ç®—ä½œä¸“åå—ï¼Ÿ"></a>3.æŸæŸç†è®ºçš„åç§°ç®—ä½œä¸“åå—ï¼ŸæŸæŸé¢†åŸŸç†è®ºä¸­çš„ä¸“ä¸šæœ¯è¯­ç®—ä½œä¸“åå—ï¼Ÿ</h3><p>ç†è®ºçš„å‘½ååŒæ ·æ˜¯ä»»æ„æ€§çš„å‘½åè¡Œä¸ºï¼Œå’Œèœåä¸€æ ·ï¼Œå¦‚æœå¯¹â€œxxxç†è®ºâ€ä¸­çš„â€œxxxâ€è¿›è¡Œåˆ‡åˆ†åï¼Œâ€œxxxâ€çš„æ„æ€æœ‰æ‰€æ”¹å˜ï¼Œé‚£ä¹ˆå°±ä¸èƒ½åˆ‡åˆ†ï¼Œå¦‚æœæ²¡æœ‰æ”¹å˜ï¼Œåˆ™å¯ä»¥åˆ‡åˆ†ã€‚æ¯”å¦‚â€œç²¾ç¥åˆ†æ/ç†è®ºâ€ï¼Œå¦‚æœåˆ‡åˆ†æˆâ€œç²¾ç¥/åˆ†æâ€ï¼Œè¿™ä¸ªâ€œç²¾ç¥â€å’Œâ€œä½ ä»Šå¤©ç²¾ç¥ä¸ä½³â€ä¸­çš„â€œç²¾ç¥â€å¹¶ä¸æ˜¯ä¸€ä¸ªæ„æ€ï¼Œå› æ­¤ä¸èƒ½åˆ‡åˆ†ã€‚è€Œâ€œç‰›é¡¿/ç¬¬äºŒ/å®šå¾‹â€åˆ‡åˆ†åæ²¡é—®é¢˜ï¼Œå› ä¸ºè¿™ä¸ªç†è®ºçš„å‘½åæœ¬èº«æ˜¯ç»„åˆè€Œæˆçš„ã€‚</p><p>é‚£ä¹ˆå„ä¸ªé¢†åŸŸä¸­çš„ä¸“ä¸šæœ¯è¯­æ˜¯å¦ç®—ä½œä¸“åå‘¢ï¼Ÿæˆ‘è®¤ä¸ºåœ¨é€šç”¨å‹çš„åˆ†è¯ä¸­ï¼ŒåªåŠ å…¥æœ€ä¸ºé‡è¦çš„ä¸€äº›ä¸“ä¸šæœ¯è¯­ï¼›è€Œåœ¨ç‰¹å®šé¢†åŸŸä¸­ï¼Œå†åœ¨è¿™æ–¹é¢è¿›è¡Œæ‹“å±•ã€‚å› æ­¤ï¼Œâ€œç¤¾ä¼šç”Ÿæ´»â€åœ¨ç¤¾ä¼šå­¦ä¸­åº”å½“ç®—ä½œä¸€ä¸ªä¸“ä¸šæœ¯è¯­ï¼Œä½†æ˜¯åœ¨é€šç”¨å‹çš„åˆ†è¯ä¸­è¿˜æ˜¯æŒ‰ç…§æ™®é€šåè¯æ¥è¿›è¡Œåˆ‡åˆ†ï¼Œå³â€œç¤¾ä¼š/ç”Ÿæ´»â€ã€‚</p><h3 id="4-å¹¶åˆ—æˆåˆ†å¦‚ä½•åˆ‡åˆ†ï¼Ÿ"><a href="#4-å¹¶åˆ—æˆåˆ†å¦‚ä½•åˆ‡åˆ†ï¼Ÿ" class="headerlink" title="4.å¹¶åˆ—æˆåˆ†å¦‚ä½•åˆ‡åˆ†ï¼Ÿ"></a>4.å¹¶åˆ—æˆåˆ†å¦‚ä½•åˆ‡åˆ†ï¼Ÿ</h3><p>å¹¶åˆ—æˆåˆ†æŒ‰ç…§é¡¿å·è¿›è¡Œåˆ‡åˆ†ï¼Œæ¯”å¦‚â€œå¹³æ´¥/ã€/è¾½æ²ˆ/æˆ˜å½¹â€ï¼Œâ€å¼ /ã€/æå®¶â€œï¼ˆè¿™é‡Œçš„â€å¼ â€œå¯ä»¥çœ‹åšæ˜¯â€å¼ å®¶â€œçš„ç¼©ç•¥å½¢å¼ï¼‰ã€‚</p>]]></content>
      
      
      
        <tags>
            
            <tag> NLP </tag>
            
            <tag> åˆ†è¯ </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/passages/hello-world/"/>
      <url>/passages/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>

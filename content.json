{"meta":{"title":"好乐无荒","subtitle":"好乐无荒，良士休休","description":null,"author":"Yuqiu Ji","url":"http://shamy1997.github.io","root":"/"},"pages":[{"title":"tags","date":"2019-04-05T02:48:02.000Z","updated":"2019-04-05T02:48:27.444Z","comments":true,"path":"tags/index.html","permalink":"http://shamy1997.github.io/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"2019-04-05T02:40:09.000Z","updated":"2019-04-05T02:44:03.107Z","comments":true,"path":"categories/index.html","permalink":"http://shamy1997.github.io/categories/index.html","excerpt":"","text":""},{"title":"about","date":"2019-04-05T01:54:38.000Z","updated":"2019-04-05T02:43:12.587Z","comments":true,"path":"about/index.html","permalink":"http://shamy1997.github.io/about/index.html","excerpt":"","text":"关于我尚不知如何定义……"}],"posts":[{"title":"word-embedding.md","slug":"word-embedding-md","date":"2019-08-18T02:27:04.000Z","updated":"2019-09-18T03:01:42.016Z","comments":true,"path":"passages/word-embedding-md/","link":"","permalink":"http://shamy1997.github.io/passages/word-embedding-md/","excerpt":"","text":"理解Word Embedding（1）：从Count Vector到word2vec参考博客链接: 🔗 这个 1. 什么是Word Embedding在机器学习和深度学习的任务中，我们都无法直接处理字符串或平文本，所以需要通过一种编码方式将其处理为数值，Word Embedding 就是这样将文本处理成数值的一类方法。 2. 不同的Word Embedding 类型2.1. 基于频率的Word Embedding2.1.1 Count Vectors假设一个一个语料库C有D个文本片段{d1,d2,d3,…dD} 以及N个从语料库C中提取的token。这N个token将会形成我们的词典，这样我们设定的Count Vector 大小便是 DxN。在矩阵M中，每行都包含着每个文本片段的token出现的频率。 让我们通过一个简单的例子来理解。 D1: He is lazy boy. She is also lazy. D2: Neeraj is a lazy person. 假设我们的语料库就仅有这两句话组成，那么我们的词典即为[‘He’,’She’,’lazy’,’boy’,’Neeraj’,’person’]。这里，D=2，N=6。 那么我们2x6的矩阵将被表示为： He She lazy boy Neeraj person D1 1 1 2 1 0 0 D2 0 0 1 0 1 1 这样，每一纵列便可被认为是每个单词的词向量。比如，lazy的词向量就是[2,1]，其他单词的词向量以此类推。在上图这个矩阵中，行对应着语料库中的一个个文本片段，列对应着词典中的一个个token。我们要像这样阅读这个矩阵。D2 包含了’lazy’：一次，’Neeraj’：一次以及’person’：一次。 然而，在准备上面这个矩阵M时，可能有一些变体。这些变体的变化之处在于： 准备词典的方式 你可以会疑惑为何准备词典时我们也要加以变动？事实上，在实际应用中，我们的语料库可能包含着成百上千个文本片段。那么我们就需要从这成百上千的文本片段中提取出独特的token，那么这势必会导致我们所得出的例如上图的矩阵非常稀疏，且计算时非常低效。因此，一个可选的解决方法是，我们将基于频率选取比方前10000个单词来作为我们的词典，然后再基于这个词典来构建我们的矩阵。 计算单词频次的方式 在计数时，其实我们有两种选择，一种是计算频率，即一个单词在这个文本中的次数，一种是计算是否出现，即一个单词如果在这个文中出现则为1，否则为0。但是一般情况下，我们还是倾向于使用前者。 下图是矩阵M的示意图，方便你理解： 2.1.2 TF-IDF vectorizationTF-IDF vectorization 是另一种基于频率的表示方式，但是它与 Count Vector不同在于它所考虑的不仅仅是一个单词在单个文本片段中的出现频次，而是考虑它在整个语料中的出现频率。所以，这背后有何合理性呢？让我们试着理解这一点。 比较常见的单词，例如”is”,”the”,”a”等和那些对于文本片段更为重要的片段相比往往出现得更为频繁。比如”the”这种单词在各个文本片段中都有出现，而”Harry Potter”可能只出现在《哈利波特》这部小说有关的文本片段里，但是对于这些片段来说，”Harry Potter”显然比”the”更重要，因为它把这些文本和其他文本区别开。于是我们希望降低这些较为常见的单词的权重并且更加重视那些文本片段中独特的单词。 TF-IDF就可以做到上面这一点。那么TD-IDF是如何工作的呢？ 如下图所示，假设我们有这样一个表格，第一列是文本中的token，第二列是出现的频次。 首先，我们先来定义一下TF-IDF相关的一些术语： TF：文本中term T出现的次数/文本的term总数 因此，TF(This,Doucument1)=1/8,TF(This,Document2)=1/5。 TF表示了这个单词对这个文本的贡献程度，比如说和文本更为相关的单词，它的TF值会比较大，因为它会更高频地出现在文本中。 DF：log(语料库中的文本总数/语料库中含有term T的文本数) 因此，IDF(this)=log(2/2)=0。 理论上来说，如果一个单词在语料库所有的单词中都出现了，那么可能这个单词对于某个或某些特定的文本并不重要，即是我们所说的那类比较常见的单词。但是如果一个单词只出现语料库的一个子集的文本中出现，那么这个单词对于那些文本具有一定的相关性。比如IDF(Messi)=log(2/1)=0.301。 由此可见，对于文本片段1而言，TF-IDF方法狠狠地处罚了”this”但是却给予”Messi”更高的权重。因此这个方法能够帮助我们更好的理解”Messi”是文本片段1的一个重要单词。 2.1.3 具有固定上下文窗口的共现矩阵指导思想：相似的单词往往一起出现并且具有相似的文本环境。比如”Apple is a fruit”,”Mango is a fruit”，苹果和芒果倾向于有一个相似的上下午，如”fruit”。 在我深入一个共现矩阵是如何构建的细节之前，我们有必要先理清两个概念。 Co-occurence：对于一个给定的语料库，一对单词的共现，比方说w1和w2的共现，就是在一个上下文窗口中它们共同出现的次数。 Context Window：上下文窗口的参数由数字和方向设定。我们举个例子来帮助理解。 Quick brown fox jump over the lazy dog Quick brown fox jump Over The lazy dog 这个表格第一行的斜体是fox的长度为2的上下文窗口，第二行的斜体是over的长度为2的上下文窗口。 现在，我们编一个用来计算共现矩阵的语料库。 语料库：He is not lazy. He is intelligent. He is smart. 让我们通过看上面两个红、蓝着色的例子来理解共现矩阵。 红色格子所表示的，是”He”和”is”在长度为2的上下文窗口中出现的次数，红色格子中的数字为4，我们可以通过下面的表格可视化这个计数过程。（即出现无需紧挨着，只要都在窗口中，即使顺序颠倒，都是可以的）。 蓝色格子所表示的，是”lazy”和”intelligent”在长度为2的上下文窗口中出现的次数，其中数字为0，表示它们从不曾同时出现在一个上下文窗口中。 共现矩阵的变体假设语料库中有V个独特的单词，那么我们的词汇长度即为V。下面给出了共现矩阵的两种不同变体： 大小为VxV的共现矩阵。但是由于这样的矩阵太大而难于计算，所以实际中这类建模并不被看好。 大小为VxN的共现矩阵。N表示去除掉停用词等不相关词汇后的V的一个自己。但是这类建模也依然很大且难于计算。 这里要强调一点，共现矩阵并非是我们广泛使用的词向量。相反，这类共现矩阵常常与诸如PCA，SVD这样的技术组合使用在因素分解上。而这些因素分解的组合构成了词向量表示。 说得更明白些，你在下面VxV的共现矩阵上使用了PCA，你会得到V个主元素。如此，你可以从这V个元素中选出k个。因此，你讲得到一个Vxk的新剧证。这样，虽然一个单词是由k维表示的而不是V维表示的，但是它依然能捕捉到几乎同样的意义。 因此，PCA背后的操作实际上就是讲共现矩阵拆解为三个矩阵，U，S和V。 共现矩阵的优点 它蕴含了单词之间的语义联系。比如”男人”和”女人”会比”男人”和”苹果”更近。 它的核心在于使用SVD来创造出比现存方法更准确的词向量表示。 它使用因子分解，因子分解是一个良定义问题并且可以被有效解决。 它只要被计算一次，之后任何时候都可以被使用。在这个意义上，它比其他方法更快。 共现矩阵的缺点 它需要巨大的内存去存储。 2.2 基于预测的word embedding前面所说的基于频率的word embedding有各种各样的局限。而后Mitolov等人将word2vec介绍到nlp的各个领域中，使得基于预测的word embedding走上历史舞台。这些方法是基于预测的，也就是说它们会给出各个单词的概率。它们在词汇相似度的任务上表现得非常好，甚至能达到King -man +woman = Queen这样的神奇效果。下面，我们就来看看word2vec具体是如何得出词向量的。 word2vec并不是一个单独的算法，它是由CBOW和Skip-gram模型组合而成的。这两个模型都是由词到词的浅层神经网络组成的。它们所学习的权重将成为单词的向量表示。接下来，我们就分别介绍这两种模型。 2.2.1 CBOW 连续词袋模型CBOW是基于语境（文本上下文）来预测出一个单词的概率。这个语境可能是一个单词或者一组词。但为了介绍的简单，我们这边以一个单词作为语境并一次来预测一个目标词汇。 假设我们有一个语料库C=”Hey, this is sample corpus using only one context word.”。并且我们已经定义了上下文窗口大小为1。这个语料库将会被转换成下图所示的训练集合。输入如下图所示。下图中右边的矩阵包含了左边的输入的独热编码。 比如说is的目标的输入为[0001000000]。 上图所显示的矩阵将会被送入一个由三层组成的浅层神经网络：一个输入层，一个隐藏层和一个输出层。输出层会使用softmax函数，softmax函数是一个用于分类预测的常用函数，这个函数得出的各个类别的数值总和为1。 流程是这样的： 输入层和目标层都是由1xV的独热编码组成，这里V=10。 这里有两套权重，一套是输入层和隐藏层之间的权重，一套是隐藏层和输出层之间的权重。input-hidden 层矩阵大小为VxN, hidden-output 那层的矩阵大小为NXV ：这里，N指的是我们选择用来表达单词的维度。它是任意的，并且是神经网络的一个超参数。并且，N是也是隐藏层的节点数，这里，我们设N=4。 任意一层之间都不存在激活函数。 输入与 input-hidden层权重的乘积被称为 hidden activation。 Hidden input 与hidden-output层权重相乘，得到输出。 输出层和目标之间的误差将会被用来进行反向传播，以调整weights。 在隐藏层和输出层之间权重将会成为词向量。 上面的流程是针对于上下文窗口为1的，下图显示了上下文窗口大于1的情况。 下图是为了更好理解这个结构的矩阵图例。 如上图所示，我们要使用3个 context word去预测目标单词的概率。输入层是3个[1xV]的向量，而输出是一个[1xV]。剩下的构造和1-context的CBOW是一样的。 但是在隐藏层中，3-context word的模型不再是简单复制输入，而是要进行一个平均。我们可以通过上面的图来理解这一点，如果我们有3个context word, 那么我们将会有3个 初步的hidden activation 然后最后平均得到最终的 hidden activiation。 那么CBOW和一般的MLP之间有何不同呢？ CBOW的目标函数和MLP不同，CBOW是目标函数负的最大似然。 误差梯度不一样，因为MLP以sigmoid作为激活函数，而CBOW一般是线性激活。 CBOW的优点： 基于概率的，更符合实际； 占用内存小。 CBOW的缺点： CBOW是利用单词的语境来表示单词的，但是对于多义词而言，比如苹果既是水果也是一家公司，但是由于CBOW将这个文本都考虑进去，所以苹果被表示在水果和公司之间了。 从头训练一个CBOW若没有很好优化的话将训练很久。 2.2.2 Skip-Gram modelSkip-gram 的类型与CBOW一样，但是它的结构是反过来的，它是基于给定单词去预测单词的上下文。我们依然用讲解CBOW时使用的语料。 Skip-gram的输入和1-context的CBOW 模型很类似。并且隐藏层的activitiaon也是一样的。不同的仅仅是目标变量。因为我们已经在单词两边都定义了一个长度为1的上下文窗口，所以我们会有两个独热编码的目标变量和两个相应的输出。 而这两个目标变量的误差将会被分别计算，然后将两个误差加起来进行反向传播。 Skip-Gram 模型的优点 可以抓住一个单词的多个义项。 使用负采样的Skip-Gram模型会比其他方法更高效。 Skip-Gram模型的缺点 依赖语料库的大小 采样是对统计数据的低效利用","categories":[{"name":"NLP","slug":"NLP","permalink":"http://shamy1997.github.io/categories/NLP/"}],"tags":[{"name":"Word Embedding","slug":"Word-Embedding","permalink":"http://shamy1997.github.io/tags/Word-Embedding/"}]},{"title":"理解Word Embedding（1）：从Count Vector到word2vec","slug":"Word Embedding梳理","date":"2019-07-04T07:10:50.000Z","updated":"2019-09-18T02:29:12.160Z","comments":true,"path":"passages/Word Embedding梳理/","link":"","permalink":"http://shamy1997.github.io/passages/Word Embedding梳理/","excerpt":"","text":"理解Word Embedding（1）：从Count Vector到word2vec 参考博客链接 1. 什么是Word Embedding在机器学习和深度学习的任务中，我们都无法直接处理字符串或平文本，所以需要通过一种编码方式将其处理为数值，Word Embedding 就是这样将文本处理成数值的一类方法。 2. 不同的Word Embedding 类型2.1. 基于频率的Word Embedding2.1.1 Count Vectors假设一个一个语料库C有D个文本片段{d1,d2,d3,…dD} 以及N个从语料库C中提取的token。这N个token将会形成我们的词典，这样我们设定的Count Vector 大小便是 DxN。在矩阵M中，每行都包含着每个文本片段的token出现的频率。 让我们通过一个简单的例子来理解。 D1: He is lazy boy. She is also lazy. D2: Neeraj is a lazy person. 假设我们的语料库就仅有这两句话组成，那么我们的词典即为[‘He’,’She’,’lazy’,’boy’,’Neeraj’,’person’]。这里，D=2，N=6。 那么我们2x6的矩阵将被表示为： He She lazy boy Neeraj person D1 1 1 2 1 0 0 D2 0 0 1 0 1 1 这样，每一纵列便可被认为是每个单词的词向量。比如，lazy的词向量就是[2,1]，其他单词的词向量以此类推。在上图这个矩阵中，行对应着语料库中的一个个文本片段，列对应着词典中的一个个token。我们要像这样阅读这个矩阵。D2 包含了’lazy’：一次，’Neeraj’：一次以及’person’：一次。 然而，在准备上面这个矩阵M时，可能有一些变体。这些变体的变化之处在于： 准备词典的方式 你可以会疑惑为何准备词典时我们也要加以变动？事实上，在实际应用中，我们的语料库可能包含着成百上千个文本片段。那么我们就需要从这成百上千的文本片段中提取出独特的token，那么这势必会导致我们所得出的例如上图的矩阵非常稀疏，且计算时非常低效。因此，一个可选的解决方法是，我们将基于频率选取比方前10000个单词来作为我们的词典，然后再基于这个词典来构建我们的矩阵。 计算单词频次的方式 在计数时，其实我们有两种选择，一种是计算频率，即一个单词在这个文本中的次数，一种是计算是否出现，即一个单词如果在这个文中出现则为1，否则为0。但是一般情况下，我们还是倾向于使用前者。 下图是矩阵M的示意图，方便你理解： 2.1.2 TF-IDF vectorizationTF-IDF vectorization 是另一种基于频率的表示方式，但是它与 Count Vector不同在于它所考虑的不仅仅是一个单词在单个文本片段中的出现频次，而是考虑它在整个语料中的出现频率。所以，这背后有何合理性呢？让我们试着理解这一点。 比较常见的单词，例如”is”,”the”,”a”等和那些对于文本片段更为重要的片段相比往往出现得更为频繁。比如”the”这种单词在各个文本片段中都有出现，而”Harry Potter”可能只出现在《哈利波特》这部小说有关的文本片段里，但是对于这些片段来说，”Harry Potter”显然比”the”更重要，因为它把这些文本和其他文本区别开。于是我们希望降低这些较为常见的单词的权重并且更加重视那些文本片段中独特的单词。 TF-IDF就可以做到上面这一点。那么TD-IDF是如何工作的呢？ 如下图所示，假设我们有这样一个表格，第一列是文本中的token，第二列是出现的频次。 首先，我们先来定义一下TF-IDF相关的一些术语： TF：文本中term T出现的次数/文本的term总数 因此，TF(This,Doucument1)=1/8,TF(This,Document2)=1/5。 TF表示了这个单词对这个文本的贡献程度，比如说和文本更为相关的单词，它的TF值会比较大，因为它会更高频地出现在文本中。 DF：log(语料库中的文本总数/语料库中含有term T的文本数) 因此，IDF(this)=log(2/2)=0。 理论上来说，如果一个单词在语料库所有的单词中都出现了，那么可能这个单词对于某个或某些特定的文本并不重要，即是我们所说的那类比较常见的单词。但是如果一个单词只出现语料库的一个子集的文本中出现，那么这个单词对于那些文本具有一定的相关性。比如IDF(Messi)=log(2/1)=0.301。 由此可见，对于文本片段1而言，TF-IDF方法狠狠地处罚了”this”但是却给予”Messi”更高的权重。因此这个方法能够帮助我们更好的理解”Messi”是文本片段1的一个重要单词。 2.1.3 具有固定上下文窗口的共现矩阵指导思想：相似的单词往往一起出现并且具有相似的文本环境。比如”Apple is a fruit”,”Mango is a fruit”，苹果和芒果倾向于有一个相似的上下午，如”fruit”。 在我深入一个共现矩阵是如何构建的细节之前，我们有必要先理清两个概念。 Co-occurence：对于一个给定的语料库，一对单词的共现，比方说w1和w2的共现，就是在一个上下文窗口中它们共同出现的次数。 Context Window：上下文窗口的参数由数字和方向设定。我们举个例子来帮助理解。 Quick brown fox jump over the lazy dog Quick brown fox jump Over The lazy dog 这个表格第一行的斜体是fox的长度为2的上下文窗口，第二行的斜体是over的长度为2的上下文窗口。 现在，我们编一个用来计算共现矩阵的语料库。 语料库：He is not lazy. He is intelligent. He is smart. 让我们通过看上面两个红、蓝着色的例子来理解共现矩阵。 红色格子所表示的，是”He”和”is”在长度为2的上下文窗口中出现的次数，红色格子中的数字为4，我们可以通过下面的表格可视化这个计数过程。（即出现无需紧挨着，只要都在窗口中，即使顺序颠倒，都是可以的）。 蓝色格子所表示的，是”lazy”和”intelligent”在长度为2的上下文窗口中出现的次数，其中数字为0，表示它们从不曾同时出现在一个上下文窗口中。 共现矩阵的变体假设语料库中有V个独特的单词，那么我们的词汇长度即为V。下面给出了共现矩阵的两种不同变体： 大小为VxV的共现矩阵。但是由于这样的矩阵太大而难于计算，所以实际中这类建模并不被看好。 大小为VxN的共现矩阵。N表示去除掉停用词等不相关词汇后的V的一个自己。但是这类建模也依然很大且难于计算。 这里要强调一点，共现矩阵并非是我们广泛使用的词向量。相反，这类共现矩阵常常与诸如PCA，SVD这样的技术组合使用在因素分解上。而这些因素分解的组合构成了词向量表示。 说得更明白些，你在下面VxV的共现矩阵上使用了PCA，你会得到V个主元素。如此，你可以从这V个元素中选出k个。因此，你讲得到一个Vxk的新剧证。这样，虽然一个单词是由k维表示的而不是V维表示的，但是它依然能捕捉到几乎同样的意义。 因此，PCA背后的操作实际上就是讲共现矩阵拆解为三个矩阵，U，S和V。 共现矩阵的优点 它蕴含了单词之间的语义联系。比如”男人”和”女人”会比”男人”和”苹果”更近。 它的核心在于使用SVD来创造出比现存方法更准确的词向量表示。 它使用因子分解，因子分解是一个良定义问题并且可以被有效解决。 它只要被计算一次，之后任何时候都可以被使用。在这个意义上，它比其他方法更快。 共现矩阵的缺点 它需要巨大的内存去存储。 2.2 基于预测的word embedding前面所说的基于频率的word embedding有各种各样的局限。而后Mitolov等人将word2vec介绍到nlp的各个领域中，使得基于预测的word embedding走上历史舞台。这些方法是基于预测的，也就是说它们会给出各个单词的概率。它们在词汇相似度的任务上表现得非常好，甚至能达到King -man +woman = Queen这样的神奇效果。下面，我们就来看看word2vec具体是如何得出词向量的。 word2vec并不是一个单独的算法，它是由CBOW和Skip-gram模型组合而成的。这两个模型都是由词到词的浅层神经网络组成的。它们所学习的权重将成为单词的向量表示。接下来，我们就分别介绍这两种模型。 2.2.1 CBOW 连续词袋模型CBOW是基于语境（文本上下文）来预测出一个单词的概率。这个语境可能是一个单词或者一组词。但为了介绍的简单，我们这边以一个单词作为语境并一次来预测一个目标词汇。 假设我们有一个语料库C=”Hey, this is sample corpus using only one context word.”。并且我们已经定义了上下文窗口大小为1。这个语料库将会被转换成下图所示的训练集合。输入如下图所示。下图中右边的矩阵包含了左边的输入的独热编码。 比如说is的目标的输入为[0001000000]。 上图所显示的矩阵将会被送入一个由三层组成的浅层神经网络：一个输入层，一个隐藏层和一个输出层。输出层会使用softmax函数，softmax函数是一个用于分类预测的常用函数，这个函数得出的各个类别的数值总和为1。 流程是这样的： 输入层和目标层都是由1xV的独热编码组成，这里V=10。 这里有两套权重，一套是输入层和隐藏层之间的权重，一套是隐藏层和输出层之间的权重。input-hidden 层矩阵大小为VxN, hidden-output 那层的矩阵大小为NXV ：这里，N指的是我们选择用来表达单词的维度。它是任意的，并且是神经网络的一个超参数。并且，N是也是隐藏层的节点数，这里，我们设N=4。 任意一层之间都不存在激活函数。 输入与 input-hidden层权重的乘积被称为 hidden activation。 Hidden input 与hidden-output层权重相乘，得到输出。 输出层和目标之间的误差将会被用来进行反向传播，以调整weights。 在隐藏层和输出层之间权重将会成为词向量。 上面的流程是针对于上下文窗口为1的，下图显示了上下文窗口大于1的情况。 下图是为了更好理解这个结构的矩阵图例。 如上图所示，我们要使用3个 context word去预测目标单词的概率。输入层是3个[1xV]的向量，而输出是一个[1xV]。剩下的构造和1-context的CBOW是一样的。 但是在隐藏层中，3-context word的模型不再是简单复制输入，而是要进行一个平均。我们可以通过上面的图来理解这一点，如果我们有3个context word, 那么我们将会有3个 初步的hidden activation 然后最后平均得到最终的 hidden activiation。 那么CBOW和一般的MLP之间有何不同呢？ CBOW的目标函数和MLP不同，CBOW是目标函数负的最大似然。 误差梯度不一样，因为MLP以sigmoid作为激活函数，而CBOW一般是线性激活。 CBOW的优点： 基于概率的，更符合实际； 占用内存小。 CBOW的缺点： CBOW是利用单词的语境来表示单词的，但是对于多义词而言，比如苹果既是水果也是一家公司，但是由于CBOW将这个文本都考虑进去，所以苹果被表示在水果和公司之间了。 从头训练一个CBOW若没有很好优化的话将训练很久。 2.2.2 Skip-Gram modelSkip-gram 的类型与CBOW一样，但是它的结构是反过来的，它是基于给定单词去预测单词的上下文。我们依然用讲解CBOW时使用的语料。 Skip-gram的输入和1-context的CBOW 模型很类似。并且隐藏层的activitiaon也是一样的。不同的仅仅是目标变量。因为我们已经在单词两边都定义了一个长度为1的上下文窗口，所以我们会有两个独热编码的目标变量和两个相应的输出。 而这两个目标变量的误差将会被分别计算，然后将两个误差加起来进行反向传播。 Skip-Gram 模型的优点 可以抓住一个单词的多个义项。 使用负采样的Skip-Gram模型会比其他方法更高效。 Skip-Gram模型的缺点 依赖语料库的大小 采样是对统计数据的低效利用","categories":[{"name":"NLP","slug":"NLP","permalink":"http://shamy1997.github.io/categories/NLP/"}],"tags":[{"name":"Word Embedding","slug":"Word-Embedding","permalink":"http://shamy1997.github.io/tags/Word-Embedding/"}]},{"title":"论文阅读 | Deep Semantic Role Labeling:What Works and What’s Next","slug":"srl-paper-reading-md","date":"2019-04-10T07:10:50.000Z","updated":"2019-04-10T08:08:27.967Z","comments":true,"path":"passages/srl-paper-reading-md/","link":"","permalink":"http://shamy1997.github.io/passages/srl-paper-reading-md/","excerpt":"","text":"什么是SRLSemantic Role Labeling 任务指的是围绕着谓词标记一句话的论元信息，识别出what，who，whom，when，where等信息。这是一项标记句子事件的浅层语义处理，不涉及句子的句法分析。比如对于“他昨天把书交给了张三”和“昨天书被他交给了张三”这两句话，它们在句法上不一样，但是在语义角色标注上是一样的。 语义角色标注是自然语言处理的底层任务，通过这项任务，我们可以直接获取到一句话事件性的信息，如果能够处理好，将对自动问答、自动文摘等任务产生直接而有力的帮助。 本文的模型Lu的模型之所以能够比原有的系统有那么大的提升，她认为主要原因是两方面，一方面是使用了优化过的BiLSTM模型，另一方面是对输出进行了优化编码。 优化过的BiLSTM模型Input、Output &amp; Function 训练输入$(w,v)$。 $w$代表词向量，本文使用的是GLoVe embedding，然后$v$代表是否是predicate（谓词），若是，则为1，否为0，两个都是100 dim。 输出是y(BIO-tagger) Scoring Function： $f(\\boldsymbol{w}, \\boldsymbol{y})=\\sum_{t=1}^{n} \\log p\\left(y_{t} | \\boldsymbol{w}\\right)-\\sum_{c \\in \\mathcal{C}} c\\left(\\boldsymbol{w}, y_{1 : t}\\right)$ 可能性减去惩罚值。因为输出的结果有一些限制，这些后面会讲。 为使目标函数最大进行前向反馈和反向反馈进行训练。 BiLSTMBiLSTM 的内部构造就是简单的LSTM只不过叠加了两层，即一个单元会收到前词信息也会收到后词信息。 \\begin{aligned} \\boldsymbol{i}_{l, t} &=\\sigma\\left(\\mathbf{W}_{\\mathrm{i}}^{l}\\left[\\boldsymbol{h}_{l, t+\\delta_{l}}, \\boldsymbol{x}_{l, t}\\right]+\\boldsymbol{b}_{\\mathrm{i}}^{l}\\right) \\\\ \\boldsymbol{o}_{l, t} &=\\sigma\\left(\\mathbf{W}_{\\mathrm{o}}^{l}\\left[\\boldsymbol{h}_{l, t+\\delta_{l}}, \\boldsymbol{x}_{l, t}\\right]+\\boldsymbol{b}_{\\mathrm{o}}^{l}\\right) \\\\ \\boldsymbol{f}_{l, t} &=\\sigma\\left(\\mathbf{W}_{\\mathrm{f}}^{l}\\left[\\boldsymbol{h}_{l, t+\\delta_{l}}, \\boldsymbol{x}_{l, t}\\right]+\\boldsymbol{b}_{\\mathrm{f}}^{l}+1\\right) \\\\ \\tilde{\\boldsymbol{c}}_{l, t} &=\\tanh \\left(\\mathbf{W}_{\\mathrm{c}}^{l}\\left[\\boldsymbol{h}_{l, t+\\delta_{l}}, \\boldsymbol{x}_{l, t}\\right]+\\boldsymbol{b}_{\\mathrm{c}}^{l}\\right) \\end{aligned}\\begin{aligned} \\boldsymbol{c}_{l, t} &=\\boldsymbol{i}_{l, t} \\circ \\tilde{\\boldsymbol{c}}_{l, t}+\\boldsymbol{f}_{l, t} \\circ \\boldsymbol{c}_{t+\\delta_{l}} \\\\ \\boldsymbol{h}_{l, t} &=\\boldsymbol{o}_{l, t} \\circ \\tanh \\left(\\boldsymbol{c}_{l, t}\\right) \\end{aligned}\\boldsymbol{x}_{l, t}=\\left\\{\\begin{array}{ll}{\\left[\\mathbf{W}_{\\mathrm{emb}}\\left(w_{t}\\right), \\mathbf{W}_{\\mathrm{mask}}(t=v)\\right]} & {l=1} \\\\ {\\boldsymbol{h}_{l-1, t}} & {l>1}\\end{array}\\right.\\delta_{l}=\\left\\{\\begin{array}{ll}{1} & {\\text { if } l \\text { is even }} \\\\ {-1} & {\\text { otherwise }}\\end{array}\\right. Recurrent dropout为了防止过拟合，我们会使用dropout的方法。过去的dropout我们大多使用随机生成，但是在这样复杂的网络中，如果采取之前的做法会让模型训练的噪声越来越大，为此，我们使用Recurrent dropout，这种dropout每层都是一样的（shared），因此可以减少噪声，达到防止过拟合的效果。 \\begin{aligned} \\widetilde{\\boldsymbol{h}}_{l, t} &=\\boldsymbol{r}_{l, t} \\circ \\boldsymbol{h}_{l, t}^{\\prime}+\\left(1-\\boldsymbol{r}_{l, t}\\right) \\circ \\mathbf{W}_{\\mathrm{h}}^{l} \\boldsymbol{x}_{l, t} \\\\ \\boldsymbol{h}_{l, t} &=\\boldsymbol{z}_{l} \\circ \\widetilde{\\boldsymbol{h}}_{l, t} \\end{aligned} Constrained A* decoding经过softmax层之后，我们会得到一个概率分布，但是并非选择概率最高的那个tag就是我们所要的tag，因为前词后词的tag选择并非独立，而是会相互影响的，换句话说，我们最后选择tag时会收到一些限制。 作者主要讲了有三种限制： 第一是BIO标签体系的限制，比如I-tag不能在B-前面； 第二是语义角色上的限制，比如核心的语义角色AG0-AG5，在只有一个谓词的情况下，每个最多出现1次； 第三是句法上的限制，比如句法上不同在一个父节点中的两个论元不能被标记为B-X，I-X（X指有同样的语义角色）。 针对这一问题，作者给出了一个惩罚函数来控制最后的分数，她希望选出在考虑了这些限制之后概率最大的结果。 结果比以前的模型的F1提高了10%。并通过实验证明了： Deep-BiLSTM 可以很好地解决语义角色标注中长距离依存的问题； 训练时对权重进行随机正交分解能够使训练更快开始； 句法信息对语义角色标注是有用的，未来可以考虑在惩罚函数中优化，我觉得就是能将之前特征工程中所总结的一些条件规划到这个模型里来。 后续学习 这个算法模型已经被整合到AllenNLP中，可以学习下如何在本地使用； 如何迁移到中文任务中？ 参考资料 论文 Lu关于这个模型的talk(油管)","categories":[{"name":"SRL","slug":"SRL","permalink":"http://shamy1997.github.io/categories/SRL/"}],"tags":[{"name":"SRL","slug":"SRL","permalink":"http://shamy1997.github.io/tags/SRL/"},{"name":"paper-reading","slug":"paper-reading","permalink":"http://shamy1997.github.io/tags/paper-reading/"},{"name":"NLP","slug":"NLP","permalink":"http://shamy1997.github.io/tags/NLP/"}]},{"title":"终端命令笔记","slug":"about-terminal","date":"2018-12-22T12:37:49.000Z","updated":"2018-12-22T13:02:22.472Z","comments":true,"path":"passages/about-terminal/","link":"","permalink":"http://shamy1997.github.io/passages/about-terminal/","excerpt":"","text":"vi 常用命令1. \b进入 vi 编辑器1sudo vi &lt;path&gt; 2. 修改内容输入i，进入insert模式。按esc，退出模式。 3. 保存，退出 :w 保存文件但不退出vi; :wq 保存文件并退出vi; q: 不保存文件，退出vi :e! 放弃所有修改，从上次保存文件开始再编辑 vi命令大全 Jupyter or conda not found我安装好anaconda后，打算用命令行直接打开jupyter notebook，结果却没有成功，网上一般的解释是要把anaconda配置到环境变量里：在终端中输入： 1sudo vi ~/.bash_profile 打开后在末尾加上： 1234567export PATH='~/anaconda/bin:$PATH'# 这里的path要根据anaconda所在的位置定义source ~/.bash_profile# 表示修改立即生效 但是呢，我试了好几次都没有成功，事实上，是我配置了oh-my-zsh的原因。 因此，正确的解决方法是，打开~/.zshrc，然后在文件最后一行添加： 1export PATH=$PATH:$HOME/anaconda/bin 保存文件后，关闭窗口\b，重新开启窗口时，输入命令conda --v来检测是否成功。 参考链接🔗 zsh not found1exec /bin/zsh 参考资料🔗","categories":[],"tags":[{"name":"命令行","slug":"命令行","permalink":"http://shamy1997.github.io/tags/命令行/"}]},{"title":"Slot Filling with SimpleRNN","slug":"slot-filling","date":"2018-09-10T02:20:20.000Z","updated":"2019-01-20T12:04:25.961Z","comments":true,"path":"passages/slot-filling/","link":"","permalink":"http://shamy1997.github.io/passages/slot-filling/","excerpt":"","text":"什么是Slot Filling？Slot Filling是自然语言理解中的一个基本问题，是对语言含义的简单化处理，它的思想类似于语言学中框架主义的一派，先设定好特定的语言类型槽，再将输入的单词一一填入槽内，而获取言语含义的时候即是根据语义槽的含义进行提取和检索。我们这里的任务就是将表示定购航班（ATIS数据集）这一言语行为的一系列语句填入各种类型的语义槽中。 为什么使用SimpleRNN?Slot Filling属于RNN应用中一对一的应用，通过训练模型，每个词都能被填到合适的槽中。RNN和一般的神经网络的不同在于，在RNN中，我们在时间t的输出不仅取决于当前的输入和权重，还取决于之前的输入，而对于其他神经网络模型，每个时刻的输入和输出都是独立而随机的，没有相关性。放到我们要处理语义理解的问题上看，语言作为一种基于时间的线性输出，显然会受到前词的影响，因此我们选取RNN模型来进行解决这个问题。这里选取SimpleRNN,是因为这个RNN比较简单，能达到熟悉框架的练习效果，之后可以选取其他有效的RNN模型，如LSTMS进行优化。 构建思路一览： 载入数据，使用的是chsasank修改的mesnilgr的load.py。 定义模型。采取Keras中的序列模型搭建，首先使用一个100维的word embedding层将输入的单词转化为高维空间中的一个向量（在这个空间中，语义和语法位置越近的单词的距离越小），然后我们构建一个dropout层防止过拟合，设置SimpleRNN层，设置TimeDistributed层以完成基于时间的反向传播。最后我们将这些层组织在一起，并确定optimizer和loss function。我们选取的optimizer是rmsprop,这样在训练后期依然能找到较有项，而选取categorical_crossentropy作为损失函数，则是因为处理的问题性质适合于此。 训练模型。出于对计算资源的考虑，我们一般使用minibtach的方法批量对模型进行训练。但是我们这里的数据是一句句话，如果按照一个固定的batch_size将其分裂，可能增加了不必要的联系（因为上下两句话是独立的），因此我们将一句话作为一个batch去进行训练、验证以及预测，并手动算出一个epoch的平均误差。 评估和预测模型。我们通过观察验证误差和预测F1精度来对模型进行评估。预测F1精度使用的是signsmile编写的conlleval.py。 保存模型。 123456789101112import numpy as npimport picklefrom keras.models import Sequentialfrom keras.layers.embeddings import Embeddingfrom keras.layers.recurrent import SimpleRNNfrom keras.layers.core import Dense,Dropoutfrom keras.utils import to_categoricalfrom keras.layers.wrappers import TimeDistributedfrom matplotlib import pyplot as pltimport data.loadfrom metrics.accuracy import evaluate Using TensorFlow backend. Load Data123456train_set,valid_set,dicts = data.load.atisfull()# print(train_set[:1])# dicts = &#123;'label2idx':&#123;&#125;,'words2idx':&#123;&#125;,'table2idx':&#123;&#125;&#125;w2idx,labels2idx = dicts['words2idx'],dicts['labels2idx']train_x,_,train_label = train_setval_x,_,val_label = valid_set 12idx2w = &#123;w2idx[i]:i for i in w2idx&#125;idx2lab = &#123;labels2idx[i]:i for i in labels2idx&#125; 12n_classes = len(idx2lab)n_vocab = len(idx2w) 123456789101112131415words_train = [[idx2w[i] for i in w[:]] for w in train_x]labels_train = [[idx2lab[i] for i in w[:]] for w in train_label]words_val = [[idx2w[i] for i in w[:]] for w in val_x]# labels_val = [[idx2lab[i] for i in w[:]] for w in val_label]labels_val =[]for w in val_label: for i in w[:]: labels_val.append(idx2lab[i])print('Real Sentence : &#123;&#125;'.format(words_train[0]))print('Encoded Form : &#123;&#125;'.format(train_x[0]))print('='*40)print('Real Label : &#123;&#125;'.format(labels_train[0]))print('Encoded Form : &#123;&#125;'.format(train_label[0])) Real Sentence : [&#39;i&#39;, &#39;want&#39;, &#39;to&#39;, &#39;fly&#39;, &#39;from&#39;, &#39;boston&#39;, &#39;at&#39;, &#39;DIGITDIGITDIGIT&#39;, &#39;am&#39;, &#39;and&#39;, &#39;arrive&#39;, &#39;in&#39;, &#39;denver&#39;, &#39;at&#39;, &#39;DIGITDIGITDIGITDIGIT&#39;, &#39;in&#39;, &#39;the&#39;, &#39;morning&#39;] Encoded Form : [232 542 502 196 208 77 62 10 35 40 58 234 137 62 11 234 481 321] ======================================== Real Label : [&#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;B-fromloc.city_name&#39;, &#39;O&#39;, &#39;B-depart_time.time&#39;, &#39;I-depart_time.time&#39;, &#39;O&#39;, &#39;O&#39;, &#39;O&#39;, &#39;B-toloc.city_name&#39;, &#39;O&#39;, &#39;B-arrive_time.time&#39;, &#39;O&#39;, &#39;O&#39;, &#39;B-arrive_time.period_of_day&#39;] Encoded Form : [126 126 126 126 126 48 126 35 99 126 126 126 78 126 14 126 126 12] Define and Compile the model1234567model = Sequential()model.add(Embedding(n_vocab,100))model.add(Dropout(0.25))model.add(SimpleRNN(100,return_sequences=True))model.add(TimeDistributed(Dense(n_classes,activation='softmax')))model.compile(optimizer = 'rmsprop',loss = 'categorical_crossentropy')model.summary() _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= embedding_1 (Embedding) (None, None, 100) 57200 _________________________________________________________________ dropout_1 (Dropout) (None, None, 100) 0 _________________________________________________________________ simple_rnn_1 (SimpleRNN) (None, None, 100) 20100 _________________________________________________________________ time_distributed_1 (TimeDist (None, None, 127) 12827 ================================================================= Total params: 90,127 Trainable params: 90,127 Non-trainable params: 0 _________________________________________________________________ Train the model1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950def train_the_model(n_epochs,train_x,train_label,val_x,val_label): epoch,train_avgloss,val_avgloss,f1s = [],[],[],[] for i in range(1,n_epochs+1): epoch.append(i) ## training train_avg_loss =0 for n_batch,sent in enumerate(train_x): label = train_label[n_batch] # label to one-hot label = to_categorical(label,num_classes=n_classes)[np.newaxis,:] sent = sent[np.newaxis,:] loss = model.train_on_batch(sent,label) train_avg_loss += loss train_avg_loss = train_avg_loss/n_batch train_avgloss.append(train_avg_loss) ## evaluate&amp;predict val_pred_label,pred_label_val,val_avg_loss = [],[],0 for n_batch,sent in enumerate(val_x): label = val_label[n_batch] label = to_categorical(label,num_classes=n_classes)[np.newaxis,:] sent = sent[np.newaxis,:] loss = model.test_on_batch(sent,label) val_avg_loss += loss pred = model.predict_on_batch(sent) pred = np.argmax(pred,-1)[0] val_pred_label.append(pred) val_avg_loss = val_avg_loss/n_batch val_avgloss.append(val_avg_loss) for w in val_pred_label: for k in w[:]: pred_label_val.append(idx2lab[k]) prec, rec, f1 = evaluate(labels_val,pred_label_val, verbose=False) print('Training epoch &#123;&#125;\\t train_avg_loss = &#123;&#125; \\t val_avg_loss = &#123;&#125;'.format(i,train_avg_loss,val_avg_loss)) print('precision: &#123;:.2f&#125;% \\t recall: &#123;:.2f&#125;% \\t f1 :&#123;:.2f&#125;%'.format(prec,rec,f1)) print('-'*60) f1s.append(f1) # return epoch,pred_label_train,train_avgloss,pred_label_val,val_avgloss return epoch,f1s,val_avgloss,train_avgloss 1epoch,f1s,val_avgloss,train_avgloss = train_the_model(40,train_x,train_label,val_x,val_label) 输出：1234567891011121314 Training epoch 1 train_avg_loss = 0.5546463992293973 val_avg_loss = 0.4345020865901363 precision: 84.79% recall: 80.79% f1 :82.74% ------------------------------------------------------------ Training epoch 2 train_avg_loss = 0.2575569036037627 val_avg_loss = 0.36228470020366654 precision: 86.64% recall: 83.86% f1 :85.22% ------------------------------------------------------------ Training epoch 3 train_avg_loss = 0.2238766908014994 val_avg_loss = 0.33974187403771694 precision: 88.03% recall: 85.55% f1 :86.77% ------------------------------------------------------------…… ------------------------------------------------------------ Training epoch 40 train_avg_loss = 0.09190682124901069 val_avg_loss = 0.2697056618613356 precision: 92.51% recall: 91.47% f1 :91.99% ------------------------------------------------------------ 可视化观察验证误差，选取合适的epoch。 123456%matplotlib inlineplt.xlabel=('epoch')plt.ylabel=('loss')plt.plot(epoch,train_avgloss,'b')plt.plot(epoch,val_avgloss,'r',label=('validation error'))plt.show() 1print('最大f1值为 &#123;:.2f&#125;%'.format(max(f1s))) 最大f1值为 92.56% 保存模型1model.save('slot_filling_with_simpleRNN.h5') 结果分析使用SimpleRNN最终得到的F1值为92.56%，和师兄的95.47%相比确实还相差很多。这主要是和我们模型的选取有关，SimpleRNN只能将前词的影响带入到模型中，但是语言中后词对前词也会有一定的影响，因此可以通过选择更加复杂的模型或者增加能够捕捉到后词信息的层来进行优化。 参考资料 Keras Tutorial - Spoken Language Understanding pytorch-slot-filling liu946 AtisSlotLabeling 【Keras情感分类】训练过程中出现的问题汇总 keras-SimpleRNN 机器学习中过拟合的解决办法","categories":[],"tags":[{"name":"NLP","slug":"NLP","permalink":"http://shamy1997.github.io/tags/NLP/"},{"name":"keras","slug":"keras","permalink":"http://shamy1997.github.io/tags/keras/"},{"name":"RNN","slug":"RNN","permalink":"http://shamy1997.github.io/tags/RNN/"}]},{"title":"TensorFlow小试牛刀","slug":"tf小试牛刀","date":"2018-09-02T16:02:32.000Z","updated":"2019-01-20T12:02:50.287Z","comments":true,"path":"passages/tf小试牛刀/","link":"","permalink":"http://shamy1997.github.io/passages/tf小试牛刀/","excerpt":"","text":"此日志为参照Udacity课程中《Intro to tensorflow》的jupyter notebook所做的分解源码，目的在于理解代码逻辑，熟悉创建流程和套路。其中参考了不少博文链接，非常感谢，全部放在文末，在原文中不再指出。 数据链接：百度云：NoMNIST 密码：fsks P1:预处理数据123456789101112import hashlibimport osimport picklefrom urllib.request import urlretrieveimport numpy as npfrom PIL import Imagefrom sklearn.model_selection import train_test_splitfrom sklearn.preprocessing import LabelBinarizerfrom sklearn.utils import resamplefrom tqdm import tqdmfrom zipfile import ZipFile 解压图片文件1234567891011121314151617181920212223242526272829303132333435363738394041def uncompress_features_labels(file): \"\"\" Uncompress features and labels from a zip file :param file: The zip file to extract the data from \"\"\" features = [] labels = [] with ZipFile(file) as zipf: # Progress Bar filenames_pbar = tqdm(zipf.namelist(), unit='files') # Get features and labels from all files for filename in filenames_pbar: # Check if the file is a directory if not filename.endswith('/'): with zipf.open(filename) as image_file: image = Image.open(image_file) image.load() # Load image data as 1 dimensional array # We're using float32 to save on memory space feature = np.array(image, dtype=np.float32).flatten() # Get the the letter from the filename. This is the letter of the image. label = os.path.split(filename)[1][0] features.append(feature) labels.append(label) return np.array(features), np.array(labels)# Get the features and labels from the zip filestrain_features, train_labels = uncompress_features_labels('notMNIST_train.zip')test_features, test_labels = uncompress_features_labels('notMNIST_test.zip')# Limit the amount of data to work with a docker containerdocker_size_limit = 150000train_features, train_labels = resample(train_features, train_labels, n_samples=docker_size_limit)# Set flags for feature engineering. This will prevent you from skipping an important step.is_features_normal = Falseis_labels_encod = False 12100%|█████████████████████████████████████████████████████████████████████| 210001/210001 [00:54&lt;00:00, 3832.78files/s]100%|███████████████████████████████████████████████████████████████████████| 10001/10001 [00:03&lt;00:00, 3207.15files/s] Min-Max ScalingImplement Min-Max scaling in the normalize_grayscale() function to a range of a=0.1 and b=0.9. After scaling, the values of the pixels in the input data should range from 0.1 to 0.9. Since the raw notMNIST image data is in grayscale, the current values range from a min of 0 to a max of 255. Min-Max Scaling:$X’=a+{\\frac {\\left(X-X_{\\min }\\right)\\left(b-a\\right)}{X_{\\max }-X_{\\min }}}$ 123456789101112def normalize_grayscale(image_data): \"\"\" Normalize the image data with Min-Max scaling to a range of [0.1, 0.9] :param image_data: The image data to be normalized :return: Normalized image data \"\"\" a = 0.1 b = 0.9 max_grayscale = 255 min_grayscale = 0 return a+((image_data-min_grayscale))*(b-a)/(max_grayscale-min_grayscale) 12train_features = normalize_grayscale(train_features)test_features = normalize_grayscale(test_features) 标签二值化LabelBinarizer()是sklearn.preprocession中用来将非数值类标签转换为独热编码向量的函数。 123456789# Create the encoder 创建编码器encoder = LabelBinarizer()# 编码器找到类别并分配 one-hot 向量encoder.fit(train_labels)#最后把目标（lables）转换成独热编码的（one-hot encoded）向量train_labels = encoder.transform(train_labels)test_labels = encoder.transform(test_labels) 转换数据类型，这样后面公式中才可以进行运算。 12train_labels = train_labels.astype(np.float32)test_labels = test_labels.astype(np.float32) 随机划分训练集和测试集常见形式为：X_train,X_test, y_train, y_test =cross_validation.train_test_split(train_data,train_target,test_size=0.4, random_state=0) 参数解释： train_data：所要划分的样本特征集 train_target：所要划分的样本结果 test_size：样本占比，如果是整数的话就是样本的数量 random_state：是随机数的种子。 随机数种子：其实就是该组随机数的编号，在需要重复试验的时候，保证得到一组一样的随机数。比如你每次都填1，其他参数一样的情况下你得到的随机数组是一样的。但填0或不填，每次都会不一样。 123456# Get randomized datasets for training and validationtrain_features, valid_features, train_labels, valid_labels = train_test_split( train_features, train_labels, test_size=0.05, random_state=832289) 打包数据方便下次取用序列化的方法为 pickle.dump()，该方法的相关参数如下：pickle.dump(obj, file, protocol=None,*,fix_imports=True) 1234567891011121314151617181920# 新建pickle_file# 参数file必须是以二进制的形式进行操作,即「wb」pickle_file = 'notMNIST.pickle'if not os.path.isfile(pickle_file): print('Saving data to pickle file...') try: with open('notMNIST.pickle', 'wb') as pfile: pickle.dump( &#123; 'train_dataset': train_features, 'train_labels': train_labels, 'valid_dataset': valid_features, 'valid_labels': valid_labels, 'test_dataset': test_features, 'test_labels': test_labels, &#125;, pfile, pickle.HIGHEST_PROTOCOL) except Exception as e: print('Unable to save data to', pickle_file, ':', e) raise P2:从预处理好的pickle中读取数据12345678910111213141516171819202122%matplotlib inline# Load the modulesimport pickleimport mathimport numpy as npimport tensorflow as tffrom tqdm import tqdmimport matplotlib.pyplot as plt# Reload the datapickle_file = 'notMNIST.pickle'with open(pickle_file, 'rb') as f: pickle_data = pickle.load(f) train_features = pickle_data['train_dataset'] train_labels = pickle_data['train_labels'] valid_features = pickle_data['valid_dataset'] valid_labels = pickle_data['valid_labels'] test_features = pickle_data['test_dataset'] test_labels = pickle_data['test_labels'] del pickle_data # Free up memory C:\\Users\\10677\\Anaconda3\\envs\\keras\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters 使用TF创建单层神经网络接下来，我们使用TensorFlow创建一个只有一个输入层和输出层的神经网络，激活函数为softmax。在TensorFlow中，数据不是以整数、浮点数或字符串的形式存储的，而是以tensor对象的形式被存储的。 在tensor中传递值有两种方法： 使用tf.constant()，传入变量，但是传入之后就不可变了 如果要使数据可变，结合tf.placeholder()和tf.feed_dict来输入 1234567891011121314151617181920212223242526272829303132333435363738394041# All the pixels in the image (28 * 28 = 784)features_count = 784# All the labels (\"A,B...J\")labels_count = 10features = tf.placeholder(tf.float32)labels = tf.placeholder(tf.float32)# Set the weights and biases tensors# tf.truncated_normal:生成正态分布的随机值# weights已经随机化，biases就不必随机，简化为0即可weights = tf.Variable(tf.truncated_normal((features_count,labels_count)))biases = tf.Variable(tf.zeros(labels_count))# Feed dicts for training, validation, and test sessiontrain_feed_dict = &#123;features: train_features, labels: train_labels&#125;valid_feed_dict = &#123;features: valid_features, labels: valid_labels&#125;test_feed_dict = &#123;features: test_features, labels: test_labels&#125;# Linear Function WX + blogits = tf.matmul(features, weights) + biasesprediction = tf.nn.softmax(logits)# Cross entropycross_entropy = -tf.reduce_sum(labels * tf.log(prediction), reduction_indices=1)# Training lossloss = tf.reduce_mean(cross_entropy)# Create an operation that initializes all variablesinit = tf.global_variables_initializer()# Test Caseswith tf.Session() as session: session.run(init) session.run(loss, feed_dict=train_feed_dict) session.run(loss, feed_dict=valid_feed_dict) session.run(loss, feed_dict=test_feed_dict) biases_data = session.run(biases) 12is_correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(labels, 1))accuracy = tf.reduce_mean(tf.cast(is_correct_prediction, tf.float32)) P3:训练神经网络1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374# Change if you have memory restrictionsbatch_size = 128# Find the best parameters for each configurationepochs = 4learning_rate = 0.2# Gradient Descent# 使用梯度下降进行训练optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss) # The accuracy measured against the validation setvalidation_accuracy = 0.0# Measurements use for graphing loss and accuracylog_batch_step = 50batches = []loss_batch = []train_acc_batch = []valid_acc_batch = []with tf.Session() as session: session.run(init) batch_count = int(math.ceil(len(train_features)/batch_size)) for epoch_i in range(epochs): # Progress bar batches_pbar = tqdm(range(batch_count), desc='Epoch &#123;:&gt;2&#125;/&#123;&#125;'.format(epoch_i+1, epochs), unit='batches') # The training cycle for batch_i in batches_pbar: # Get a batch of training features and labels batch_start = batch_i*batch_size batch_features = train_features[batch_start:batch_start + batch_size] batch_labels = train_labels[batch_start:batch_start + batch_size] # Run optimizer and get loss _, l = session.run( [optimizer, loss], feed_dict=&#123;features: batch_features, labels: batch_labels&#125;) # Log every 50 batches if not batch_i % log_batch_step: # Calculate Training and Validation accuracy training_accuracy = session.run(accuracy, feed_dict=train_feed_dict) validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict) # Log batches previous_batch = batches[-1] if batches else 0 batches.append(log_batch_step + previous_batch) loss_batch.append(l) train_acc_batch.append(training_accuracy) valid_acc_batch.append(validation_accuracy) # Check accuracy against Validation data validation_accuracy = session.run(accuracy, feed_dict=valid_feed_dict)loss_plot = plt.subplot(211)loss_plot.set_title('Loss')loss_plot.plot(batches, loss_batch, 'g')loss_plot.set_xlim([batches[0], batches[-1]])acc_plot = plt.subplot(212)acc_plot.set_title('Accuracy')acc_plot.plot(batches, train_acc_batch, 'r', label='Training Accuracy')acc_plot.plot(batches, valid_acc_batch, 'x', label='Validation Accuracy')acc_plot.set_ylim([0, 1.0])acc_plot.set_xlim([batches[0], batches[-1]])acc_plot.legend(loc=4)plt.tight_layout()plt.show()print('Validation accuracy at &#123;&#125;'.format(validation_accuracy)) Epoch 1/4: 100%|████████████████████████████████████████████████████████████| 1114/1114 [00:11&lt;00:00, 101.27batches/s] Epoch 2/4: 100%|████████████████████████████████████████████████████████████| 1114/1114 [00:10&lt;00:00, 101.99batches/s] Epoch 3/4: 100%|████████████████████████████████████████████████████████████| 1114/1114 [00:10&lt;00:00, 101.38batches/s] Epoch 4/4: 100%|█████████████████████████████████████████████████████████████| 1114/1114 [00:12&lt;00:00, 92.55batches/s] Validation accuracy at 0.7662666440010071 P4:检测12345678910111213141516171819202122232425262728test_accuracy = 0.0with tf.Session() as session: session.run(init) batch_count = int(math.ceil(len(train_features)/batch_size)) for epoch_i in range(epochs): # Progress bar batches_pbar = tqdm(range(batch_count), desc='Epoch &#123;:&gt;2&#125;/&#123;&#125;'.format(epoch_i+1, epochs), unit='batches') # The training cycle for batch_i in batches_pbar: # Get a batch of training features and labels batch_start = batch_i*batch_size batch_features = train_features[batch_start:batch_start + batch_size] batch_labels = train_labels[batch_start:batch_start + batch_size] # Run optimizer _ = session.run(optimizer, feed_dict=&#123;features: batch_features, labels: batch_labels&#125;) # Check accuracy against Test data test_accuracy = session.run(accuracy, feed_dict=test_feed_dict)assert test_accuracy &gt;= 0.80, 'Test accuracy at &#123;&#125;, should be equal to or greater than 0.80'.format(test_accuracy)print('Nice Job! Test Accuracy is &#123;&#125;'.format(test_accuracy)) Epoch 1/4: 100%|████████████████████████████████████████████████████████████| 1114/1114 [00:01&lt;00:00, 588.57batches/s] Epoch 2/4: 100%|████████████████████████████████████████████████████████████| 1114/1114 [00:01&lt;00:00, 634.64batches/s] Epoch 3/4: 100%|████████████████████████████████████████████████████████████| 1114/1114 [00:01&lt;00:00, 633.74batches/s] Epoch 4/4: 100%|████████████████████████████████████████████████████████████| 1114/1114 [00:01&lt;00:00, 638.60batches/s] Nice Job! Test Accuracy is 0.8468999862670898 参考链接： python tqdm模块分析 Sklearn-train_test_split随机划分训练集和测试集 numpy_ndarray.flatten sklearn.LabelBinarizer","categories":[],"tags":[{"name":"tensorflow","slug":"tensorflow","permalink":"http://shamy1997.github.io/tags/tensorflow/"},{"name":"深度学习","slug":"深度学习","permalink":"http://shamy1997.github.io/tags/深度学习/"}]},{"title":"北大分词方案解读及颗粒度分词方案","slug":"颗粒度分词调研","date":"2018-08-30T06:23:49.000Z","updated":"2019-01-20T11:41:16.746Z","comments":true,"path":"passages/颗粒度分词调研/","link":"","permalink":"http://shamy1997.github.io/passages/颗粒度分词调研/","excerpt":"","text":"一、调研资料 北大现代汉语语料库基本加工规范 计算所汉语词性标注集 几个开源分词系统所使用标注集的来源 海量中文智能分词接口手册 阿里多粒度分词专利 腾讯多粒度分词专利 百度多粒度分词专利 KTDictSeg 分词组件1.3版本 部分算法讨论 — 分词粒度 二、调研目的分词单位不同于语言学中的“词”，不同的算法下的分词结果千差万别，有的分出的是语言学意义上的词，而有的分出的是语言学意义上的“短语”（或者说“词组”）因此，我们希望寻找一个可理解的统一的粒度标准，而这个粒度标准能够实现对不同分词任务的不同层次的分词。为证实多颗粒度的分词标注确实能提高特定的分词任务的准确率，我们进行了这样的前期调研。通过搜集资料，我们以北大方案为蓝本，以一定的语言学知识为基础，对分词颗粒进行不同粒度的划分。首先对北大分词方案进行解读，然后再阐释我对分词粒度初步的构建想法。 注：颗粒度方案只考虑分词问题，不考虑词性标注。 三、北大分词方案讲解1. 分词单位的概念界定分词单位，“指信息处理中使用的、具有确定的语义和语法功能的基本单位”，该概念明确了其使用的特定环境——“信息处理任务”，以及其语义和语法功能明确的特点。 基于这样的概念划分，北大方案认定的分词单位里不仅包括了词，还“包括了一部分结合紧密、使用稳定的词组”，并且“在某些特殊情况孤立的语素或非语素字”。 事实上，我们撇开北大方案来看词这个整体，根据朱德熙先生的划分，可以分为可穷尽的虚词类和不可穷尽的实词类。虚词类，举例来说，包括连词、语气词、介词等，这类词可以在语法词典中被枚举出来，因此在进行分词时难度较小。因此，分词的困难常常出现在实词的切分上。 结合北大方案的划分，我认为对实词序列进行划分时，一般可以遵照以下原则： （1）依据语法词典来划分，如果语法词典中进行规定，那么就不做划分。语言是约定俗成的产物，当某个词语组合被广泛而稳定地使用时，那么社会团体便会接受这样的一个“新词”，因此这样的一个词语组合也可以被视作是一个分词单位。而判断社会团体是否已经接受这一语言现象很显性的一大标志便是词典收录了该词条。那么问题就转变为，什么样的词典可以成为可供划分的语法词典。 （2）考虑切分序列的音节组合。汉语在发展过程中经历了一个从单音节向双音节的发展过程。虽然现代汉语以双音节为主要的成词单位，但是古代汉语中的一些单音节词依然残存在现代汉语中，并且在一些特殊语体中还广泛地存在着。因此，对于那些单音节成词的单位在标注时要格外注意标记出来，而处理多音节序列时，则要尽量保证分词结果以双音节为一个单位。 （3）考虑到词义与语素结合义。我们所认定的分词单位，它的词义是凝合而成的，而不是两个语素的意义简单的相加。因此，如果一个切分单位的语义是其切分单位意义的简单相加，那么就要对其进行切分。而判定是否是词义简单的相加的方法主要有“的”插入法和替换法两种，这在后面具体的讲解中会进行阐释。 （4）要考虑到切分的经济性。北大方案是切分和标注同时进行，为了保证标注符号使用的经济性，方案要求，要保证切分出来的单位尽量少的是无法独立成词的语素。因此，对于一个切分序列，如果我们切分后多出了无法独立成词的语素，比如说前接成分、后接成分等，我们尽可能地不去切分它。 2.分词实际情况中的应用接下来，我们将对分词方案的第四章、第五章结合我们总结出来的规则进行精简式的说明。 （1）人名 对于人名的切分，方案给出的切分标准是姓和名切分开。而对于其他称呼是否切分，可以用语义规则来解释。第二条规则：姓名后的职务、职称或称呼要分开。第四条规则：带明显排行的亲属称谓要切分开。这两条规则是因为组成的切分序列的意思即是各组成成分的组合义，因此要切分。而第三条规则：对人的简称、尊称若为两个字，则合为一个切分单位。不仅是因为这些切分序列的含义不是其组成成分的组合义，至少有表示尊敬的社会含义，还是因为如果切分，会多出无法独立成词的语素，因此把这些双音节作为一个切分单位。而对于外国人名和笔名、著名人名，我们不做切分，一是因为这种命名是随意的，切分下来的意义不大；二是因为著名人名是在语法词典中就规定了的内容。 （2）地名 大部分地名都是在语法词典中事先规定了的，除此以外的切分原则主要是和音节有关，如果地名后接的是单音节语素，则不切分；如果接的是双音节或多音节语素，则要进行切分。 （3）团体、机构、组织的专有名称 对于团体、机构、组织的专有名称，如果它们被语法词典收录，那么肯定不切分，如果没有，则要进行切分。（如果找不到这样合适的词典，一个PLAN B的建议：按照普通词组切分，再上游任务中再识别出来） （4）除人名、国名、地名、团体、机构、组织以外的其他专名 首先，我们还是要考虑其是否被语法词典收录。然后要考虑其后接语素的音节，如果是单音节的，如“人”“族”这样的，不切分，如果是多音节的，则要进行切分。 （5）数词与数量词组 数词与数量词组的规定是另外的。详见方案。 （6）时间词 时间词中登录在语法词典中的，比如历史朝代的名称，特殊的年份“甲午年”等，不做切分，其他的要按照“年、月、日、时、分、秒”的层次进行切分。 （7）单音节代词“本”、“每”、“各”、“诸 若后接成分是单音节名词，则不做切分，若是双音节或多音节，则要切分开。 （8）区别词 首先，我们要明确何为区别词，区别词指的是成对的，有分类性质的一类词，它们只能够做定语，不能做谓语，所以又称为非谓形容词。 举例来说，区别词包括：男、女、雌、雄、单、双、复、金、银、西式、中式、古代、近代、现代、当代、阴性、阳性、军用、民用、国有、私有、小型、中型、大型、微型、有期、无期、彩色、黑白、急性、慢性、小号、中号、大号、野生、家养、正式、非正式、人造（从动词过来的）、天然、冒牌、正牌、正版、盗版、下等、中等、上等、初级、中级、高级、中式、欧式等等。 对于含有区别词的序列，我们的切分原则也是同样按照音节来进行，如果区别词后接一个单音节名词，则不切分，若接的是多音节名词，则要切分。 （9）述补结构 简单来说，述补结构指的是描述一个动词发生的情貌或结果，即对动词所代表的事件进行的补充。对于双音节的述补结构我们的切分原则是，如果进行切分后，会有无法独立成词的语素存在，则不切分，反之，则切分。 述补结构中还有一类常见的多音节的“得”字补语，对于这类述补结构，我们可以将“得”字去掉，若去掉后依然能成词，则要将其切分；若不能成词，则“得”字补语整体作为一个分词单位，内部不做切分。 （10）、（11）、（12）、（13）略 （14）语素和非语素字的处理 对于离合词的离析形式，要进行切分。所谓离合词，指的是可以在组合的两个语素中插入其他成分的词，比如“吃饭”，它的离析形式有，“吃了饭”“吃了一个饭”等。 对于表示方位的双音节词，若切分出无法独立成词的语素，则不切分，否则则要进行切分。 （15）文本中非汉字的字符串 略 （16）重叠 重叠是汉语独特的语言现象之一。北大方案中对这类词的切分看似复杂，实质上是切分到能够独立使用的单位，并且要避免切分出不能单独成词的语素。 比如，“甜甜的蜂蜜”，由于“甜甜”不能单独成词，因此要切分到“甜甜的”。 而“试试看”由于“看”这里表示动作的尝试，作为这个意义并不能单独运用，因此不切分。 （17）附加成分 附加成分实质上指的是构词中的前缀和后缀。汉语构词法中有一类是依据词缀加词根进行的派生构词。对于这一类切分序列，除非其接入成分太多，会对其进行切分，否则不切分。比如“老师们”就不做切分，“苦苦追求而不得者”中的“者”由于统摄的成分太多，所以要单独切分开。 （18）复合词构词 在切分复合词的问题上，北大方案是存在讨论的余地的。由于复合词本身和短语之间的界限较为模糊，即使在语言学意义的界定上也会存在分歧，因此对于复合词类型的切分序列是否切分，实质上很难回答。北大方案给出的解决办法是，首先如果切分后会有无法独立成词的成分，那么就不切分；另外要判断这个复合词的意义是否只是组成成分的简单相加，如果是，那么就切分，如果不是，那就说明组成该词的两个成分之间意义是有相互渗透的联结的，就不能切分。但是如何判断复合词意义是否是组合成分的相加呢？ 这里的方法主要有两个，一个是加“的”法。这个方法主要针对的是定中结构的复合词，即一个语素修饰另一个语素。比如“白花”，和“白的花”意义一致，那么就要切分。 第二个方法是替换法，将复合词“AB”的A语素拿出来进行组词，再将B语素拿出来进行组词，若单独组词后其词义都是一样的，那么就说明复合词AB的词义是A语素义和B语素义的相加，因此要切分；若有A语素或B语素有和其他组词情况中语义不同的，那么就不切分复合词AB。 但是这两个方法并不能解决所有的复合词判断问题，因此到底是将问题简化还是对规则进一步细致，是值得思考的。 颗粒度方案（调整版）调整内容： 将原来的第一粒度作为细粒度（非常细，存在语义不透明的词缀），将第二粒度和第三粒度合并成为粗粒度），针对专有名词的问题，划出粗粒度2级（这个可以讨论，是在分词中一下子划分出来，还是在上游任务中再处理。在参考资料的专利中，他们往往在分词中就解决了）。 理清实体和专有名词的区别细粒度 单音词 单独一个语素即可成词的，如“火、书、水” 连绵词 必须和其他语素结合成词的，且结合的语素是固定的，如“葡萄”“乒乓” 音译词 包括了外国的专名（人名等） 数词 量词 比如：条、串、张 这里要注意一些从名词发展过来的量词，比如“碗” 这里包括度量：3/cm，7/天 另外细粒度中，时间数和时间单位也切分开，如：2018/年 不含行政区划的地名 比如：上海、北京、武汉 专有名词：机构、团体、组织 是一个封闭类，是不可类推的 包含上下隶属关系的团体机构专有名词，切分到最小的团体机构。比如“中国/银行/北京/分行”。 简称略语 方位词 语气词 叹词 实语素 包括北大方案里的形语素、名语素、动语素、人名中的姓氏，比如：锦（形语素） 虚语素 前接成分 比如“阿”“老”“非” 这类除了传统意义上的前缀，也要考虑一些网络流行语的临时构词产出的前缀 副语素 主要是否定副词，比如“不”“很” 后接成分 比如：们，儿（表亲昵的），子，头，化，者 我认为，还应包括行政区划的单位，比如：省、市、区等；和表示尊称的“老”“总” 助词 助动词、助数词 习语 包括成语、四字格短语、歇后语 但是如果歇后语有标点符号，要按照标点符号划分 比如：“不管三七二十一”“百尺竿头/，/更进一步” 粗粒度简言之：切到词组层，且注意音节数，对双音节放宽。将细粒度中可成词的组合成词（派生词），另将可独立成词的词根结合成复合词。粗粒度的切分目标是，使得每一个实词性的切分单位都是表义明确的分词单位，不存在语义不透明的分词单位。因此，我们也不能奢求实体识别等上游任务在分词任务中就得以解决。 前接成分+名词 比如：阿牛 前接成分+数 比如：阿大 名词+后接成分 比如：学生们、老师们、拳头、高清版 动词+后接成分 比如：创新化（单独“创新”还是分到”创新“） 姓氏+名 比如：张伟 数+量+（助数词） 比如：四/人，五个/人 时间 按北大方案，不要合并 比如：1997年/9月/3日，早/八点 复合词 双音节、三音节（切分原则详见对北大方案的讲解） 注意，不要将联合构词的词组算作复合词。 地名+行政区划 比如：北京市、上海市 地名+自然地形 比如：华北平原、南沙群岛 粗粒度下的切分难点1.专名和实体的切分专有名词指的是专指性的人名、地名、团体、机构、组织、民族、商标。 人名、地名、民族、商标基本上没有异议，但是哪些团体、机构、组织能算专有名词，哪些不能算是不太明确的。 另外，除上面指出的分类外，其他的具有专指性的实体，不能被当做专有名词来处理。具体来说，专有名词的切分难点有以下几点： （1） 专有名词的专指性是忽略文本语境。比如”校长办公室发布重要通知“，即使通过前文我们知道这里指的是北大的校长办公室，我们只将它作为普通名词的处理，而不是作为一个专指性的机构名来处理。 但是在国际或中国范围内的知名的唯一的团体、机构、组织 的名称我们依然将之处理为专名，比如“国务院”，它和“校长办公室”的区别在于“国务院”全国只有一个，而“校长办公室”有很多个，因此“国务院”作为专名不切分，而“校长办公室”要切分成“校长/办公室”。 （2）专有名词的组合性。专有名词有时会和其他名词一起组合成词。对于分词任务而言，我们只需考虑将专有名词和这个词切开后这个词能否单独成词，如果不能，那么就不切分，如果能，那么就切分。（这里和北大方案不同，北大方案认为接单音节可以切分，也可以不切分。）比如”满人“，”哈萨克人“，”昌平/分行“，而对于一些多个名词组合成专名的情况，比如“全国/总/工会”“全国/人民/代表/大会“，在细粒度和粗粒度中，由于它们音节数较多，视为普通名词进行切分。是否可以设置一个粗粒度2级，在粗粒度2级中，作为组织类专有名词，不切分。 （3）专有名词层次性。表示机构的专有名词中有些是前后相连，包含上下隶属关系的。下级机构的专指性有的是从由上级团体继承来的，比如“北京大学计算语言学研究所”是一个专指性的短语，它之所以有专指性，是因为“北京大学”这个专有名词的专指性，如果没有“北京大学”，则“计算语言学研究所”按照普通名词词组来切分（参照第一点）；有的是通过其他专有名词，如地名、人名获得的，比如“鲁迅研究院”，“北京分行”。在粗粒度中，对于获得专指性的专有名词不切分，如“鲁迅研究院”，“北京分行”是否可以设置粗粒度2级，表示上下级的专有名词全部纳入？比如“北京大学计算语言学研究所”，在粗粒度2级中就不做切分。 （4）电视节目、文艺作品（书、文档、协议）标题、电视剧、战争名等，不作为专有名词，按照普通名词划分。举例： 伊拉克/战争 辛亥/革命 平津/战役 开心/词典 新闻/30分 新闻/早/8点 中央电视台/-/1（它们后期可以通过书名号和引号识别出来。） 2.政治话语是否算作习语？（可以讨论）政治口号和政治思想由于在一定的历史时期中频繁使用，因此，如果切分表意就不一样。比如“中国特色社会主义思想”和“习近平新时代中国特色社会主义思想”就是两个概念。 有两个解决方案，一个是将音节较短的政治话语算作语法词典中的词，如“科技强国”“科教兴国”“绿色经济”，“科技创新”等等，然后遇到这样的词，细粒度、粗粒度里都不切分，而音节较长的，比如“中华民族伟大复兴”就作为普通名词进行切分；第二个解决方案是全部按照普通名词切分，到具体的任务需求时再处理。不过，我觉得这两个解决方案都会影响分词粒度整体的平衡度，因为政治口号构词有时非常非常长。 3.某某理论的名称算作专名吗？某某领域理论中的专业术语算作专名吗？理论的命名同样是任意性的命名行为，和菜名一样，如果对“xxx理论”中的“xxx”进行切分后，“xxx”的意思有所改变，那么就不能切分，如果没有改变，则可以切分。比如“精神分析/理论”，如果切分成“精神/分析”，这个“精神”和“你今天精神不佳”中的“精神”并不是一个意思，因此不能切分。而“牛顿/第二/定律”切分后没问题，因为这个理论的命名本身是组合而成的。 那么各个领域中的专业术语是否算作专名呢？我认为在通用型的分词中，只加入最为重要的一些专业术语；而在特定领域中，再在这方面进行拓展。因此，“社会生活”在社会学中应当算作一个专业术语，但是在通用型的分词中还是按照普通名词来进行切分，即“社会/生活”。 4.并列成分如何切分？并列成分按照顿号进行切分，比如“平津/、/辽沈/战役”，”张/、/李家“（这里的”张“可以看做是”张家“的缩略形式）。","categories":[],"tags":[{"name":"NLP","slug":"NLP","permalink":"http://shamy1997.github.io/tags/NLP/"},{"name":"分词","slug":"分词","permalink":"http://shamy1997.github.io/tags/分词/"}]},{"title":"Hello World","slug":"hello-world","date":"2018-05-30T06:23:49.000Z","updated":"2019-01-20T11:55:31.044Z","comments":true,"path":"passages/hello-world/","link":"","permalink":"http://shamy1997.github.io/passages/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}